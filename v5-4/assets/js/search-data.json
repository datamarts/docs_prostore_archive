{"0": {
    "doc": "ALTER VIEW",
    "title": "ALTER VIEW",
    "content": "Запрос позволяет изменить вид логического представления в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Логическое представление можно также изменить с помощью запроса CREATE OR REPLACE VIEW (см. CREATE VIEW). Если при обработке запроса происходит ошибка, последующее изменение сущностей логической базы данных невозможно. В этом случае нужно повторить запрос. Действие перезапустит обработку запроса, и после ее завершения можно будет продолжить работу с логической БД. Каждое изменение представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html"
  },"1": {
    "doc": "ALTER VIEW",
    "title": "Синтаксис",
    "content": "ALTER VIEW [db_name.]view_name AS SELECT query . Параметры: . | db_name — имя логической базы данных, в которой находится логическое представление. Опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя изменяемого логического представления; | query — SELECT-подзапрос, на основе которого строится новый вид логического представления. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html#syntax",
    "relUrl": "/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html#syntax"
  },"2": {
    "doc": "ALTER VIEW",
    "title": "Ограничения",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Подзапрос query не может содержать: . | логические представления, | системные представления INFORMATION_SCHEMA, | ключевое слово FOR SYSTEM_TIME, | ключевое слово DATASOURCE_TYPE. | . | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html#restrictions",
    "relUrl": "/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html#restrictions"
  },"3": {
    "doc": "ALTER VIEW",
    "title": "Пример",
    "content": "ALTER VIEW marketing.stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM marketing.sales GROUP BY store_id ORDER BY product_amount ASC LIMIT 20 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html#examples",
    "relUrl": "/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html#examples"
  },"4": {
    "doc": "CREATE MATERIALIZED VIEW",
    "title": "CREATE MATERIALIZED VIEW",
    "content": "Содержание раздела . | Синтаксис . | Ключевое слово DATASOURCE_TYPE | Ключевое слово LOGICAL_ONLY | . | Ограничения | Примеры . | Создание представления на основе одной таблицы с условием | Создание представления на основе одной таблицы с условием, агрегацией и группировкой | Создание представления на основе двух таблиц | Создание представления только на логическом уровне | . | . Запрос позволяет создать материализованное представление в логической базе данных. Материализованные представления можно создавать на основе данных ADB. Данные представлений могут размещаться в ADG и (или) ADQM. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса система создает материализованное представление, а также подготавливает хранилище к размещению данных представления — создает физические таблицы, связанные с материализованным представлением и предназначенные для хранения его данных. Физические таблицы создаются в тех СУБД хранилища, которые указаны в запросе. В отличие от запроса на создание логической таблицы, запрос CREATE MATERIALIZED VIEW должен содержать ключевое слово DATASOURCE_TYPE со списком СУБД для размещения данных представления. Требование связано с тем, что данные представлений (в отличие от данных логических таблиц) могут размещаться только в ADG и ADQM, а не во всех СУБД хранилища. Синхронизация нового представления запускается в первом цикле синхронизации, доступном после создания представления, в порядке очереди (если такая есть). Статус синхронизации представления можно узнать с помощью запроса CHECK_MATERIALIZED_VIEW. Подробнее о синхронизации см. в разделе Синхронизация материализованных представлений. Изменение материализованного представления недоступно. Для замены материализованного представления необходимо удалить его и создать новое. Если при обработке запроса происходит ошибка, последующее изменение сущностей логической базы данных невозможно. В этом случае нужно повторить запрос. Действие перезапустит обработку запроса, и после ее завершения можно будет продолжить работу с логической БД. Каждое создание представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html"
  },"5": {
    "doc": "CREATE MATERIALIZED VIEW",
    "title": "Синтаксис",
    "content": "CREATE MATERIALIZED VIEW [db_name.]materialized_view_name ( column_name_1 datatype_1 [ NULL | NOT NULL ], column_name_2 datatype_2 [ NULL | NOT NULL ], column_name_3 datatype_3 [ NULL | NOT NULL ], PRIMARY KEY (column_list_1) ) DISTRIBUTED BY (column_list_2) DATASOURCE_TYPE (datasource_aliases) AS SELECT query DATASOURCE_TYPE = origin_datasource_alias [LOGICAL_ONLY] . Параметры: . | db_name — имя логической базы данных, в которой создается материализованное представление. Опционально, если выбрана логическая БД, используемая по умолчанию; | materialized_view_name — имя создаваемого материализованного представления, уникальное среди логических сущностей логической БД; | column_name_N — имя столбца представления; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | column_list_1 — список столбцов, входящих в первичный ключ представления; | column_list_2 — список столбцов, входящих в ключ шардирования представления. Столбцы должны быть из числа столбцов column_list_1; | datasource_aliases — список псевдонимов СУБД хранилища, в которых нужно разместить данные представления. Элементы списка перечисляются через запятую. Возможные значения: adqm, adg. Значения можно указывать без кавычек (например, adg) или двойных кавычках (например, \"adg\"); | query — SELECT-подзапрос, на основе которого строится представление; | origin_datasource_alias — псевдоним СУБД, которая служит источником данных. Возможные значения: 'adb'. Значение указывается в одинарных кавычках. | . Ключевое слово DATASOURCE_TYPE . Ключевое слово DATASOURCE_TYPE позволяет указать СУБД хранилища, в которых необходимо размещать данные материализованного представления. В текущей версии данные представления могут размещаться в ADG и (или) в ADQM. Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет создать материализованное представление только на логическом уровне (в логической схеме данных), без пересоздания связанных физических таблиц в хранилище данных. Если ключевое слово не указано, создается как материализованное представление, так и связанные с ним физические таблицы. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html#syntax",
    "relUrl": "/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html#syntax"
  },"6": {
    "doc": "CREATE MATERIALIZED VIEW",
    "title": "Ограничения",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Имена представления и его столбцов должны начинаться с латинской буквы, после первого символа могут следовать латинские буквы, цифры и символы подчеркивания в любом порядке. | Представление и его столбцы не могут иметь имена, перечисленные в разделе Зарезервированные слова. Столбцы также не могут иметь имена, зарезервированные системой для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Имена столбцов должны быть уникальны в рамках представления. | Имена, порядок и типы данных столбцов должны совпадать в SELECT-подзапросе и представлении. | Первичный ключ должен включать все столбцы ключа шардирования. | Подзапрос может обращаться только к логическим таблицам и только той логической базы данных, в которой находится материализованное представление. | Подзапрос не может содержать: . | ключевое слово FOR SYSTEM_TIME, | ключевое слово ORDER BY, | ключевое слово LIMIT. | . | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html#restrictions",
    "relUrl": "/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html#restrictions"
  },"7": {
    "doc": "CREATE MATERIALIZED VIEW",
    "title": "Примеры",
    "content": "Создание представления на основе одной таблицы с условием . Создание представления с размещением в ADG и ADQM: . CREATE MATERIALIZED VIEW marketing.sales_december_2020 ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adg, adqm) AS SELECT * FROM marketing.sales WHERE cast(transaction_date as date) BETWEEN '2020-12-01' AND '2020-12-31' DATASOURCE_TYPE = 'adb' . Создание представления на основе одной таблицы с условием, агрегацией и группировкой . Создание представления с размещением в ADQM: . CREATE MATERIALIZED VIEW marketing.sales_by_stores ( store_id INT NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, PRIMARY KEY (store_id, product_code) ) DISTRIBUTED BY (store_id) DATASOURCE_TYPE (adqm) AS SELECT store_id, product_code, SUM(product_units) as product_units FROM marketing.sales WHERE product_code &lt;&gt; 'ABC0001' GROUP BY store_id, product_code DATASOURCE_TYPE = 'adb' . Создание представления на основе двух таблиц . CREATE MATERIALIZED VIEW marketing.sales_and_stores ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, description VARCHAR(256), store_id INT NOT NULL, store_category VARCHAR(256) NOT NULL, region VARCHAR(256) NOT NULL, PRIMARY KEY (id, region) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adg) AS SELECT s.id, s.transaction_date, s.product_code, s.product_units, s.description, st.id AS store_id, st.category as store_category, st.region FROM marketing.sales AS s JOIN marketing.stores AS st ON s.store_id = st.id DATASOURCE_TYPE = 'adb' . Создание представления только на логическом уровне . CREATE MATERIALIZED VIEW marketing.stores_by_sold_products_matview ( store_id INT NOT NULL, product_amount INT NOT NULL, PRIMARY KEY (store_id) ) DISTRIBUTED BY (store_id) DATASOURCE_TYPE (adg) AS SELECT store_id, SUM(product_units) AS product_amount FROM marketing.sales GROUP BY store_id DATASOURCE_TYPE = 'adb' LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html#examples",
    "relUrl": "/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html#examples"
  },"8": {
    "doc": "DELETE",
    "title": "DELETE",
    "content": "Содержание раздела . | Синтаксис | Ограничения | Пример | . Запрос позволяет удалить актуальные записи логической таблицы. Записи выбираются по условию, указанному в блоке запроса WHERE. Записи становятся архивными и при этом остаются доступными для чтения и выгрузки. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на обновление данных. Удаление записей возможно только из логической таблицы. Удаление записей из логических и материализованных представлений недоступно. Запрос не поддерживается для ADG. Для обновления большого объема данных следует использовать загрузку данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Если операция записи, запущенная запросом DELETE, зависла, горячую дельту невозможно закрыть или откатить. В этом случае нужно повторить запрос. Действие перезапустит обработку операции, и после ее завершения можно будет закрыть или откатить дельту. Список незавершенных (в том числе — зависших) операций можно посмотреть можно с помощью запроса GET_WRITE_OPERATIONS. Чтобы удалить записи вместе с историей изменений или только историю изменений, используйте запрос TRUNCATE HISTORY. Удалить все записи таблицы с историей можно, удалив логическую таблицу из всех СУБД хранилища. Обратите внимание, что удаленные таким образом данные невозможно восстановить средствами системы. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DELETE/DELETE.html",
    "relUrl": "/reference/sql_plus_requests/DELETE/DELETE.html"
  },"9": {
    "doc": "DELETE",
    "title": "Синтаксис",
    "content": "DELETE FROM [db_name.]table_name [WHERE filter_expression] . Параметры: . | db_name — имя логической базы данных. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя логической таблицы, записи которой удаляются; | filter_expression — условие выбора удаляемых записей. Если ключевое слово WHERE с условием не указано, удаляются все актуальные данные таблицы. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DELETE/DELETE.html#syntax",
    "relUrl": "/reference/sql_plus_requests/DELETE/DELETE.html#syntax"
  },"10": {
    "doc": "DELETE",
    "title": "Ограничения",
    "content": ". | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | Столбцы в условии запроса не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | В условии WHERE не допускается использование функций, результаты которых различаются в разных СУБД хранилища. Примерами таких функций служат операции с вещественными числами (числами с плавающей запятой): сравнение с вещественным числом, округление и т.д. | Не допускается выполнение идентичных параллельных запросов. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DELETE/DELETE.html#restrictions",
    "relUrl": "/reference/sql_plus_requests/DELETE/DELETE.html#restrictions"
  },"11": {
    "doc": "DELETE",
    "title": "Пример",
    "content": "-- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- открытие новой (горячей) дельты BEGIN DELTA; -- удаление записей логической таблицы sales о покупках в магазине, который был закрыт DELETE FROM sales WHERE store_id = 234; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DELETE/DELETE.html#examples",
    "relUrl": "/reference/sql_plus_requests/DELETE/DELETE.html#examples"
  },"12": {
    "doc": "INSERT INTO download_external_table",
    "title": "INSERT INTO download_external_table",
    "content": "Содержание раздела . | Синтаксис | Ограничения | Пример . | Выгрузка из наиболее оптимальной СУБД | Выгрузка из указанной СУБД | Выгрузка из материализованного представления | . | . Запрос позволяет выгрузить данные, выбранные SELECT-подзапросом к логической базе данных, во внешний приемник данных. Данные можно выгружать из логических таблиц, логических и материализованных представлений. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на выгрузку данных. Для получения небольшого объема данных можно использовать запрос данных. Перед выполнением запроса необходимо создать внешнюю таблицу с указанием пути к внешнему приемнику данных. Подробнее о порядке выполнения действий для выгрузки данных см. в разделе Выгрузка данных. В запросе можно указать СУБД хранилища для выгрузки данных. Если СУБД не указана, система определяет СУБД, оптимальную для выгрузки, в зависимости от параметров запроса, месторасположения данных и конфигурации системы. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса данные выгружаются в том формате и в тот приемник данных, которые были указаны при создании внешней таблицы выгрузки. Формат данных соответствует описанному в разделе Формат выгрузки данных. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html",
    "relUrl": "/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html"
  },"13": {
    "doc": "INSERT INTO download_external_table",
    "title": "Синтаксис",
    "content": "INSERT INTO [db_name.]ext_table_name SELECT query . Параметры: . | db_name — имя логической базы данных, из которой выгружаются данные. Параметр опционален, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя внешней таблицы выгрузки; | query — SELECT-подзапрос для выбора выгружаемых данных. Если в подзапросе указано ключевое слово DATASOURCE_TYPE с псевдонимом СУБД хранилища, данные выгружаются из этой СУБД, иначе — из СУБД, наиболее оптимальной для исполнения запроса. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html#syntax",
    "relUrl": "/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html#syntax"
  },"14": {
    "doc": "INSERT INTO download_external_table",
    "title": "Ограничения",
    "content": "Имена и порядок следования столбцов должны совпадать в SELECT-подзапросе на выгрузку данных и внешней таблице выгрузки. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html#restrictions",
    "relUrl": "/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html#restrictions"
  },"15": {
    "doc": "INSERT INTO download_external_table",
    "title": "Пример",
    "content": "Выгрузка из наиболее оптимальной СУБД . INSERT INTO marketing.sales_ext_download SELECT * FROM marketing.sales WHERE product_units &gt; 2 . Выгрузка из указанной СУБД . INSERT INTO marketing.sales_ext_download SELECT * FROM marketing.sales WHERE description = 'Покупка по акции 1+1' DATASOURCE_TYPE = 'adqm' . Выгрузка из материализованного представления . INSERT INTO marketing.sales_by_stores_ext_download SELECT * FROM marketing.sales_by_stores WHERE product_code IN ('ABC0002', 'ABC0003', 'ABC0004') DATASOURCE_TYPE = 'adqm' . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html#examples",
    "relUrl": "/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html#examples"
  },"16": {
    "doc": "INSERT SELECT",
    "title": "INSERT SELECT",
    "content": "Содержание раздела . | Синтаксис | Ограничения | Пример . | Вставка данных во все столбцы таблицы | Вставка данных в некоторые столбцы таблицы | Вставка данных из таблицы другой логической БД | Вставка данных из логического представления | Вставка данных столбца из другой таблицы | . | . Запрос позволяет вставить несколько записей в логическую таблицу (далее — целевая таблица) из другой логической сущности: логической таблицы, логического или материализованного представления. Вставка данных в логические и материализованные представления недоступна. Запрос поддерживается для ADB, ADQM и ADP. Для вставки большого объема данных следует использовать загрузку данных или сочетание выгрузки и загрузки данных. Вставка данных возможна, если выполнено любое из условий: . | данные целевой таблицы размещены только в одной СУБД хранилища, и источником данных служит та же СУБД хранилища; | данные целевой таблицы размещены в ADB и ADQM, и источником данных служит ADB. | . Источником данных всегда служит одна СУБД хранилища: указанная в запросе или, если такая не указана, наиболее оптимальная СУБД для исполнения SELECT-подзапроса. Подробнее о выборе СУБД для исполнения запроса см. в разделе Маршрутизация запросов к данным. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса вставленные записи сохраняются как актуальные записи, а предыдущие актуальные записи, если такие найдены, становятся архивными. Наличие предыдущей актуальной записи определяется по первичному ключу: все записи таблицы с одинаковым первичным ключом рассматриваются системой как различные исторические состояния одного объекта. Подробнее о версионировании см. в разделе Версионирование данных. Если операция записи, запущенная запросом INSERT SELECT, зависла, горячую дельту невозможно закрыть или откатить. В этом случае нужно повторить запрос. Действие перезапустит обработку операции, и после ее завершения можно будет закрыть или откатить дельту. Список незавершенных (в том числе — зависших) операций можно посмотреть можно с помощью запроса GET_WRITE_OPERATIONS. Месторасположение данных логической таблицы можно задавать запросами CREATE TABLE и DROP TABLE с ключевым словом DATASOURCE_TYPE. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_SELECT/INSERT_SELECT.html",
    "relUrl": "/reference/sql_plus_requests/INSERT_SELECT/INSERT_SELECT.html"
  },"17": {
    "doc": "INSERT SELECT",
    "title": "Синтаксис",
    "content": "Вставка данных во все столбцы логической таблицы: . INSERT INTO [db_name.]table_name SELECT query . Вставка данных только в некоторые столбцы логической таблицы (с заполнением остальных столбцов значениями, которые определены в СУБД хранилища как значения по умолчанию): . INSERT INTO [db_name.]table_name (column_list) SELECT query . Параметры: . | db_name — имя логической базы данных. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя логической таблицы, в которую вставляются данные; | column_list — список имен столбцов логической таблицы. Имена указываются в круглых скобках через запятую. Список опционален, если количество и порядок столбцов в SELECT-подзапросе соответствуют количеству и порядку столбцов в логической таблице; | query — SELECT-подзапрос для выбора данных. Если в подзапросе указано ключевое слово DATASOURCE_TYPE с псевдонимом СУБД хранилища, данные выбираются из указанной СУБД, иначе — из СУБД, наиболее оптимальной для исполнения запроса. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_SELECT/INSERT_SELECT.html#syntax",
    "relUrl": "/reference/sql_plus_requests/INSERT_SELECT/INSERT_SELECT.html#syntax"
  },"18": {
    "doc": "INSERT SELECT",
    "title": "Ограничения",
    "content": ". | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | Столбцы в запросе не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Типы вставляемых данных должны соответствовать типам данных столбцов целевой логической таблицы. | Не допускается выполнение идентичных параллельных запросов. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_SELECT/INSERT_SELECT.html#restrictions",
    "relUrl": "/reference/sql_plus_requests/INSERT_SELECT/INSERT_SELECT.html#restrictions"
  },"19": {
    "doc": "INSERT SELECT",
    "title": "Пример",
    "content": "Вставка данных во все столбцы таблицы . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- создание логической таблицы sales_july_2021 с данными о продажах за июль 2021 (с размещением данных в ADB) CREATE TABLE sales_july_2021 ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adb); -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка данных из таблицы sales в таблицу sales_july_2021 INSERT INTO sales_july_2021 SELECT * FROM sales WHERE CAST(EXTRACT(MONTH FROM transaction_date) AS INT) = 7 AND CAST(EXTRACT(YEAR FROM transaction_date) AS INT) = 2021 DATASOURCE_TYPE = 'adb'; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Вставка данных в некоторые столбцы таблицы . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales; -- создание логической таблицы current_stores с выборкой из таблицы stores (с размещением данных в ADQM) CREATE TABLE current_stores ( id INT NOT NULL, category VARCHAR(256), region VARCHAR(256), address VARCHAR(256), description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adqm); -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка данных в таблицу current_stores без указания значения столбца description INSERT INTO current_stores (id, category, region, address) SELECT id, category, region, address FROM stores FOR SYSTEM_TIME AS OF DELTA_NUM 10 DATASOURCE_TYPE = 'adqm'; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Вставка данных из таблицы другой логической БД . -- создание новой логической БД marketing_new CREATE DATABASE marketing_new; -- выбор логической базы данных sales в качестве базы данных по умолчанию USE marketing_new; -- создание логической таблицы sales в логической БД marketing_new (с размещением данных в ADP) CREATE TABLE sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adp); -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка данных в таблицу sales из аналогичной таблицы другой логической БД INSERT INTO sales SELECT * FROM marketing.sales WHERE store_id BETWEEN 1234 AND 4567 DATASOURCE_TYPE = 'adp'; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Вставка данных из логического представления . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales; -- создание логического представления basic_stores с данными о магазинах категории basic CREATE VIEW basic_stores AS SELECT * FROM stores WHERE category = 'basic'; -- создание таблицы basic_stores_table с данными о магазинах категории basic (с размещением данных в ADB и ADQM) CREATE TABLE basic_stores_table ( id INT NOT NULL, category VARCHAR(256), region VARCHAR(256), address VARCHAR(256), description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adb, adqm); -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка данных в таблицу basic_stores_table INSERT INTO basic_stores_table SELECT * FROM basic_stores DATASOURCE_TYPE = 'adb'; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Вставка данных столбца из другой таблицы . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales; -- создание логической таблицы с данными покупок и адресов магазинов, где были совершены покупки CREATE TABLE sales_with_address ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256), store_address VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adb, adqm); -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка данных из таблицы sales (заполнение всех столбцов, кроме store_address) INSERT INTO sales_with_address (id, transaction_date, product_code, product_units, store_id, description) SELECT * FROM sales DATASOURCE_TYPE = 'adb'; -- закрытие дельты (фиксация изменений) COMMIT DELTA; -- открытие новой (горячей) дельты BEGIN DELTA; --- вставка данных адресов из таблицы stores в те строки, где адрес не заполнен INSERT INTO sales_with_address SELECT s.id, s.transaction_date, s.product_code, s.product_units, s.store_id, s.description, st.region || ', ' || st.address as store_address FROM stores AS st JOIN sales_with_address AS s ON s.store_id = st.id WHERE s.store_address IS NULL OR s.store_address = '' DATASOURCE_TYPE = 'adb'; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_SELECT/INSERT_SELECT.html#examples",
    "relUrl": "/reference/sql_plus_requests/INSERT_SELECT/INSERT_SELECT.html#examples"
  },"20": {
    "doc": "docs_prostore",
    "title": "docs_prostore",
    "content": "Prostore user guide . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/README.html",
    "relUrl": "/README.html"
  },"21": {
    "doc": "SELECT",
    "title": "SELECT",
    "content": "Содержание раздела . | Синтаксис . | Поддерживаемые ключевые слова | Ключевое слово FOR SYSTEM_TIME | Поддерживаемые типы соединений (префиксы JOIN) | Ключевое слово COLLATE | Ключевое слово OFFSET | Ключевое слово ESTIMATE_ONLY | . | Ограничения | Примеры . | Звездочка и WHERE | DATASOURCE_TYPE | GROUP BY, ORDER BY и LIMIT | ESTIMATE_ONLY | COLLATE | OFFSET | ORDER BY, LIMIT и OFFSET | FOR SYSTEM_TIME AS OF DELTA_NUM | Соединение таблиц из разных логических БД | Соединение изменений из разных дельт | . | . Запрос позволяет выбрать данные из логических таблиц, логических представлений и (или) материализованных представлений или получить информацию о запросе к данным. Возможен запрос к срезу данных на указанный момент времени. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на чтение данных. В ответе возвращается: . | объект ResultSet c выбранными записями или информацией о запросе при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Запрос также можно использовать как подзапрос в следующих запросах: . | на выгрузку данных, | на создание или обновление логического представления, | на создание материализованного представления. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/SELECT/SELECT.html",
    "relUrl": "/reference/sql_plus_requests/SELECT/SELECT.html"
  },"22": {
    "doc": "SELECT",
    "title": "Синтаксис",
    "content": "SELECT column_list FROM [db_name.]entity_name [FOR SYSTEM_TIME time_expression [AS alias_name]] [DATASOURCE_TYPE = datasource_alias] [ESTIMATE_ONLY] . Параметры: . | column_list — список выбираемых столбцов таблицы или представления. Можно указывать символ * для выбора всех столбцов; | db_name — имя логической базы данных, из которой выбираются данные. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | entity_name — имя таблицы или представления, из которого выбираются данные; | time_expression — выражение, задающее момент или период времени, за который выбираются данные или изменения данных. Синтаксис выражения см. ниже; | alias_name — псевдоним таблицы или представления. Может включать латинские буквы, цифры и символы подчеркивания; | datasource_alias — системный псевдоним СУБД хранилища, из которой выбираются данные. Возможные значения: 'adb', 'adqm', 'adg', 'adp'. | . В запросах можно указывать: . | ключевые слова, перечисленные в секции Поддерживаемые ключевые слова, | функции, перечисленные в разделе Поддержка SQL, | псевдонимы для имен таблиц, представлений и столбцов. | . Некоторые агрегатные функции и типы соединений недоступны для исполнения в определенных СУБД хранилища. Список доступных возможностей см. в разделе Поддержка SQL. Поддерживаемые ключевые слова . В запросе можно использовать следующие ключевые слова, которые должны быть указаны в порядке их перечисления: . | FOR SYSTEM_TIME — для указания момента времени или периода, за который выбираются данные или изменения данных. Если ключевое слово не указано, из логической таблицы и логического представления выбираются данные, актуальные на момент обработки запроса, из материализованного представления — данные, актуальные на момент последней синхронизации представления. Описание синтаксиса см. в секции Ключевое слово FOR SYSTEM_TIME; | JOIN ON — для соединения данных нескольких логических таблиц и (или) представлений из одной или нескольких логических БД. Возможные префиксы см. в секции Возможные типы соединений (префиксы JOIN); | WHERE — для указания условий выбора данных. Условия в запросах к ADG могут включать ключевое слово COLLATE; | GROUP BY — для группировки данных; | HAVING — для указания условий выбора сгруппированных данных; | ORDER BY — для сортировки данных; | LIMIT или FETCH NEXT &lt;N&gt; ROWS ONLY— для ограничения количества возвращаемых строк; | OFFSET — для пропуска указанного количества строк в результате запроса. Описание синтаксиса см. в секции Ключевое слово OFFSET; | DATASOURCE_TYPE — для указания СУБД хранилища, из которой выбираются данные; | ESTIMATE_ONLY — для получения информации о запросе, а не самих данных. Описание см. в секции Ключевое слово ESTIMATE_ONLY. | . Ключевое слово FOR SYSTEM_TIME . Ключевое слово FOR SYSTEM_TIME позволяет указать момент, по состоянию на который запрашиваются данные, или период (диапазон дельт), за который запрашиваются изменения. Ключевое слово относится к логической таблице, логическому представлению или материализованному представлению, после имени которого оно следует. Если в запросе соединяется несколько логических таблиц и представлений, для каждой логической сущности можно указать свое ключевое слово FOR SYSTEM_TIME, при этом значения этих ключевых слов могут различаться (см. пример ниже). Наличие и значение ключевого слова FOR SYSTEM_TIME для материализованного представления влияют на порядок маршрутизации запроса (см. раздел Маршрутизация запросов к данным материализованных представлений). Ключевое слово указывается в формате FOR SYSTEM_TIME time_expression, где выражение time_expression принимает одно из следующих значений: . | AS OF 'YYYY-MM-DD hh:mm:ss' — запрос данных, актуальных на указанную дату и время. Возможные форматы даты и времени см. в разделе Форматы даты и времени в запросах; | AS OF DELTA_NUM delta_num — запрос данных, актуальных на дату и время закрытия дельты с номером delta_num; | AS OF LATEST_UNCOMMITTED_DELTA — запрос данных на текущий момент, включая данные, загруженные в рамках горячей дельты. По горячей дельте возвращаются записи, загруженные в рамках непрерывного диапазона завершенных операций записи (см. параметры cn_from и cn_to в разделе GET_DELTA_HOT); | STARTED IN (delta_num1, delta_num2) — запрос данных, добавленных или измененных в период между дельтой delta_num1 и дельтой delta_num2 (включая граничные дельты); | FINISHED IN (delta_num1, delta_num2) — запрос данных, удаленных в период между дельтой delta_num1 и дельтой delta_num2 (включая граничные дельты). | . Следующие значения ключевого слова не поддерживаются в запросах к материализованным представлениям: . | FOR SYSTEM_TIME AS OF LATEST_UNCOMMITTED_DELTA; | FOR SYSTEM_TIME STARTED IN (delta_num1, delta_num2), если хотя бы одна дельта из диапазона отсутствует в материализованном представлении; | FOR SYSTEM_TIME FINISHED IN (delta_num1, delta_num2), если хотя бы одна дельта из диапазона отсутствует в материализованном представлении. | . Поддерживаемые типы соединений (префиксы JOIN) . Поддерживаются следующие типы соединений: . | [INNER] — внутреннее соединение, | NATURAL — внутреннее соединение по всем столбцам с одинаковыми именами, ключи соединения не указываются, | LEFT [OUTER] — левое внешнее соединение, | RIGHT [OUTER] — правое внешнее соединение, | FULL [OUTER] — полное внешнее соединение, | CROSS — декартово произведение таблиц или представлений, ключи соединения не указываются. | . Ключевое слово COLLATE . Ключевое слово COLLATE позволяет задать правило сопоставления символьных строк, например, приравнять строки в верхнем и нижнем регистрах. Ключевое слово доступно в условии, заданном с помощью ключевого слова WHERE (см. пример ниже). Ключевое слово COLLATE поддерживается только для запросов к ADG. Это означает, что для его корректной работы в запросе нужно либо указать ADG в качестве источника данных (DATASOURCE_TYPE = 'adg'), либо обращаться к логической сущности, данные которой размещены только в ADG. Подробнее о правилах сопоставления символьных строк в ADG см. в документации Tarantool. Ключевое слово OFFSET . Ключевое слово OFFSET позволяет пропустить первые несколько строк результата и выбрать только последующие строки (см. примеры ниже). В качестве значения ключевого слова можно указать любое неотрицательное целое число, начиная с нуля, или переменную. Если для OFFSET указано значение 0, то пропускается 0 строк, что равносильно запросу без OFFSET. Запросы с OFFSET без ограничения количества строк не поддерживаются. То есть, если ключевое слово OFFSET указано в запросе, то перед ним должно быть ключевое слово LIMIT &lt;N&gt; или FETCH NEXT &lt;N&gt; ROWS ONLY. Обратного ограничения нет: ключевые слова LIMIT &lt;N&gt; и FETCH NEXT &lt;N&gt; ROWS ONLY можно использовать без OFFSET. Рекомендуется сочетать OFFSET с ключевым словом ORDER BY для получения упорядоченного набора строк. Ключевое слово ORDER BY необязательно, однако без него запрос с OFFSET возвращает неупорядоченный и потому непредсказуемый набор строк. Таким образом, для ключевого слова OFFSET поддерживается следующий синтаксис: . [ ORDER BY &lt;column_name&gt; ] { LIMIT &lt;value_1&gt; | FETCH NEXT &lt;value_1&gt; ROWS ONLY } OFFSET &lt;value_2&gt; [ ROW | ROWS ] . Ключевое слово ESTIMATE_ONLY . Ключевое слово ESTIMATE_ONLY позволяет запросить информацию о выполнении запроса к данным, а не сами данные (см. пример ниже). Если запрос содержит ESTIMATE_ONLY, вместо выборки данных из таблицы или представления в ответе возвращается следующая информация: . | имя СУБД хранилища, в которой предполагается выполнение запроса; | план выполнения запроса (только для ADB и ADP) — результат выполнения команды EXPLAIN в СУБД хранилища. Подробнее о команде EXPLAIN в ADB см. в документации Greenplum, о команде в ADP — в документации PostgreSQL; | обогащенный запрос — запрос, подготовленный системой на основе исходного запроса с учетом специфики СУБД хранилища. | . В ответе возвращается объект ResultSet с одной строкой, содержащей JSON-строку в следующем формате: . { \"plugin\": \"&lt;имя_СУБД&gt;\", \"estimation\": &lt;план_выполнения_запроса&gt;, \"query\": &lt;обогащенный_запрос&gt; } . Ниже показан пример JSON-строки, полученной по запросу к ADB. Для наглядности пример представлен в виде дерева, а не плоской строки. { \"plugin\": \"ADB\", \"estimation\": [ { \"Plan\": { \"Node Type\": \"Gather Motion\", \"Senders\": 4, \"Receivers\": 1, \"Slice\": 1, \"Segments\": 4, \"Gang Type\": \"primary reader\", \"Startup Cost\": 0.00, \"Total Cost\": 433.70, \"Plan Rows\": 50000, \"Plan Width\": 8, \"Plans\": [ { \"Node Type\": \"Seq Scan\", \"Parent Relationship\": \"Outer\", \"Slice\": 1, \"Segments\": 4, \"Gang Type\": \"primary reader\", \"Relation Name\": \"sales_actual\", \"Alias\": \"sales_actual\", \"Startup Cost\": 0.00, \"Total Cost\": 432.18, \"Plan Rows\": 50000, \"Plan Width\": 8 } ] }, \"Settings\": { \"Optimizer\": \"Pivotal Optimizer (GPORCA)\" } } ], \"query\": \"SELECT * FROM (SELECT id FROM marketing.sales_actual WHERE sys_from &lt;= 98 AND COALESCE(sys_to, 9223372036854775807) &gt;= 98)\" } . Ниже показан пример JSON-строки, полученной по запросу к ADP. Для наглядности пример представлен в виде дерева, а не плоской строки. { \"plugin\": \"ADP\", \"estimation\": [ { \"Plan\": { \"Node Type\": \"Seq Scan\", \"Parallel Aware\": false, \"Relation Name\": \"sales_actual\", \"Alias\": \"sales_actual\", \"Startup Cost\": 0.00, \"Total Cost\": 18.80, \"Plan Rows\": 880, \"Plan Width\": 64 } } ], \"query\": \"SELECT * FROM (SELECT id FROM marketing.sales_actual WHERE sys_from &lt;= 98 AND COALESCE(sys_to, 9223372036854775807) &gt;= 98)\" } . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/SELECT/SELECT.html#syntax",
    "relUrl": "/reference/sql_plus_requests/SELECT/SELECT.html#syntax"
  },"23": {
    "doc": "SELECT",
    "title": "Ограничения",
    "content": ". | Запрос может обращаться либо к логической БД, либо к сервисной БД (см. SELECT FROM INFORMATION_SCHEMA), но не к обеим одновременно. | Если ключами соединения в запросе выступают поля типа Nullable, то строки, где хотя бы один из ключей имеет значение NULL, не соединяются. | Ключевое слово ORDER BY не поддерживается для SELECT-подзапроса в составе запроса CREATE MATERIALIZED VIEW. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/SELECT/SELECT.html#restrictions",
    "relUrl": "/reference/sql_plus_requests/SELECT/SELECT.html#restrictions"
  },"24": {
    "doc": "SELECT",
    "title": "Примеры",
    "content": "Звездочка и WHERE . Запрос с неявным указанием столбцов и ключевым словом WHERE: . SELECT * FROM marketing.sales WHERE store_id = 1234 . DATASOURCE_TYPE . Запрос с перечислением столбцов и выбором данных из определенной СУБД хранилища (ADQM): . SELECT sold.store_id, sold.product_amount FROM marketing.stores_by_sold_products AS sold DATASOURCE_TYPE = 'adqm' . GROUP BY, ORDER BY и LIMIT . Запрос с агрегацией, группировкой и сортировкой данных, а также выбором первых 20 строк: . SELECT s.store_id, SUM(s.product_units) AS product_amount FROM marketing.sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC LIMIT 20 . ESTIMATE_ONLY . Запрос на получение информации о запросе: . SELECT s.store_id, SUM(s.product_units) AS product_amount FROM marketing.sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC ESTIMATE_ONLY . Описание ключевого слова см. в секции Ключевое слово ESTIMATE_ONLY. COLLATE . Запрос строк с указанными значениями без учета регистра: . SELECT * from marketing.sales WHERE product_code = 'ABC1234' AND product_code &lt;&gt; 'abc4567' COLLATE 'unicode_ci' DATASOURCE_TYPE = 'adg' . Описание ключевого слова см. в секции Ключевое слово COLLATE. OFFSET . Запрос 20 строк, начиная с десятой: . SELECT * from marketing.sales FETCH NEXT 20 ROWS ONLY OFFSET 9 . Описание ключевого слова см. в секции Ключевое слово OFFSET. ORDER BY, LIMIT и OFFSET . Запрос 20 строк, упорядоченных по значению id и выбираемых начиная с десятой строки результата: . SELECT * from marketing.sales ORDER BY id LIMIT 20 OFFSET 9 . Такое сочетание ключевых слов позволяет выбирать данные порциями с сохранением их порядка. FOR SYSTEM_TIME AS OF DELTA_NUM . Запрос записей, актуальных на момент закрытия дельты с номером 9, из материализованного представления: . SELECT * FROM marketing.sales_and_stores FOR SYSTEM_TIME AS OF DELTA_NUM 9 . Описание ключевого слова см. в секции Ключевое слово FOR SYSTEM_TIME. Соединение таблиц из разных логических БД . Запрос с соединением данных логических таблиц из двух разных логических БД: . SELECT st.id, st.category, s.product_code FROM marketing.stores AS st INNER JOIN marketing_new.sales AS s ON st.id = s.store_id . О возможных типах соединений см. в секции Поддерживаемые типы соединений (префиксы JOIN). Соединение изменений из разных дельт . Запрос с соединением записей логической таблицы, добавленных и измененных в двух различных диапазонах дельт: . SELECT st.id, st.category, s.product_code FROM marketing.stores FOR SYSTEM_TIME STARTED IN(0,7) AS st INNER JOIN marketing.sales FOR SYSTEM_TIME STARTED IN(0,1) AS s ON st.id = s.store_id . О возможных типах соединений см. в секции Поддерживаемые типы соединений (префиксы JOIN). ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/SELECT/SELECT.html#examples",
    "relUrl": "/reference/sql_plus_requests/SELECT/SELECT.html#examples"
  },"25": {
    "doc": "UPSERT VALUES",
    "title": "UPSERT VALUES",
    "content": "Содержание раздела . | Синтаксис | Ограничения | Пример . | Вставка данных во все столбцы таблицы | Вставка данных в указанные столбцы таблицы | . | . Запрос позволяет вставить новые записи и обновить существующие записи в логической таблице. Существование записи в таблице определяется по значению первичного ключа. Если в таблице существует запись со значением первичного ключа, указанным в запросе, то запись обновляется значениями из запроса. Иначе, если запись отсутствует, то добавляется новая запись со значениями из запроса, а пропущенные поля заполняются значениями по умолчанию. Запрос поддерживается для ADB и ADP. В отличие от INSERT VALUES, запрос UPSERT VALUES обновляет существующую запись только теми значениями, которые указаны в запросе. Для полного обновления существующих записей следует использовать запрос INSERT VALUES. Для обновления большого объема данных следует использовать загрузку данных. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на обновление данных. Вставка данных в логические и материализованные представления недоступна. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса записи вставляются в СУБД хранилища, в которых размещены данные логической таблицы. При фиксации изменений каждая вставленная запись становится актуальной записью таблицы, а предыдущая актуальная запись, если такая есть, становится архивной. Месторасположение данных таблицы можно задавать запросами CREATE TABLE и DROP TABLE с ключевым словом DATASOURCE_TYPE. Все записи таблицы с одинаковым первичным ключом рассматриваются системой как различные исторические состояния одного объекта. Подробнее о версионировании см. в разделе Версионирование данных. Если операция записи, запущенная запросом UPSERT VALUES, зависла, горячую дельту невозможно закрыть или откатить. В этом случае нужно повторить запрос. Действие перезапустит обработку операции, и после ее завершения можно будет закрыть или откатить дельту. Список незавершенных (в том числе — зависших) операций можно посмотреть с помощью запроса GET_WRITE_OPERATIONS. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/UPSERT_VALUES/UPSERT_VALUES.html",
    "relUrl": "/reference/sql_plus_requests/UPSERT_VALUES/UPSERT_VALUES.html"
  },"26": {
    "doc": "UPSERT VALUES",
    "title": "Синтаксис",
    "content": "Вставка данных во все столбцы логической таблицы: . UPSERT INTO [db_name.]table_name VALUES (value_list_1), (value_list_2), ... Вставка данных только в некоторые столбцы логической таблицы (с сохранением значений остальных столбцов без изменений): . UPSERT INTO [db_name.]table_name (column_list) VALUES (value_list_1), (value_list_2), ... Параметры: . | db_name — имя логической базы данных. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя логической таблицы, в которую вставляются данные; | column_list — список имен столбцов логической таблицы. Имена указываются в круглых скобках через запятую. Список опционален, если количество и порядок вставляемых значений (в списке value_list_N) соответствуют количеству и порядку столбцов в логической таблице; | value_list_N — список значений, вставляемых в столбцы логической таблицы. Значения указываются в круглых скобках через запятую. Каждый такой список — это строка, вставляемая в таблицу. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/UPSERT_VALUES/UPSERT_VALUES.html#syntax",
    "relUrl": "/reference/sql_plus_requests/UPSERT_VALUES/UPSERT_VALUES.html#syntax"
  },"27": {
    "doc": "UPSERT VALUES",
    "title": "Ограничения",
    "content": ". | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | Столбцы в запросе не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Не допускается выполнение идентичных параллельных запросов. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/UPSERT_VALUES/UPSERT_VALUES.html#restrictions",
    "relUrl": "/reference/sql_plus_requests/UPSERT_VALUES/UPSERT_VALUES.html#restrictions"
  },"28": {
    "doc": "UPSERT VALUES",
    "title": "Пример",
    "content": "Вставка данных во все столбцы таблицы . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка трех записей в логическую таблицу sales UPSERT INTO sales VALUES (200011, '2021-08-21 23:34:10', 'ABC0001', 2, 123, 'Покупка по акции \"1+1\"'), (200012, '2021-08-22 10:05:56', 'ABC0001', 1, 234, 'Покупка без акций'), (200013, '2021-08-22 13:17:47', 'ABC0002', 4, 123, 'Покупка по акции \"Лето\"'); -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Вставка данных в указанные столбцы таблицы . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка двух записей в логическую таблицу sales (без опционального значения description) UPSERT INTO sales (id, transaction_date, product_code, product_units, store_id) VALUES (200014, '2021-08-23 09:34:10', 'ABC0003', 3, 123), (200012, '2021-08-23 20:05:56', 'ABC0001', 6, 234); -- закрытие дельты (фиксация изменений) COMMIT DELTA; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/UPSERT_VALUES/UPSERT_VALUES.html#examples",
    "relUrl": "/reference/sql_plus_requests/UPSERT_VALUES/UPSERT_VALUES.html#examples"
  },"29": {
    "doc": "Конфигурация",
    "title": "Конфигурация",
    "content": "Перед началом работы с системой необходимо настроить конфигурацию системы, а также конфигурацию используемых коннекторов. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/configuration.html",
    "relUrl": "/maintenance/configuration/configuration.html"
  },"30": {
    "doc": "Подключение",
    "title": "Подключение",
    "content": "Чтобы начать работать с системой, нужно подключиться к системе. Доступны следующие способы подключения: . | с помощью SQL-клиента, например DBeaver или DataGrip; | с помощью программного подключения. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/connection/connection.html",
    "relUrl": "/working_with_system/connection/connection.html"
  },"31": {
    "doc": "Программное подключение",
    "title": "Программное подключение",
    "content": "JDBC-драйвер системы позволяет подключаться программно (без использования SQL-клиента). Вы можете реализовать свое приложение, работающее с системой через JDBC-подключение. Чтобы подключиться к системе с помощью программного подключения: . | Загрузите скомпилированный файл драйвера с именем dtm-jdbc-&lt;version&gt;.jar. | Определите путь к jar-файлу драйвера любым из способов: . | задайте путь с помощью переменной окружения CLASSPATH; | задайте путь в командной строке при запуске своего приложения (формат зависит от операционной системы): java -classpath /&lt;path-to-driver&gt;/dtm-jdbc-&lt;version&gt;.jar myapplication.class . | . | В реализации класса вашего приложения, который отвечает за подключение к системе (см. пример ниже): . | импортируйте пакеты Java SQL: import java.sql.*; . | если используется Java версии менее 1.6, загрузите драйвер в память: Class.forName(\"ru.datamart.prostore.jdbc.Driver\"); . | установите соединение с системой с помощью метода DriverManager.getConnection() в следующем формате: String url = \"jdbc:prostore://DtmHost:portNumber/logicalDatabaseName\"; Connection conn = DriverManager.getConnection(url, null, null); . | . | . Строка url содержит параметры: . | DtmHost — IP-адрес или имя хоста, на котором установлена система; | portNumber — номер порта для подключения; | (опционально) logicalDatabaseName — имя логической базы данных, используемой по умолчанию. | . Пример url: . String url = \"jdbc:prostore://10.92.3.3:9092/demo\"; Connection conn = DriverManager.getConnection(url, null, null); . После установки соединения можно выполнять запросы SQL+. По окончании работы с системой нужно закрыть подключение. В примере ниже показана базовая реализация класса SimpleDtmJDBCExample, который устанавливает соединение с системой по заданному адресу и затем закрывает соединение. import java.sql.*; public class SimpleDtmJDBCExample { public static void main(String[] args) { Connection conn; String url = \"jdbc:prostore://10.92.3.3:9092/demo\"; try { conn = DriverManager.getConnection(url); System.out.println(\"Connected\"); } catch (SQLException e) { // Catch all for the SQL exceptions e.printStackTrace(); } finally { conn.close(); } } . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/connection/connection_via_code/connection_via_code.html",
    "relUrl": "/working_with_system/connection/connection_via_code/connection_via_code.html"
  },"32": {
    "doc": "Подключение с помощью SQL-клиента",
    "title": "Подключение с помощью SQL-клиента",
    "content": "Перед настройкой подключения загрузите скомпилированный файл драйвера с именем dtm-jdbc-&lt;version&gt;.jar в вашу файловую систему. Чтобы настроить подключение к системе с помощью SQL-клиента: . | Откройте меню, отвечающее за добавление новых JDBC-драйверов. В SQL-клиенте DBeaver это меню Driver Management, доступное в панели Database Navigator, в DataGrip — меню Data Sources. | Добавьте новый драйвер со следующими настройками (см. рисунок ниже): . | (Driver) Name — произвольное имя драйвера, например Prostore, | (Class) Name — ru.datamart.prostore.jdbc.Driver, | URL Template — jdbc:prostore://{host}:{port}/{database}, | Default Port (если параметр присутствует) — 9090 или 9092. | . | Нажмите кнопку Add (File) для добавления файла драйвера и выберите файл dtm-jdbc-&lt;version&gt;.jar в вашей файловой системе (см. рисунок ниже). | Сохраните настройки драйвера. | Настройте новое подключение к системе с использованием добавленного JDBC-драйвера и укажите URL для подключения (например, jdbc:prostore://10.129.0.18:9092). | . После завершения настройки подключитесь к системе с помощью SQL-клиента. На рисунках ниже показаны параметры JDBC-драйвера Prostore в SQL-клиенте DBeaver. Параметры JDBC-драйвера . Подключенная библиотека JDBC-драйвера . На рисунке ниже показаны параметры подключения к системе с использованием драйвера Prostore. Параметры подключения к системе . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/connection/connection_via_sql_client/connection_via_sql_client.html",
    "relUrl": "/working_with_system/connection/connection_via_sql_client/connection_via_sql_client.html"
  },"33": {
    "doc": "Конфигурация коннекторов",
    "title": "Конфигурация коннекторов",
    "content": "Содержание раздела . | Конфигурация коннектора Kafka-Clickhouse reader | Конфигурация коннектора Kafka-Clickhouse writer | Конфигурация коннектора Kafka-Postgres reader | Конфигурация коннектора Kafka-Postgres writer | . Следующие коннекторы требуют настройки конфигурации: . | Kafka-Clickhouse reader connector, | Kafka-Clickhouse writer connector, | Kafka-Postgres reader connector, | Kafka-Postgres writer connector. | . Ссылки на репозитории с исходным кодом коннекторов доступны в разделе Ресурсы. Конфигурация коннекторов задается в текстовых YAML-файлах; параметры конфигурации организованы в иерархическую древовидную структуру. В разделе приведены примеры файлов конфигурации коннекторов, где перед каждым параметром описано его назначение. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/connectors/connectors.html",
    "relUrl": "/maintenance/configuration/connectors/connectors.html"
  },"34": {
    "doc": "Конфигурация коннекторов",
    "title": "Конфигурация коннектора Kafka-Clickhouse reader",
    "content": "# настройки Vertx vertx: # признак кластеризованного режима Vertx clustered:true # настройки журналирования logging: level: # уровень важности сообщений, записываемых в лог-файл ru.datamart.kafka.clickhouse.reader: ${LOG_LEVEL:DEBUG} # настройки вертиклов Vertx verticle: worker: task-worker: # максимальный размер пула подключений веб-клиентов к ADQM poolSize: ${TASK_WORKER_POOL_SIZE:12} # имя пула подключений веб-клиентов к ADQM poolName: ${TASK_WORKER_POOL_NAME:task-worker} # внутренний таймаут обработки запросов (в миллисекундах) responseTimeoutMs: ${TASK_WORKER_RESPONSE_TIMEOUT_MS:86400000} # настройки HTTP-подключений http: # порт, на котором работает коннектор port: ${SERVER_PORT:8086} # временная зона коннектора timezone: ${MPPR_TIME_ZONE:UTC} # настройки для работы с ADQM datasource: clickhouse: # имя базы данных в ADQM database: ${CLICKHOUSE_DB_NAME:test1} # имя пользователя/логин для авторизации в ADQM user: ${CLICKHOUSE_USERNAME:default} # пароль для авторизации в ADQM password: ${CLICKHOUSE_PASS:} # сетевой адрес хоста с ADQM и номер порта на хосте hosts: ${CLICKHOUSE_HOSTS:clickhouse.host:8123} # максимальный размер результата, возвращаемого по FETCH-запросу к ADQM fetchSize: ${CLICKHOUSE_FETCH_SIZE:1000} # настройки для работы с брокером сообщений Kafka kafka: clickhouse: # настройки производителя данных producer: property: # сериализатор строковых ключей key.serializer: org.apache.kafka.common.serialization.ByteArraySerializer # сериализатор строковых значений value.serializer: org.apache.kafka.common.serialization.ByteArraySerializer # настройки кластера cluster: # сетевой адрес хоста Zookeeper для брокера сообщений Kafka zookeeperHosts: ${ZOOKEEPER_HOSTS:zk-1.dtm.local} # корневой путь к хосту Zookeeper для брокера сообщений Kafka rootPath: ${KAFKA_CLUSTER_ROOTPATH:arenadata/cluster/21} . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/connectors/connectors.html#adqm_reader",
    "relUrl": "/maintenance/configuration/connectors/connectors.html#adqm_reader"
  },"35": {
    "doc": "Конфигурация коннекторов",
    "title": "Конфигурация коннектора Kafka-Clickhouse writer",
    "content": "# настройки HTTP-подключений http: # порт, на котором работает коннектор port: ${SERVER_PORT:8090} # настройки для работы с брокером сообщений Kafka client: kafka: # настройки консьюмера (потребителя) Kafka consumer: # периодичность проверки (в миллисекундах) статуса брокера сообщений Kafka checkingTimeoutMs: ${KAFKA_CHECKING_TIMEOUT_MS:10000} # время ожидания (в миллисекундах) ответа брокера сообщений Kafka до тайм-аута responseTimeoutMs: ${KAFKA_RESPONSE_TIMEOUT_MS:10000} # количество консьюмеров Kafka consumerSize: ${KAFKA_CONSUMER_SIZE:10} # время ожидания (в миллисекундах) до закрытия соединения с брокером сообщений Kafka closeConsumersTimeout: ${KAFKA_CLOSE_CONSUMER_TIMEOUT:15000} # свойства консьюмера в соответствии с конфигурацией консьюмеров Kafka (https://kafka.apache.org/documentation/#consumerconfigs) property: # список адресов и портов Bootstrap-серверов брокера сообщений Kafka bootstrap.servers: ${KAFKA_BOOTSTRAP_SERVERS:kafka.host:9092} # имя консьюмер-группы для загрузки данных в ADQM group.id: ${KAFKA_CONSUMER_GROUP_ID:clickhouse-query-execution} # режим обнуления смещения в топиках Kafka auto.offset.reset: ${KAFKA_AUTO_OFFSET_RESET:earliest} # признак автоматической записи смещения в топиках Kafka enable.auto.commit: ${KAFKA_AUTO_COMMIT:false} # периодичность (в миллисекундах) автоматической записи смещения в топиках Kafka auto.commit.interval.ms: ${KAFKA_AUTO_INTERVAL_MS:1000} # настройки окружения env: # имя окружения name: ${ENV:test} # настройки, связанные с системными полями datamart: # системное поле, хранящее номер операции записи hot-delta-field-name: sys_from # настройки для работы с ADQM datasource: clickhouse: # имя базы данных в ADQM database: ${CLICKHOUSE_DB_NAME:test1} # имя пользователя/логин для авторизации в ADQM user: ${CLICKHOUSE_USERNAME:default} # пароль для авторизации в ADQM password: ${CLICKHOUSE_PASS:} # список хостов ADQM (адрес:порт через запятую) hosts: ${CLICKHOUSE_HOSTS:clockhouse.host:8123} # настройки VertX verticle: worker: # настройки компонента, обрабатывающего запросы new-data-worker: # максимальный размер пула потоков poolSize: ${DATA_WORKER_POOL_SIZE:20} # имя пула потоков poolName: ${DATA_WORKER_POOL_NAME:new-data-worker} # настройки компонента, обрабатывающего полученные данные task-worker: # максимальный размер пула потоков poolSize: ${TASK_WORKER_POOL_SIZE:12} # имя пула потоков poolName: ${TASK_WORKER_POOL_NAME:task-worker} # внутренний таймаут обработки полученных данных (в миллисекундах) responseTimeoutMs: ${TASK_WORKER_RESPONSE_TIMEOUT_MS:86400000} # настройки компонента, выполняющего вставку данных insert-worker: # максимальный размер пула потоков poolSize: ${INSERT_WORKER_POOL_SIZE:32} # имя пула потоков poolName: ${INSERT_WORKER_POOL_NAME:insert-worker} # внутренний таймаут обработки вставки данных (в миллисекундах) responseTimeoutMs: ${INSERT_WORKER_RESPONSE_TIMEOUT_MS:86400000} # периодичность вставки данных (в миллисекундах) insertPeriodMs: ${INSERT_PERIOD_MS:1000} # размер пакета операций при вставке данных batchSize: ${INSERT_BATCH_SIZE:500} # настройки компонента, считывающего данные их топиков Kafka kafka-consumer-worker: # максимальный размер пула потоков poolSize: ${KAFKA_CONSUMER_WORKER_POOL_SIZE:32} # имя пула потоков poolName: ${KAFKA_CONSUMER_WORKER_POOL_NAME:insert-worker} # внутренний таймаут обработки консьюмера данных (в миллисекундах) responseTimeoutMs: ${KAFKA_CONSUMER_WORKER_RESPONSE_TIMEOUT_MS:86400000} # максимальный размер результата, возвращаемого по FETCH-запросу к ADQM maxFetchSize: ${KAFKA_CONSUMER_MAX_FETCH_SIZE:10000} # настройки компонента, записывающего смещение в топиках Kafka kafka-commit-worker: # максимальный размер пула потоков poolSize: ${KAFKA_COMMIT_WORKER_POOL_SIZE:1} # имя пула потоков poolName: ${KAFKA_COMMIT_WORKER_POOL_NAME:commit-worker} # периодичность записи смещения в топиках Kafka (в миллисекундах) commitPeriodMs: ${KAFKA_COMMIT_WORKER_COMMIT_PERIOD_MS:1000} # настройки журналирования logging: level: # уровень важности сообщений, записываемых в лог-файл ru.datamart.prostore: DEBUG # уровень важности сообщений, записываемых в лог-файл по событиям Kafka org.apache.kafka: INFO . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/connectors/connectors.html#adqm_writer",
    "relUrl": "/maintenance/configuration/connectors/connectors.html#adqm_writer"
  },"36": {
    "doc": "Конфигурация коннекторов",
    "title": "Конфигурация коннектора Kafka-Postgres reader",
    "content": "# настройки журналирования logging: level: # уровень важности сообщений, записываемых в лог-файл ru.datamart.kafka: ${LOG_LEVEL:DEBUG} # уровень важности сообщений, записываемых в лог-файл по событиям Kafka org.apache.kafka: ${KAFKA_LOG_LEVEL:INFO} # настройки HTTP-подключений http: # порт, на котором работает коннектор port: ${SERVER_PORT:8094} # настройки дла работы с Vertx vertx: pools: # максимальный размер пула потоков, обрабатывающих события Vertx eventLoopPoolSize: ${VERTX_EVENT_LOOP_SIZE:12} # максимальный размер пула потоков, выполняющих долгие операции workersPoolSize: ${VERTX_WORKERS_POOL_SIZE:32} verticle: query: # количество экземпляров, принимающих запросы instances: ${QUERY_VERTICLE_INSTANCES:12} # настройки для работы с ADP datasource: postgres: # имя базы данных ADP database: ${POSTGRES_DB_NAME:db} # имя пользователя/логин для авторизации в ADP user: ${POSTGRES_USERNAME:user} # пароль для авторизации в ADP password: ${POSTGRES_PASS:password} # сетевой адрес хоста с ADP и номер порта на хосте hosts: ${POSTGRES_HOSTS:postgres.host:5432} # максимальный размер пула потоков poolSize: ${POSTGRES_POOLSIZE:10} # максимальный размер кэша запроса prepared statement preparedStatementsCacheMaxSize: ${POSTGRES_CACHE_MAX_SIZE:256} # максимальный размер запроса prepared statement, который может быть закэширован preparedStatementsCacheSqlLimit: ${POSTGRES_CACHE_SQL_LIMIT:2048} # признак кэширования запросов prepared statement preparedStatementsCache: ${POSTGRES_CACHE:true} # максимальный размер результата, возвращаемого по FETCH-запросу к ADP fetchSize: ${POSTGRES_FETCH_SIZE:1000} # настройки для работы с брокером сообщений Kafka kafka: client: property: # сериализатор строковых ключей key.serializer: org.apache.kafka.common.serialization.ByteArraySerializer # сериализатор строковых значений value.serializer: org.apache.kafka.common.serialization.ByteArraySerializer . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/connectors/connectors.html#adp_reader",
    "relUrl": "/maintenance/configuration/connectors/connectors.html#adp_reader"
  },"37": {
    "doc": "Конфигурация коннекторов",
    "title": "Конфигурация коннектора Kafka-Postgres writer",
    "content": "# настройки журналирования logging: level: # уровень важности сообщений, записываемых в лог-файл ru.datamart.kafka: ${LOG_LEVEL:DEBUG} # уровень важности сообщений, записываемых в лог-файл по событиям Kafka org.apache.kafka: ${KAFKA_LOG_LEVEL:INFO} # настройки HTTP-подключений http: # порт, на котором работает коннектор port: ${SERVER_PORT:8096} # настройки для работы с Vertx vertx: pools: # максимальный размер пула потоков, обрабатывающих события Vertx eventLoopPoolSize: ${VERTX_EVENT_LOOP_SIZE:12} # максимальный размер пула потоков, выполняющих долгие операции workersPoolSize: ${VERTX_WORKERS_POOL_SIZE:32} verticle: query: # количество экземпляров вертиклов, обрабатывающих запросы instances: ${QUERY_VERTICLE_INSTANCES:12} insert: # максимальный размер пула потоков, вставляющих данные poolSize: ${INSERT_WORKER_POOL_SIZE:32} # периодичность вставки новых данных (в миллисекундах) insertPeriodMs: ${INSERT_PERIOD_MS:1000} # размер пакета операций при вставке данных batchSize: ${INSERT_BATCH_SIZE:500} consumer: # максимальный размер пула потоков, считывающих данные poolSize: ${KAFKA_CONSUMER_WORKER_POOL_SIZE:32} # максимальный размер результата, возвращаемого по FETCH-запросу к ADP maxFetchSize: ${KAFKA_CONSUMER_MAX_FETCH_SIZE:10000} commit: # размер пула потоков, записывающих смещение в топиках Kafka poolSize: ${KAFKA_COMMIT_WORKER_POOL_SIZE:1} # периодичность записи смещения в топиках Kafka (в миллисекундах) commitPeriodMs: ${KAFKA_COMMIT_WORKER_COMMIT_PERIOD_MS:1000} # настройки для работы с брокером сообщений Kafka client: kafka: # настройки консьюмера (потребителя) Kafka consumer: # периодичность проверки (в миллисекундах) статуса брокера сообщений Kafka checkingTimeoutMs: ${KAFKA_CHECKING_TIMEOUT_MS:10000} # время ожидания (в миллисекундах) ответа от брокера сообщений Kafka до тайм-аута responseTimeoutMs: ${KAFKA_RESPONSE_TIMEOUT_MS:10000} # количество консьюмеров Kafka consumerSize: ${KAFKA_CONSUMER_SIZE:10} # время ожидания (в миллисекундах) до закрытия соединения с брокером сообщений Kafka closeConsumersTimeout: ${KAFKA_CLOSE_CONSUMER_TIMEOUT:15000} # свойства консьюмера в соответствии с конфигурацией консьюмеров Kafka (https://kafka.apache.org/documentation/#consumerconfigs) property: # список адресов и портов Bootstrap-серверов брокера сообщений Kafka bootstrap.servers: ${KAFKA_BOOTSTRAP_SERVERS:kafka.host:9092} # имя консьюмер-группы для загрузки данных в ADP group.id: ${KAFKA_CONSUMER_GROUP_ID:postgres-query-execution} # режим обнуления смещения в топиках Kafka auto.offset.reset: ${KAFKA_AUTO_OFFSET_RESET:earliest} # признак автоматической записи смещения в топиках Kafka enable.auto.commit: ${KAFKA_AUTO_COMMIT:false} # периодичность (в миллисекундах) автоматической записи смещения в топиках Kafka auto.commit.interval.ms: ${KAFKA_AUTO_INTERVAL_MS:1000} # настройки для работы с ADP datasource: postgres: # имя базы данных ADP database: ${POSTGRES_DB_NAME:db} # имя пользователя/логин для авторизации в ADP user: ${POSTGRES_USERNAME:user} # пароль для авторизации в ADP password: ${POSTGRES_PASS:password} # сетевой адрес хоста с ADP и номер порта на хосте hosts: ${POSTGRES_HOSTS:postgres.host:5432} # максимальный размер пула потоков poolSize: ${POSTGRES_POOLSIZE:10} # максимальный размер кэша запроса prepared statement preparedStatementsCacheMaxSize: ${POSTGRES_CACHE_MAX_SIZE:256} # максимальный размер запроса prepared statement, который может быть закэширован preparedStatementsCacheSqlLimit: ${POSTGRES_CACHE_SQL_LIMIT:2048} # признак кэширования запросов prepared statement preparedStatementsCache: ${POSTGRES_CACHE:true} . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/connectors/connectors.html#adp_writer",
    "relUrl": "/maintenance/configuration/connectors/connectors.html#adp_writer"
  },"38": {
    "doc": "Сборка и развёртывание",
    "title": "Сборка и развёртывание",
    "content": "Содержание раздела . | Предустановленные программные средства | Сборка Prostore | Настройка СУБД Postgres | Сборка и установка коннектора Kafka-Postgres | Запуск сервисов Apache Zookeeper и Apache Kafka | Запуск коннектора Kafka-Postgres | Запуск службы dtm-status-monitor | Запуск Prostore | Подключение к Prostore с помощью SQL-клиента | Демонстрационный сценарий . | Создание необходимых логических сущностей | Создание топика Kafka для последующей загрузки данных | Создание бинарного avro-файла kafka_upload_sales.avro из avro-схемы и данных | Загрузка avro-файла kafka_upload_sales.avro | Загрузка данных | Вставка данных | Выборка данных | Выгрузка в топик Kafka | Удаление логических сущностей | . | . В этом разделе описаны шаги по развёртыванию среды в конфигурации, предполагающей единственное хранилище — СУБД PostgreSQL. Дополнительная информация приведена в разделе Схемы развёртывания. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html",
    "relUrl": "/getting_started/getting_started.html"
  },"39": {
    "doc": "Сборка и развёртывание",
    "title": "Предустановленные программные средства",
    "content": ". | OC Centos 7; | yum-utils; | curl; | git; | wget; | OpenJDK 8; | Apache Maven 3.6.3; | СУБД PostgreSQL 13; | Apache Zookeeper; | Apache Kafka (например, в каталоге /opt/kafka); | SQL-клиент, например DBeaver; | docker; | Браузер топиков Kafka с возможностью загрузки бинарных данных, например kafkacat. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#preinstalled_software",
    "relUrl": "/getting_started/getting_started.html#preinstalled_software"
  },"40": {
    "doc": "Сборка и развёртывание",
    "title": "Сборка Prostore",
    "content": "# клонирование репозитория Prostore git clone https://github.com/datamarts/prostore ~/prostore # запуск сборки Prostore средствами Apache Maven cd ~/prostore mvn clean install -DskipTests=true # создание символической ссылки на файл конфигурации sudo ln -s ~/prostore/dtm-query-execution-core/config/application.yml ~/prostore/dtm-query-execution-core/target/application.yml # приведение конфигурационного файла к виду, показанному ниже sudo nano ~/prostore/dtm-query-execution-core/config/application.yml . конфигурационный файл Prostore `application.yml` # # Copyright © 2021 ProStore # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # logging: level: ru.datamart.prostore.query.execution: ${DTM_LOGGING_LEVEL:TRACE} server: port: ${DTM_METRICS_PORT:8080} management: endpoints: enabled-by-default: ${DTM_METRICS_ENABLED:true} web: exposure: include: ${DTM_METRICS_SCOPE:info, health, requests} core: plugins: active: ${CORE_PLUGINS_ACTIVE:ADP} http: port: ${DTM_CORE_HTTP_PORT:9090} tcpNoDelay: ${DTM_CORE_HTTP_TCP_NO_DELAY:true} tcpFastOpen: ${DTM_CORE_HTTP_TCP_FAST_OPEN:true} tcpQuickAck: ${DTM_CORE_HTTP_TCP_QUICK_ACK:true} env: name: ${DTM_NAME:test} restoration: autoRestoreState: ${AUTO_RESTORE_STATE:true} matviewsync: periodMs: ${MATERIALIZED_VIEWS_SYNC_PERIOD_MS:5000} retryCount: ${MATERIALIZED_VIEWS_RETRY_COUNT:10} maxConcurrent: ${MATERIALIZED_VIEWS_CONCURRENT:2} metrics: enabled: ${DTM_CORE_METRICS_ENABLED:true} datasource: edml: defaultChunkSize: ${EDML_DEFAULT_CHUNK_SIZE:1000} pluginStatusCheckPeriodMs: ${EDML_STATUS_CHECK_PERIOD_MS:1000} firstOffsetTimeoutMs: ${EDML_FIRST_OFFSET_TIMEOUT_MS:15000} changeOffsetTimeoutMs: ${EDML_CHANGE_OFFSET_TIMEOUT_MS:10000} zookeeper: connection-string: ${ZOOKEEPER_DS_ADDRESS:localhost} connection-timeout-ms: ${ZOOKEEPER_DS_CONNECTION_TIMEOUT_MS:30000} session-timeout-ms: ${ZOOKEEPER_DS_SESSION_TIMEOUT_MS:86400000} chroot: ${ZOOKEEPER_DS_CHROOT:/adtm} kafka: producer: property: key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer cluster: zookeeper: connection-string: ${ZOOKEEPER_KAFKA_ADDRESS:localhost} connection-timeout-ms: ${ZOOKEEPER_KAFKA_CONNECTION_TIMEOUT_MS:30000} session-timeout-ms: ${ZOOKEEPER_KAFKA_SESSION_TIMEOUT_MS:86400000} chroot: ${ZOOKEEPER_KAFKA_CHROOT:} admin: inputStreamTimeoutMs: ${KAFKA_INPUT_STREAM_TIMEOUT_MS:2000} status.event.publish: enabled: ${KAFKA_STATUS_EVENT_ENABLED:false} statusMonitor: statusUrl: ${STATUS_MONITOR_URL:http://localhost:9095/status} versionUrl: ${STATUS_MONITOR_VERSION_URL:http://localhost:9095/versions} vertx: blocking-stacktrace-time: ${DTM_VERTX_BLOCKING_STACKTRACE_TIME:1} pool: worker-pool: ${DTM_CORE_WORKER_POOL_SIZE:20} event-loop-pool: ${DTM_CORE_EVENT_LOOP_POOL_SIZE:20} task-pool: ${DTM_CORE_TASK_POOL_SIZE:20} task-timeout: ${DTM_CORE_TASK_TIMEOUT:86400000} cache: initialCapacity: ${CACHE_INITIAL_CAPACITY:100000} maximumSize: ${CACHE_MAXIMUM_SIZE:100000} expireAfterAccessMinutes: ${CACHE_EXPIRE_AFTER_ACCESS_MINUTES:99960} delta: rollback-status-calls-ms: ${DELTA_ROLLBACK_STATUS_CALLS_MS:2000} adp: datasource: user: ${ADP_USERNAME:dtm} password: ${ADP_PASS:dtm} host: ${ADP_HOST:localhost} port: ${ADP_PORT:5432} poolSize: ${ADP_MAX_POOL_SIZE:3} executorsCount: ${ADP_EXECUTORS_COUNT:3} fetchSize: ${ADP_FETCH_SIZE:1000} preparedStatementsCacheMaxSize: ${ADP_PREPARED_CACHE_MAX_SIZE:256} preparedStatementsCacheSqlLimit: ${ADP_PREPARED_CACHE_SQL_LIMIT:2048} preparedStatementsCache: ${ADP_PREPARED_CACHE:true} mppw: restStartLoadUrl: ${ADP_REST_START_LOAD_URL:http://localhost:8096/newdata/start} restStopLoadUrl: ${ADP_REST_STOP_LOAD_URL:http://localhost:8096/newdata/stop} restVersionUrl: ${ADP_MPPW_CONNECTOR_VERSION_URL:http://localhost:8096/versions} kafkaConsumerGroup: ${ADP_KAFKA_CONSUMER_GROUP:adp-load} mppr: restLoadUrl: ${ADP_MPPR_QUERY_URL:http://localhost:8094/query} restVersionUrl: ${ADP_MPPR_CONNECTOR_VERSION_URL:http://localhost:8094/versions} . Далее конфигурационный файл application.yml обозначается термином “конфигурация Prostore”. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#prostore_build",
    "relUrl": "/getting_started/getting_started.html#prostore_build"
  },"41": {
    "doc": "Сборка и развёртывание",
    "title": "Настройка СУБД Postgres",
    "content": "# создание в СУБД Postgres SUPERUSER-пользователя c именем и паролем, # указанными в конфигурации Prostore # (значения параметров (adp:datasource:user) и (adp:datasource:password) соответственно) cd / sudo -u postgres psql -c 'CREATE ROLE dtm WITH LOGIN SUPERUSER' sudo -u postgres psql -c \"ALTER ROLE dtm WITH PASSWORD 'dtm'\" # создание базы данных с именем test, указанным в конфигурации Prostore (env: name) sudo -u postgres psql -c 'CREATE DATABASE test' # перезапуск сервиса Postgresql sudo systemctl reload postgresql-13 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#postgres_setup",
    "relUrl": "/getting_started/getting_started.html#postgres_setup"
  },"42": {
    "doc": "Сборка и развёртывание",
    "title": "Сборка и установка коннектора Kafka-Postgres",
    "content": "# клонирование репозитория kafka-postgres-connector git clone https://github.com/datamarts/kafka-postgres-connector ~/kafka-postgres-connector # запуск сборки коннектора kafka-postgres средствами Apache Maven cd ~/kafka-postgres-connector mvn clean install -DskipTests=true # приведение конфигурационных файлов kafka-postgres-writer и kafka-postgres-reader к виду, # показанному ниже, чтобы значения параметров совпадали со значениями соответствующих параметров конфигурации Prostore # datasource: postgres: database ~ env: name, # datasource: postgres: user ~ adp: datasource: user, # datasource: postgres: password ~ adp: datasource: password, # datasource: postgres: hosts ~ adp: datasource: host, adp: datasource: port sudo nano ~/kafka-postgres-connector/kafka-postgres-writer/src/main/resources/application.yml sudo nano ~/kafka-postgres-connector/kafka-postgres-reader/src/main/resources/application.yml # создание символических ссылок на файлы конфигурации sudo ln -s ~/kafka-postgres-connector/kafka-postrges-writer/src/main/resources/application.yml ~/kafka-postgres-connector/kafka-postrges-writer/target/application.yml sudo ln -s ~/kafka-postgres-connector/kafka-postrges-reader/src/main/resources/application.yml ~/kafka-postgres-connector/kafka-postrges-reader/target/application.yml . конфигурационный файл kafka-postgres-writer `application.yml` logging: level: ru.datamart.kafka: ${LOG_LEVEL:DEBUG} org.apache.kafka: ${KAFKA_LOG_LEVEL:INFO} http: port: ${SERVER_PORT:8096} vertx: pools: eventLoopPoolSize: ${VERTX_EVENT_LOOP_SIZE:12} workersPoolSize: ${VERTX_WORKERS_POOL_SIZE:32} verticle: query: instances: ${QUERY_VERTICLE_INSTANCES:12} insert: poolSize: ${INSERT_WORKER_POOL_SIZE:32} insertPeriodMs: ${INSERT_PERIOD_MS:1000} batchSize: ${INSERT_BATCH_SIZE:500} consumer: poolSize: ${KAFKA_CONSUMER_WORKER_POOL_SIZE:32} maxFetchSize: ${KAFKA_CONSUMER_MAX_FETCH_SIZE:10000} commit: poolSize: ${KAFKA_COMMIT_WORKER_POOL_SIZE:1} commitPeriodMs: ${KAFKA_COMMIT_WORKER_COMMIT_PERIOD_MS:1000} client: kafka: consumer: checkingTimeoutMs: ${KAFKA_CHECKING_TIMEOUT_MS:10000} responseTimeoutMs: ${KAFKA_RESPONSE_TIMEOUT_MS:10000} consumerSize: ${KAFKA_CONSUMER_SIZE:10} closeConsumersTimeout: ${KAFKA_CLOSE_CONSUMER_TIMEOUT:15000} property: bootstrap.servers: ${KAFKA_BOOTSTRAP_SERVERS:kafka.host:9092} group.id: ${KAFKA_CONSUMER_GROUP_ID:postgres-query-execution} auto.offset.reset: ${KAFKA_AUTO_OFFSET_RESET:earliest} enable.auto.commit: ${KAFKA_AUTO_COMMIT:false} auto.commit.interval.ms: ${KAFKA_AUTO_INTERVAL_MS:1000} datasource: postgres: database: ${POSTGRES_DB_NAME:test} user: ${POSTGRES_USERNAME:dtm} password: ${POSTGRES_PASS:dtm} hosts: ${POSTGRES_HOSTS:localhost:5432} poolSize: ${POSTGRES_POOLSIZE:10} preparedStatementsCacheMaxSize: ${POSTGRES_CACHE_MAX_SIZE:256} preparedStatementsCacheSqlLimit: ${POSTGRES_CACHE_SQL_LIMIT:2048} preparedStatementsCache: ${POSTGRES_CACHE:true} . конфигурационный файл kafka-postgres-reader `application.yml` logging: level: ru.datamart.kafka: ${LOG_LEVEL:DEBUG} org.apache.kafka: ${KAFKA_LOG_LEVEL:INFO} http: port: ${SERVER_PORT:8094} vertx: pools: eventLoopPoolSize: ${VERTX_EVENT_LOOP_SIZE:12} workersPoolSize: ${VERTX_WORKERS_POOL_SIZE:32} verticle: query: instances: ${QUERY_VERTICLE_INSTANCES:12} datasource: postgres: database: ${POSTGRES_DB_NAME:test} user: ${POSTGRES_USERNAME:dtm} password: ${POSTGRES_PASS:dtm} hosts: ${POSTGRES_HOSTS:localhost:5432} poolSize: ${POSTGRES_POOLSIZE:10} preparedStatementsCacheMaxSize: ${POSTGRES_CACHE_MAX_SIZE:256} preparedStatementsCacheSqlLimit: ${POSTGRES_CACHE_SQL_LIMIT:2048} preparedStatementsCache: ${POSTGRES_CACHE:true} fetchSize: ${POSTGRES_FETCH_SIZE:1000} kafka: client: property: key.serializer: org.apache.kafka.common.serialization.ByteArraySerializer value.serializer: org.apache.kafka.common.serialization.ByteArraySerializer . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#kafka_postgres_connector_build_deploy",
    "relUrl": "/getting_started/getting_started.html#kafka_postgres_connector_build_deploy"
  },"43": {
    "doc": "Сборка и развёртывание",
    "title": "Запуск сервисов Apache Zookeeper и Apache Kafka",
    "content": "# запуск одного экземпляра сервера ZooKeeper, если он еще не запущен sudo systemctl start zookeeper # запуск сервера Kafka и проверка его состояния sudo systemctl start kafka sudo systemctl status kafka . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#zookeeper_kafka_execution",
    "relUrl": "/getting_started/getting_started.html#zookeeper_kafka_execution"
  },"44": {
    "doc": "Сборка и развёртывание",
    "title": "Запуск коннектора Kafka-Postgres",
    "content": "# запуск kafka-postgres-writer в отдельном окне терминала cd ~/kafka-postgres-connector/kafka-postgres-writer/target java -jar kafka-postgres-writer-&lt;version&gt;.jar # запуск kafka-postgres-reader в отдельном окне терминала cd ~/kafka-postgres-connector/kafka-postgres-reader/target java -jar kafka-postgres-reader-&lt;version&gt;.jar . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#kafka_postgres_execution",
    "relUrl": "/getting_started/getting_started.html#kafka_postgres_execution"
  },"45": {
    "doc": "Сборка и развёртывание",
    "title": "Запуск службы dtm-status-monitor",
    "content": "# создание символической ссылки на файл конфигурации dtm-status-monitor sudo ln -s ~/prostore/dtm-status-monitor/src/main/resources/application.yml ~/prostore/dtm-status-monitor/target/application.yml # запуск dtm-status-monitor в отдельном окне терминала с указанием порта, заданного в конфигурации Prostore (core:kafka:statusMonitor) cd ~/prostore/dtm-status-monitor/target java -Dserver.port=9095 -jar dtm-status-monitor-&lt;version&gt;.jar . Примечание: Запуск службы dtm-status-monitor без указания порта -Dserver.port приведёт к конкуренции с сервисом Prostore за использование последним порта по умолчанию 8080. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#dtm_status_monitor_execution",
    "relUrl": "/getting_started/getting_started.html#dtm_status_monitor_execution"
  },"46": {
    "doc": "Сборка и развёртывание",
    "title": "Запуск Prostore",
    "content": "Запуск со значением по умолчанию (8080) для порта (server:port) в конфигурации Prostore: . # запуск файла dtm-query-execution-core-&lt;version&gt;.jar (например, dtm-query-execution-core-5.1.0.jar) cd ~/prostore/dtm-query-execution-core/target java -jar dtm-query-execution-core-&lt;version&gt;.jar . Запуск с иным заданным значением осуществляется путём изменения параметра (server:port) в конфигурации Prostore или задании переменной окружения . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#prostore_execution",
    "relUrl": "/getting_started/getting_started.html#prostore_execution"
  },"47": {
    "doc": "Сборка и развёртывание",
    "title": "Подключение к Prostore с помощью SQL-клиента",
    "content": "Порядок подключения описан в разделе Подключение с помощью SQL-клиента. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#sql_client_connection",
    "relUrl": "/getting_started/getting_started.html#sql_client_connection"
  },"48": {
    "doc": "Сборка и развёртывание",
    "title": "Демонстрационный сценарий",
    "content": "Создание необходимых логических сущностей . -- создание логической базы данных CREATE DATABASE marketing; -- выбор логической БД по умолчанию USE marketing; -- создание логической таблицы в БД marketing CREATE TABLE sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id); -- создание внешней таблицы загрузки CREATE UPLOAD EXTERNAL TABLE sales_ext_upload ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://localhost:2181/salesTopic' FORMAT 'AVRO' MESSAGE_LIMIT 1000; -- создание логического представления stores_by_sold_products CREATE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 30; -- создание внешней таблицы выгрузки в топик Kafka \"salesTopicOut\" CREATE DOWNLOAD EXTERNAL TABLE sales_ext_download ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://localhost:2181/salesTopicOut' FORMAT 'AVRO' CHUNK_SIZE 1000; . Создание топика Kafka для последующей загрузки данных . Создание топика Kafka “salesTopic” в терминале: . cd /opt/kafka/bin bash kafka-topics.sh --create --replication-factor 1 --partitions 1 --topic salesTopic --zookeeper localhost:2181 . Создание бинарного avro-файла kafka_upload_sales.avro из avro-схемы и данных . JSON-файл avro-схемы `kafka_upload_sales.avsc` { \"name\": \"sales\", \"namespace\": \"sales\", \"type\": \"record\", \"fields\": [ { \"name\": \"id\", \"type\": \"long\" }, { \"name\": \"transaction_date\", \"type\": { \"type\": \"long\", \"logicalType\": \"timestamp-micros\" } }, { \"name\": \"product_code\", \"type\": \"string\" }, { \"name\": \"product_units\", \"type\": \"long\" }, { \"name\": \"store_id\", \"type\": \"long\" }, { \"name\": \"description\", \"type\": \"string\" }, { \"name\": \"sys_op\", \"type\": \"int\" } ] } . JSON-файл данных `kafka_upload_sales.json` { \"id\": 1000111, \"transaction_date\": 1614269474000000, \"product_code\": \"ABC102101\", \"product_units\": 2, \"store_id\": 1000012345, \"description\": \"Покупка по акции 1+1\", \"sys_op\": 0 } { \"id\": 1000112, \"transaction_date\": 1614334214000000, \"product_code\": \"ABC102001\", \"product_units\": 1, \"store_id\": 1000000123, \"description\": \"Покупка без акций\", \"sys_op\": 0 } { \"id\": 1000020, \"transaction_date\": 1614636614000000, \"product_code\": \"ABC102010\", \"product_units\": 4, \"store_id\": 1000000123, \"description\": \"Покупка по акции 1+1\", \"sys_op\": 0 } . бинарный AVRO-файл `kafka_upload_sales.avro` Сохранить бинарный файл . Загрузка avro-файла kafka_upload_sales.avro . Загрузка avro-файла kafka_upload_sales.avro в топик Kafka “salesTopic” через терминал с помощью kafkacat: . #получение docker-образа kafkacat sudo docker pull edenhill/kcat:1.7.0 #запуск docker-образа kafkacat для загрузки в топик salesTopic #avro-файла /opt/kafka/sales/kafka_upload_sales.avro sudo docker run -it --network host \\ --volume /opt/kafka/sales/kafka_upload_sales.avro:/data/kafka_upload_sales.avro \\ edenhill/kcat:1.7.0 -b localhost:9092 -t salesTopic -P /data/kafka_upload_sales.avro . Загрузка данных . -- открытие новой (горячей) дельты BEGIN DELTA; -- запуск загрузки данных в логическую таблицу sales INSERT INTO sales SELECT * FROM sales_ext_upload; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Вставка данных . -- открытие новой (горячей) дельты BEGIN DELTA; -- запуск вставки данных в логическую таблицу sales INSERT INTO sales (id, transaction_date, product_code, product_units, store_id, description) VALUES (2000111, '2020-05-01 13:14:16', 'ABC202010', 7, 1000000123, 'Покупка без акций'), (2000112, '2020-05-02 16:13:17', 'ABC202011', 11, 1000000456, 'Покупка без акций'), (2000113, '2020-05-03 21:15:17', 'ABC202012', 5, 1000000789, 'Покупка без акций'), (2000114, '2020-05-04 23:03:13', 'ABC202013', 7, 1000000123, 'Покупка без акций'), (2000115, '2020-05-05 14:10:21', 'ABC202014', 21, 1000000623, 'Покупка без акций'), (2000116, '2020-06-12 08:43:56', 'ABC202015', 32, 1000000987, 'Покупка без акций'); -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Выборка данных . -- запрос с неявным указанием столбцов и ключевым словом WHERE SELECT * FROM sales WHERE store_id = 1000000123; -- запрос с агрегацией, группировкой и сортировкой данных, а также выбором первых 5 строк SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC LIMIT 5; -- запрос к логическому представлению stores_by_sold_products SELECT * FROM stores_by_sold_products; . Выгрузка в топик Kafka . -- запуск выгрузки данных из логической таблицы sales INSERT INTO sales_ext_download SELECT * FROM sales WHERE product_units &gt; 2; . Удаление логических сущностей . -- удаление внешней таблицы загрузки DROP UPLOAD EXTERNAL TABLE sales_ext_upload; -- удаление внешней таблицы выгрузки DROP DOWNLOAD EXTERNAL TABLE sales_ext_download; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/getting_started/getting_started.html#demo_scenario",
    "relUrl": "/getting_started/getting_started.html#demo_scenario"
  },"49": {
    "doc": "Логические типы данных",
    "title": "Логические типы данных",
    "content": "Система поддерживает логические типы данных, описанные в таблице ниже. Для каждого из них в таблице указаны соответствующие физические типы данных СУБД хранилища. При работе с логическими базами данных и их объектами нужно указывать логические типы данных. Физические типы данных описаны в справочных целях. | Логическийтип | Описание  | Тип данныхADB | Тип данныхADG | Тип данныхADQM | Тип данныхADP | . | BOOLEAN | Логический (булевый) тип | boolean | boolean | UInt8 | boolean | . | VARCHAR [(n)] | Строка ограниченной длины (n символов); размерность строки опциональна | varchar [(n)] | string | String | varchar (n) | . | LINK | Строка неограниченной длины. Предназначена для ссылочных полей | varchar | string | String | varchar | . | CHAR (n) | Строка ограниченной длины (n символов); размерность строки обязательна | varchar (n) | string | String | varchar (n) | . | UUID | Строка ограниченной длины (36 символов) | varchar (36) | string | String | varchar (36) | . | BIGINT | Целое число фиксированной длины со знаком, находящееся в диапазоне от -2^63&lt;/sup&gt; до 2^63-1 | bigint (int8) | integer | Int64 | bigint (int8) | . | INT | Целое число фиксированной длины со знаком, находящееся в диапазоне от -2^63 до 2^63-1 | bigint (int8) | integer | Int64 | bigint (int8) | . | INT32 | Целое число фиксированной длины со знаком, находящееся в диапазоне от -2147483648 до 2147483647 | integer (int4) | integer | Int32 | integer (int4) | . | DOUBLE | Число с плавающей запятой с двойной точностью | double precision (float8) | number | Float64 | double precision (float8) | . | FLOAT | Число с плавающей запятой | real (float4) | number | Float32 | real (float4) | . | DATE | Дата (без времени суток) | date | integer (знаковое число дней относительно даты 1970-01-01) | Int64 (знаковое число дней относительно даты 1970-01-01) | date | . | TIME, TIME (precision) | Время (без даты). Заданная точность (precision) влияет только на отображение времени. Возможные значения: от 0 до 6. Значение 0 соответствует секундам, значение 6 — микросекундам. Значение по умолчанию — 6. Количество микросекунд находится в диапазоне от 0 до 86399999999 | time (6) | integer (знаковое число микросекунд, начиная с 00:00:00.000000) | Int64 (знаковое число микросекунд, начиная с 00:00:00.000000) | time (6) | . | TIMESTAMP, TIMESTAMP (precision) | Дата и время. Заданная точность (precision) влияет только на отображение даты и времени. Возможные значения: от 0 до 6. Значение 0 соответствует секундам, значение 6 — микросекундам. Значение по умолчанию — 6 | timestamp (6) | integer (знаковое число микросекунд относительно 1970-01-01 00:00:00) | Int64 (знаковое число микросекунд относительно 1970-01-01 00:00:00) | timestamp (6) | . -263 = -9223372036854775808 263-1 = 9223372036854775807 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/supported_data_types/logical_data_types/logical_data_types.html",
    "relUrl": "/reference/supported_data_types/logical_data_types/logical_data_types.html"
  },"50": {
    "doc": "Эксплуатация",
    "title": "Эксплуатация",
    "content": " ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/maintenance.html",
    "relUrl": "/maintenance/maintenance.html"
  },"51": {
    "doc": "Обзор понятий, компонентов и связей",
    "title": "Обзор понятий, компонентов и связей",
    "content": " ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/overview.html",
    "relUrl": "/overview/overview.html"
  },"52": {
    "doc": "Зарезервированные слова",
    "title": "Зарезервированные слова",
    "content": " ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html",
    "relUrl": "/reference/reserved_words/reserved_words.html"
  },"53": {
    "doc": "Зарезервированные слова",
    "title": "A",
    "content": "ABS, ALL, ALLOCATE, ALLOW, ALTER, AND, ANY, ARE, ARRAY, ARRAY_MAX_CARDINALITY, AS, ASENSITIVE, ASYMMETRIC, AT, ATOMIC, AUTHORIZATION, AVG . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#a",
    "relUrl": "/reference/reserved_words/reserved_words.html#a"
  },"54": {
    "doc": "Зарезервированные слова",
    "title": "B",
    "content": "BEGIN, BEGIN_FRAME, BEGIN_PARTITION, BETWEEN, BIGINT, BINARY, BIT, BLOB, BOOLEAN, BOTH, BY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#b",
    "relUrl": "/reference/reserved_words/reserved_words.html#b"
  },"55": {
    "doc": "Зарезервированные слова",
    "title": "C",
    "content": "CALL, CALLED, CARDINALITY, CASCADED, CASE, CAST, CEIL, CEILING, CHAR, CHARACTER, CHARACTER_LENGTH, CHAR_LENGTH, CHECK, CLASSIFIER, CLOB, CLOSE, COALESCE, COLLATE, COLLECT, COLUMN, COMMIT, CONDITION, CONNECT, CONSTRAINT, CONTAINS, CONVERT, CORR, CORRESPONDING, COUNT, COVAR_POP, COVAR_SAMP, CREATE, CROSS, CUBE, CUME_DIST, CURRENT, CURRENT_CATALOG, CURRENT_DATE, CURRENT_DEFAULT_TRANSFORM_GROUP, CURRENT_PATH, CURRENT_ROLE, CURRENT_ROW, CURRENT_SCHEMA, CURRENT_TIME, CURRENT_TIMESTAMP, CURRENT_TRANSFORM_GROUP_FOR_TYPE, CURRENT_USER, CURSOR, CYCLE . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#c",
    "relUrl": "/reference/reserved_words/reserved_words.html#c"
  },"56": {
    "doc": "Зарезервированные слова",
    "title": "D",
    "content": "DATE, DAY, DEALLOCATE, DEC, DECIMAL, DECLARE, DEFAULT, DEFINE, DELETE, DENSE_RANK, DEREF, DESCRIBE, DETERMINISTIC, DISALLOW, DISCONNECT, DISTINCT, DOUBLE, DROP, DYNAMIC . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#d",
    "relUrl": "/reference/reserved_words/reserved_words.html#d"
  },"57": {
    "doc": "Зарезервированные слова",
    "title": "E",
    "content": "EACH, ELEMENT, ELSE, EMPTY, END, END-EXEC, END_FRAME, END_PARTITION, EQUALS, ESCAPE, EVERY, EXCEPT, EXEC, EXECUTE, EXISTS, EXP, EXPLAIN, EXTEND, EXTERNAL, EXTRACT . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#e",
    "relUrl": "/reference/reserved_words/reserved_words.html#e"
  },"58": {
    "doc": "Зарезервированные слова",
    "title": "F",
    "content": "FALSE, FETCH, FILTER, FIRST_VALUE, FLOAT, FLOOR, FOR, FOREIGN, FRAME_ROW, FREE, FROM, FULL, FUNCTION, FUSION . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#f",
    "relUrl": "/reference/reserved_words/reserved_words.html#f"
  },"59": {
    "doc": "Зарезервированные слова",
    "title": "G",
    "content": "GET, GLOBAL, GRANT, GROUP, GROUPING, GROUPS . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#g",
    "relUrl": "/reference/reserved_words/reserved_words.html#g"
  },"60": {
    "doc": "Зарезервированные слова",
    "title": "H",
    "content": "HAVING, HOLD, HOUR . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#h",
    "relUrl": "/reference/reserved_words/reserved_words.html#h"
  },"61": {
    "doc": "Зарезервированные слова",
    "title": "I",
    "content": "IDENTITY, IMPORT, IN, INDICATOR, INITIAL, INNER, INOUT, INSENSITIVE, INSERT, INT, INTEGER, INTERSECT, INTERSECTION, INTERVAL, INTO, IS . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#i",
    "relUrl": "/reference/reserved_words/reserved_words.html#i"
  },"62": {
    "doc": "Зарезервированные слова",
    "title": "J",
    "content": "JOIN, JSON_ARRAY, JSON_ARRAYAGG, JSON_EXISTS, JSON_OBJECT, JSON_OBJECTAGG, JSON_QUERY, JSON_VALUE . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#j",
    "relUrl": "/reference/reserved_words/reserved_words.html#j"
  },"63": {
    "doc": "Зарезервированные слова",
    "title": "L",
    "content": "LAG, LANGUAGE, LARGE, LAST_VALUE, LATERAL, LEAD, LEADING, LEFT, LIKE, LIKE_REGEX, LIMIT, LN, LOCAL, LOCALTIME, LOCALTIMESTAMP, LOWER . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#l",
    "relUrl": "/reference/reserved_words/reserved_words.html#l"
  },"64": {
    "doc": "Зарезервированные слова",
    "title": "M",
    "content": "MATCH, MATCHES, MATCH_NUMBER, MATCH_RECOGNIZE, MAX, MEASURES, MEMBER, MERGE, METHOD, MIN, MINUS, MINUTE, MOD, MODIFIES, MODULE, MONTH, MULTISET . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#m",
    "relUrl": "/reference/reserved_words/reserved_words.html#m"
  },"65": {
    "doc": "Зарезервированные слова",
    "title": "N",
    "content": "NATIONAL, NATURAL, NCHAR, NCLOB, NEW, NEXT, NO, NONE, NORMALIZE, NOT, NTH_VALUE, NTILE, NULL, NULLIF, NUMERIC . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#n",
    "relUrl": "/reference/reserved_words/reserved_words.html#n"
  },"66": {
    "doc": "Зарезервированные слова",
    "title": "O",
    "content": "OCCURRENCES_REGEX, OCTET_LENGTH, OF, OFFSET, OLD, OMIT, ON, ONE, ONLY, OPEN, OR, ORDER, OUT, OUTER, OVER, OVERLAPS, OVERLAY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#o",
    "relUrl": "/reference/reserved_words/reserved_words.html#o"
  },"67": {
    "doc": "Зарезервированные слова",
    "title": "P",
    "content": "PARAMETER, PARTITION, PATTERN, PER, PERCENT, PERCENTILE_CONT, PERCENTILE_DISC, PERCENT_RANK, PERIOD, PERMUTE, PORTION, POSITION, POSITION_REGEX, POWER, PRECEDES, PRECISION, PREPARE, PREV, PRIMARY, PROCEDURE . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#p",
    "relUrl": "/reference/reserved_words/reserved_words.html#p"
  },"68": {
    "doc": "Зарезервированные слова",
    "title": "R",
    "content": "RANGE, RANK, READS, REAL, RECURSIVE, REF, REFERENCES, REFERENCING, REGR_AVGX, REGR_AVGY, REGR_COUNT, REGR_INTERCEPT, REGR_R2, REGR_SLOPE, REGR_SXX, REGR_SXY, REGR_SYY, RELEASE, RESET, RESULT, RETURN, RETURNS, REVOKE, RIGHT, ROLLBACK, ROLLUP, ROW, ROW_NUMBER, ROWS, RUNNING . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#r",
    "relUrl": "/reference/reserved_words/reserved_words.html#r"
  },"69": {
    "doc": "Зарезервированные слова",
    "title": "S",
    "content": "SAVEPOINT, SCOPE, SCROLL, SEARCH, SECOND, SEEK, SELECT, SENSITIVE, SESSION_USER, SET, SHOW, SIMILAR, SKIP, SMALLINT, SOME, SPECIFIC, SPECIFICTYPE, SQL, SQLEXCEPTION, SQLSTATE, SQLWARNING, SQRT, START, STATIC, STDDEV_POP, STDDEV_SAMP, STREAM, SUBMULTISET, SUBSET, SUBSTRING, SUBSTRING_REGEX, SUCCEEDS, SUM, SYMMETRIC, SYSTEM, SYSTEM_TIME, SYSTEM_USER . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#s",
    "relUrl": "/reference/reserved_words/reserved_words.html#s"
  },"70": {
    "doc": "Зарезервированные слова",
    "title": "T",
    "content": "TABLE, TABLESAMPLE, THEN, TIME, TIMESTAMP, TIMEZONE_HOUR, TIMEZONE_MINUTE, TINYINT, TO, TRAILING, TRANSLATE, TRANSLATE_REGEX, TRANSLATION, TREAT, TRIGGER, TRIM, TRIM_ARRAY, TRUE, TRUNCATE, TUMBLE . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#t",
    "relUrl": "/reference/reserved_words/reserved_words.html#t"
  },"71": {
    "doc": "Зарезервированные слова",
    "title": "U",
    "content": "UESCAPE, UNION, UNIQUE, UNKNOWN, UNNEST, UPDATE, UPPER, UPSERT, USER, USING . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#u",
    "relUrl": "/reference/reserved_words/reserved_words.html#u"
  },"72": {
    "doc": "Зарезервированные слова",
    "title": "V",
    "content": "VALUE, VALUE_OF, VALUES, VARBINARY, VARCHAR, VAR_POP, VAR_SAMP, VARYING, VERSIONING . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#v",
    "relUrl": "/reference/reserved_words/reserved_words.html#v"
  },"73": {
    "doc": "Зарезервированные слова",
    "title": "W",
    "content": "WHEN, WHENEVER, WHERE, WIDTH_BUCKET, WINDOW, WITH, WITHIN, WITHOUT . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#w",
    "relUrl": "/reference/reserved_words/reserved_words.html#w"
  },"74": {
    "doc": "Зарезервированные слова",
    "title": "Y",
    "content": "YEAR . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reserved_words/reserved_words.html#y",
    "relUrl": "/reference/reserved_words/reserved_words.html#y"
  },"75": {
    "doc": "Ограничения системы",
    "title": "Ограничения системы",
    "content": "Содержание раздела . | ALLOW_CHANGES | ALTER VIEW | BEGIN DELTA | CHECK_DATA | CHECK_SUM | CHECK_SUM_SNAPSHOT | COMMIT DELTA | CREATE DATABASE | CREATE DOWNLOAD EXTERNAL TABLE | CREATE MATERIALIZED VIEW | CREATE TABLE | CREATE UPLOAD EXTERNAL TABLE | CREATE VIEW | DELETE | DENY_CHANGES | DROP DATABASE | DROP DOWNLOAD_EXTERNAL_TABLE | DROP MATERIALIZED VIEW | DROP TABLE | DROP UPLOAD EXTERNAL TABLE | DROP_VIEW | INSERT INTO download external table | INSERT INTO logical table | INSERT SELECT | INSERT VALUES | SELECT | SELECT FROM INFORMATION_SCHEMA | TRUNCATE_HISTORY | UPSERT VALUES | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html",
    "relUrl": "/restrictions/restrictions.html"
  },"76": {
    "doc": "Ограничения системы",
    "title": "ALLOW_CHANGES",
    "content": ". | Выполнение запроса недоступно при наличии незавершенного запроса на создание, удаление или изменение таблицы или представления. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#allow_changes",
    "relUrl": "/restrictions/restrictions.html#allow_changes"
  },"77": {
    "doc": "Ограничения системы",
    "title": "ALTER VIEW",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Подзапрос query не может содержать: . | логические представления, | системные представления INFORMATION_SCHEMA, | ключевое слово FOR SYSTEM_TIME, | ключевое слово DATASOURCE_TYPE. | . | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#alter-view",
    "relUrl": "/restrictions/restrictions.html#alter-view"
  },"78": {
    "doc": "Ограничения системы",
    "title": "BEGIN DELTA",
    "content": ". | Выполнение запроса невозможно при наличии незавершенного запроса на создание, удаление или изменение таблицы или представления. | Если в запросе указан номер открываемой дельты, он должен быть равен номеру последней закрытой дельты + 1. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#begin-delta",
    "relUrl": "/restrictions/restrictions.html#begin-delta"
  },"79": {
    "doc": "Ограничения системы",
    "title": "CHECK_DATA",
    "content": ". | Существует вероятность совпадения контрольных сумм для разных наборов записей, поэтому возможен ложноположительный результат проверки. | Количество проверяемых записей в одной сущности ограничено и регулируется коэффициентом нормализации. Если количество загруженных записей какой-либо сущности в указанной дельте больше 4'294'967'298, нужно подобрать подходящее значение коэффициента нормализации. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#check_data",
    "relUrl": "/restrictions/restrictions.html#check_data"
  },"80": {
    "doc": "Ограничения системы",
    "title": "CHECK_SUM",
    "content": ". | Контрольная сумма логической базы данных рассчитывается только по данным логических таблиц и не учитывает данные материализованных представлений. | Существует вероятность совпадения контрольных сумм для разных наборов данных. | Количество проверяемых записей в одной сущности ограничено и регулируется коэффициентом нормализации. Если количество загруженных записей какой-либо сущности в указанной дельте больше 4'294'967'298, нужно подобрать подходящее значение коэффициента нормализации. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#check_sum",
    "relUrl": "/restrictions/restrictions.html#check_sum"
  },"81": {
    "doc": "Ограничения системы",
    "title": "CHECK_SUM_SNAPSHOT",
    "content": ". | Контрольная сумма логической базы данных рассчитывается только по данным логических таблиц и не учитывает данные материализованных представлений. | Существует вероятность совпадения контрольных сумм для разных наборов данных. | Количество проверяемых записей в одной сущности ограничено и регулируется коэффициентом нормализации. Если количество актуальных записей какой-либо сущности в указанной дельте больше 4'294'967'298, нужно подобрать подходящее значение коэффициента нормализации. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#check_sum_snapshot",
    "relUrl": "/restrictions/restrictions.html#check_sum_snapshot"
  },"82": {
    "doc": "Ограничения системы",
    "title": "COMMIT DELTA",
    "content": ". | Если в запросе указаны дата и время закрытия дельты, они должны быть больше, чем дата и время последней закрытой дельты. Дату и время последней закрытой дельты можно узнать, выполнив запрос GET_DELTA_OK. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#commit-delta",
    "relUrl": "/restrictions/restrictions.html#commit-delta"
  },"83": {
    "doc": "Ограничения системы",
    "title": "CREATE DATABASE",
    "content": ". | Недоступно создание логической базы данных с именем INFORMATION_SCHEMA, зарезервированным для сервисной БД. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#create-database",
    "relUrl": "/restrictions/restrictions.html#create-database"
  },"84": {
    "doc": "Ограничения системы",
    "title": "CREATE DOWNLOAD EXTERNAL TABLE",
    "content": ". | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#create-download-external-table",
    "relUrl": "/restrictions/restrictions.html#create-download-external-table"
  },"85": {
    "doc": "Ограничения системы",
    "title": "CREATE MATERIALIZED VIEW",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Имена столбцов должны быть уникальны в рамках представления. | Столбцы не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Имена, порядок и типы данных столбцов должны совпадать в SELECT-подзапросе и представлении. | Первичный ключ должен включать все столбцы ключа шардирования. | Подзапрос может обращаться только к логическим таблицам и только той логической базы данных, в которой находится материализованное представление. | Подзапрос не может содержать: . | ключевое слово FOR SYSTEM_TIME, | ключевое слово ORDER BY, | ключевое слово LIMIT. | . | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#create-materialized-view",
    "relUrl": "/restrictions/restrictions.html#create-materialized-view"
  },"86": {
    "doc": "Ограничения системы",
    "title": "CREATE TABLE",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Имена столбцов должны быть уникальны в рамках логической таблицы. | Столбцы не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Первичный ключ должен включать все столбцы ключа шардирования. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#create-table",
    "relUrl": "/restrictions/restrictions.html#create-table"
  },"87": {
    "doc": "Ограничения системы",
    "title": "CREATE UPLOAD EXTERNAL TABLE",
    "content": ". | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#create-upload-external-table",
    "relUrl": "/restrictions/restrictions.html#create-upload-external-table"
  },"88": {
    "doc": "Ограничения системы",
    "title": "CREATE VIEW",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | В подзапросе query не допускается использование: . | логических представлений, | системных представлений INFORMATION_SCHEMA, | ключевого слова FOR SYSTEM_TIME. | . | Ключевое слово DATASOURCE_TYPE, указанное в подзапросе query, игнорируется. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#create-view",
    "relUrl": "/restrictions/restrictions.html#create-view"
  },"89": {
    "doc": "Ограничения системы",
    "title": "DELETE",
    "content": ". | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | Столбцы в условии запроса не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | В условии WHERE не допускается использование функций, результаты которых различаются в разных СУБД хранилища. Примерами таких функций служат операции с вещественными числами (числами с плавающей запятой): сравнение с вещественным числом, округление и т.д. | Не допускается выполнение идентичных параллельных запросов. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#delete",
    "relUrl": "/restrictions/restrictions.html#delete"
  },"90": {
    "doc": "Ограничения системы",
    "title": "DENY_CHANGES",
    "content": ". | Выполнение запроса недоступно при наличии другого запрета изменений или незавершенного запроса на создание, удаление или изменение таблицы или представления. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#deny_changes",
    "relUrl": "/restrictions/restrictions.html#deny_changes"
  },"91": {
    "doc": "Ограничения системы",
    "title": "DROP DATABASE",
    "content": ". | Недоступно удаление сервисной базы данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#drop-database",
    "relUrl": "/restrictions/restrictions.html#drop-database"
  },"92": {
    "doc": "Ограничения системы",
    "title": "DROP DOWNLOAD_EXTERNAL_TABLE",
    "content": ". | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#drop-download_external_table",
    "relUrl": "/restrictions/restrictions.html#drop-download_external_table"
  },"93": {
    "doc": "Ограничения системы",
    "title": "DROP MATERIALIZED VIEW",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#drop-materialized-view",
    "relUrl": "/restrictions/restrictions.html#drop-materialized-view"
  },"94": {
    "doc": "Ограничения системы",
    "title": "DROP TABLE",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#drop-table",
    "relUrl": "/restrictions/restrictions.html#drop-table"
  },"95": {
    "doc": "Ограничения системы",
    "title": "DROP UPLOAD EXTERNAL TABLE",
    "content": ". | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#drop-upload-external-table",
    "relUrl": "/restrictions/restrictions.html#drop-upload-external-table"
  },"96": {
    "doc": "Ограничения системы",
    "title": "DROP_VIEW",
    "content": ". | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#drop_view",
    "relUrl": "/restrictions/restrictions.html#drop_view"
  },"97": {
    "doc": "Ограничения системы",
    "title": "INSERT INTO download external table",
    "content": ". | Имена и порядок следования столбцов должны совпадать в SELECT-подзапросе на выгрузку данных и внешней таблице выгрузки. | Выгрузка данных, выбранных с использованием агрегатных функций, из ADQM дает некорректные результаты. Ограничение связано с тем, что данные из сегментов кластера ADQM выгружаются параллельно и не объединяются. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#insert-into-download-external-table",
    "relUrl": "/restrictions/restrictions.html#insert-into-download-external-table"
  },"98": {
    "doc": "Ограничения системы",
    "title": "INSERT INTO logical table",
    "content": ". | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#insert-into-logical-table",
    "relUrl": "/restrictions/restrictions.html#insert-into-logical-table"
  },"99": {
    "doc": "Ограничения системы",
    "title": "INSERT SELECT",
    "content": ". | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | Столбцы в запросе не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Типы вставляемых данных должны соответствовать типам данных столбцов целевой логической таблицы. | Не допускается выполнение идентичных параллельных запросов. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#insert-select",
    "relUrl": "/restrictions/restrictions.html#insert-select"
  },"100": {
    "doc": "Ограничения системы",
    "title": "INSERT VALUES",
    "content": ". | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | Столбцы в запросе не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Не допускается выполнение идентичных параллельных запросов. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#insert-values",
    "relUrl": "/restrictions/restrictions.html#insert-values"
  },"101": {
    "doc": "Ограничения системы",
    "title": "SELECT",
    "content": ". | Запрос может обращаться либо к логической БД, либо к сервисной БД (см. SELECT FROM INFORMATION_SCHEMA), но не к обеим одновременно. | Если ключами соединения в запросе выступают поля типа Nullable, то строки, где хотя бы один из ключей имеет значение NULL, не соединяются. | Ключевое слово ORDER BY не поддерживается для SELECT-подзапроса в составе запроса CREATE MATERIALIZED VIEW. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#select",
    "relUrl": "/restrictions/restrictions.html#select"
  },"102": {
    "doc": "Ограничения системы",
    "title": "SELECT FROM INFORMATION_SCHEMA",
    "content": ". | Не допускается комбинирование подзапросов к INFORMATION_SCHEMA с подзапросами к логическим базам данных. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#select-from-information_schema",
    "relUrl": "/restrictions/restrictions.html#select-from-information_schema"
  },"103": {
    "doc": "Ограничения системы",
    "title": "TRUNCATE_HISTORY",
    "content": ". | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#truncate_history",
    "relUrl": "/restrictions/restrictions.html#truncate_history"
  },"104": {
    "doc": "Ограничения системы",
    "title": "UPSERT VALUES",
    "content": ". | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | Столбцы в запросе не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Не допускается выполнение идентичных параллельных запросов. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/restrictions/restrictions.html#upsert-values",
    "relUrl": "/restrictions/restrictions.html#upsert-values"
  },"105": {
    "doc": "История изменений",
    "title": "История изменений",
    "content": "Содержание раздела . | Текущая версия документации (5.4) | Архивные версии документации . | Версия 5.3 | Версия 5.2 | Версия 5.1 | Версия 5.0 | Версия 4.1 | Версия 4.0 | Версия 3.7.3 | . | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/revision_history/revision_history.html",
    "relUrl": "/revision_history/revision_history.html"
  },"106": {
    "doc": "История изменений",
    "title": "Текущая версия документации (5.4)",
    "content": "Изменения: . | начало строки подключения изменено с jdbc:adtm на jdbc:prostore; | запрос UPSERT VALUES переименован в INSERT VALUES, запрос UPSERT SELECT — в INSERT SELECT; | добавлены новые запросы: . | UPSERT VALUES; | CHECK_SUM_SNAPSHOT; | . | обновлена конфигурация системы: . | добавлен параметр KAFKA_STATUS_EVENT_TOPIC; | изменены значения по умолчанию: . | параметр ADQM_DB_NAME теперь имеет значение по умолчанию default; | параметр ADQM_CLUSTER теперь имеет значение по умолчанию default_cluster; | значения параметра ADQM_SHARDING_EXPR изменены с cityHash64 и intAdd на CITY_HASH_64 и INT_ADD соответственно; | . | начало путей io.arenadata во всех вхождениях заменено на ru.datamart; | добавлены неучтенные ранее параметры для ADG: TARANTOOL_VERTX_WORKERS, TARANTOOL_DB_SYNC_CONNECTION_TIMEOUT, TARANTOOL_DB_SYNC_READ_TIMEOUT и TARANTOOL_DB_SYNC_REQUEST_TIMEOUT; | . | добавлено ограничение на имена логических сущностей и их столбцов: имя должно начинаться с латинской буквы, после первого символа могут следовать латинские буквы, цифры и символы подчеркивания в любом порядке; | изменен ответ GET_CHANGES в случае отсутствия журнала: теперь возвращается пустой объект ResultSet, а не ошибка; | локализация статуса 2 операции записи изменена с «Ошибка» на «Отменяется»; | имя логической базы данных в примерах изменено с sales на marketing. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/revision_history/revision_history.html#current",
    "relUrl": "/revision_history/revision_history.html#current"
  },"107": {
    "doc": "История изменений",
    "title": "Архивные версии документации",
    "content": "Версия 5.3 . Версия 5.3 доступна в архиве. Изменения: . | добавлено создание материализованных представлений в ADQM на основе данных ADB; | добавлена вставка данных из ADB в ADQM с помощью UPSERT SELECT; | удалено требование на целочисленные ключи шардирования в логических таблицах: теперь ключ может содержать столбцы с любыми типами данных; | добавлены новые запросы: . | CHECK_MATERIALIZED_VIEW; | DENY_CHANGES; | ALLOW_CHANGES; | GET_CHANGES; | GET_ENTITY_DDL; | . | в системное представление tables добавлен новый тип сущности — MATERIALIZED VIEW; | добавлено возможность возобновления зависшей операции обновления данных; | добавлено автоматическое ведение журнала — списка операций по изменению логических сущностей; | для выгрузки данных добавлен выбор оптимальной СУБД хранилища, аналогичный выбору СУБД для SELECT-запросов; | из описания запроса CREATE TABLE удалено неподдерживаемое ключевое слово DEFAULT; | добавлен раздел «Зарезервированные слова» со словами, которые не могут использоваться как имена сущностей и имена полей; | добавлен раздел «Ограничения системы» со списком всех ограничений, имеющихся в запросах системы; | обновлена конфигурация системы: . | добавлен параметр ADQM_SHARDING_EXPR; | добавлен параметр ADB_MPPW_USE_ADVANCED_CONNECTOR; | удален параметр EDML_DATASOURCE; | исправлен путь до параметра ADB_WITH_HISTORY_TABLE с adb:mppw:with-history-table на adb:with-history-table; | исправлен путь до параметров ADG_MAX_MSG_PER_PARTITION и ADG_CB_FUNC_IDLE: из пути удален параметр kafka; | . | изменена терминология: архивация актуальных записей теперь называется удалением, а удаление записей с помощью запроса TRUNCATE HISTORY — удалением записей с историей. | . Версия 5.2 . Версия 5.2 доступна в архиве. Изменения: . | добавлена функция обновления данных — альтернатива загрузке в случае небольших объемов данных; описание доступно в следующие разделах: . | «Обновление данных»; | «Порядок обработки запросов на обновление данных»; | UPSERT VALUES; | UPSERT SELECT; | DELETE; | . | добавлены новые запросы: . | CONFIG_SHOW; | GET_WRITE_OPERATIONS; | RESUME_WRITE_OPERATION; | . | добавлено ключевое слово COLLATE, доступное в SELECT-запросах к ADG; | добавлена возможность выгрузки данных из материализованных представлений; | изменена маршрутизация SELECT-запросов: теперь учитывается не только категория запроса, но и набор узлов кластера, для которых предназначен запрос; | добавлен раздел «Разбор ошибок загрузки и обновления данных»; | ограничено исполнение запросов по управлению схемой данных в сервисной базе данных INFORMATION_SCHEMA; | изменен перечень операций, отменяемых запросом ROLLBACK DELTA: отменяются все завершенные операции (как операции загрузки данных, так и обновления данных), а также незавершенные операции загрузки данных; незавершенные операции обновления данных не отменяются; | обновлена конфигурация системы: . | добавлены параметры AUTO_RESTORE_STATE, ADB_MAX_RECONNECTIONS, ADB_QUERIES_BY_CONNECT_LIMIT и ADB_RECONNECTION_INTERVAL; | добавлена секция параметров autoSelect для настройки порядка выбора СУБД в зависимости от категории и подкатегории запросов; | удален параметр CORE_TIME_ZONE (больше не используется); | путь к параметру DTM_METRICS_PORT изменен с management.server.port на server.port; | путь к параметру DTM_CORE_METRICS_ENABLED изменен c core.metrics.isEnabled на core.metrics.еnabled; | . | добавлен раздел «Конфигурация коннекторов»; | описание конфигурационных параметров системы перенесено из раздела «Конфигурация» в раздел «Конфигурация системы»; | имя системы заменено на Prostore (в соответствии с именем проекта с открытым исходным кодом); | скорректировано описание служебного поля sys_op: поле должно отсутствовать во внешней таблице загрузки и логической таблице и должно присутствовать в загружаемых сообщениях топика Kafka. | . Версия 5.1 . Версия 5.1 доступна в архиве. Изменения: . | добавлено ключевое слово ESTIMATE_ONLY, доступное в SELECT-запросах; | добавлено ключевое слово LOGICAL_ONLY, доступное в запросах на создание и удаление логической БД, логической таблицы и материализованного представления; | обновлено описание запросов CHECK_DATA и CHECK_SUM: . | добавлен коэффициент нормализации, повышающий максимально допустимое количество записей в проверяемых дельтах; | изменен расчет контрольных сумм: теперь они считаются по дельтам, а не отдельным операциям записи; | . | обновлено описание запроса CHECK_SUM: . | изменен расчет контрольной суммы по таблице/представлению: теперь расчет аналогичен тому, который выполняется для CHECK_DATA; | изменен расчет контрольной суммы по логической БД: теперь контрольные суммы таблиц складываются, а не проходят дополнительный этап хеширования; | . | в конфигурацию добавлен параметр DTM_VERTX_BLOCKING_STACKTRACE_TIME; | добавлена глава «Сборка и развертывание»; | в главу «Работа с системой» добавлены разделы «Получение информации о SELECT-запросе» и «Проверка месторасположения логической сущности»; | в главу «Эксплуатация» добавлен раздел «Часовые пояса системы и компонентов». | . Версия 5.0 . Изменения: . | добавлена СУБД хранилища нового типа — ADP — на основе PostgreSQL; | добавлена выгрузка данных из СУБД хранилища, указанной в запросе INSERT INTO download_external_table; | в системное представление tables добавлен столбец table_datasource_type; | обновлено описание запроса CHECK_SUM: теперь запрос поддерживает расчет контрольной суммы по материализованному представлению; | обновлена конфигурация: . | добавлены параметры для управления СУБД ADP; | добавлены параметры запроса prepared statement для ADB: ADB_PREPARED_CACHE_MAX_SIZE, ADB_PREPARED_CACHE_SQL_LIMIT и ADB_PREPARED_CACHE; | значения следующих параметров расширены новой СУБД ADP: CORE_PLUGINS_ACTIVE, DTM_CORE_PLUGINS_RELATIONAL, DTM_CORE_PLUGINS_ANALYTICAL, DTM_CORE_PLUGINS_DICTIONARY, DTM_CORE_PLUGINS_UNDEFINED; | добавлен параметр DTM_LOGGING_LEVEL для управления уровнем логирования; | конкретные IP-адреса заменены на localhost; | . | добавлен раздел «Схемы развертывания». | . Версия 4.1 . Версия 4.1 доступна в архиве. Изменения: . | добавлено ключевое слово OFFSET, доступное в SELECT-запросах; | добавлено ключевое слово FETCH NEXT &lt;N&gt; ROWS ONLY как полная альтернатива ключевому слову LIMIT &lt;N&gt; в SELECT-запросах; | обновлено описание запроса ROLLBACK DELTA: теперь запрос отменяет как завершенные, так и выполняемые операции записи; | обновлена конфигурация: . | значение параметра ADB_EXECUTORS_COUNT изменено с 20 на 3; | значение параметра ADB_MAX_POOL_SIZE изменено с 5 на 3; | добавлен новый параметр DELTA_ROLLBACK_STATUS_CALLS_MS. | . | . Версия 4.0 . Изменения: . | описаны материализованные представления; | описаны возможные форматы даты и времени в запросах; | добавлен раздел «Проверка наличия логической сущности»; | добавлен раздел «Настройка JSON-логов»; | в конфигурацию добавлены параметры по управлению материализованными представлениями: . | MATERIALIZED_VIEWS_SYNC_PERIOD_MS, | MATERIALIZED_VIEWS_RETRY_COUNT, | MATERIALIZED_VIEWS_RETRY_COUNT. | . | . Версия 3.7.3 . Версия 3.7.3 доступна в архиве. Изменения: . | обновлена конфигурация: . | в секцию vertx.pool добавлены параметры DTM_CORE_WORKER_POOL_SIZE и DTM_CORE_EVENT_LOOP_POOL_SIZE; | путь к параметру ADB_MAX_POOL_SIZE изменился с adb.maxSize на adb.poolSize; | в секцию adb добавлен параметр ADB_EXECUTORS_COUNT; | . | описан запрос ROLLBACK CRASHED_WRITE_OPERATIONS; | доработаны разделы CHECK_DATA и CHECK_SUM: описаны алгоритм и пример расчета контрольной суммы; | уточнено описание формата загрузки и формата выгрузки данных; | в разделе «Минимальные системные требования» версия ADG обновлена до 2.7.2. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/revision_history/revision_history.html#archive",
    "relUrl": "/revision_history/revision_history.html#archive"
  },"108": {
    "doc": "Поддержка SQL",
    "title": "Поддержка SQL",
    "content": "Содержание раздела . | Преобразование типов . | Неявное преобразование | CAST | . | Запросы с подзапросами . | TRUNCATE HISTORY | DELETE | . | Функции и операторы соединения . | UNION | INTERSECT | EXCEPT | JOIN | . | Функции и операторы даты и времени . | CAST AS DATE | CURRENT_DATE | CAST AS TIME | CURRENT_TIME | CAST AS TIMESTAMP | CURRENT_TIMESTAMP | EXTRACT | LOCALTIME | LOCALTIMESTAMP | MONTH, QUARTER, WEEK, YEAR | . | Системные функции и операторы | Строковые функции и операторы . | POSITION | UPPER | LOWER | SUBSTRING | COALESCE | TRIM | REPLACE | CONCATENATION | INITCAP | . | Математические функции и операторы . | ABS | ROUND | FLOOR | CEIL | CEILING | BIT_AND | BIT_OR | DEGREES | RADIANS | SIGN | SIN, COS, TAN, COT | ASIN, ACOS, ATAN, ATAN2 | POWER, EXP*, LOG* | SQRT, CBRT | MOD | MAX, MIN | SUM, COUNT | AVG | COVAR | VAR | STDDEV | . | Функции в SQL+ запросах . | COALESCE: INSERT SELECT | . | . В SELECT-запросах к данным можно использовать функции и операторы, описанные в таблице ниже. СУБД хранилища имеют ограничения на использование некоторых функций в запросах, вызванные особенностями этих СУБД. Наиболее полный синтаксис запросов доступен в ADB и ADP. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html",
    "relUrl": "/reference/sql_support/sql_support.html"
  },"109": {
    "doc": "Поддержка SQL",
    "title": "Преобразование типов",
    "content": "Неявное преобразование . | bigint_col to boolean: Не поддерживается | . | SELECT bigint_col = true FROM table1; | . | int_col to boolean: Не поддерживается | . | SELECT int_col = true FROM table1; | . | integer type to boolean within MATERIALIZED VIEW: Не поддерживается | . | CREATE MATERIALIZED VIEW matview1( id int not null, int_col int, primary key (id))DISTRIBUTED BY (id)DATASOURCE_TYPE (adg, adqm)ASSELECT * FROM table1 a INNER JOIN table2 c ON a.int_col = trueDATASOURCE_TYPE = 'adb'; | . CAST . | CAST (boolean as int32): Не поддерживается | . | SELECT CAST(boolean_col as int32) FROM table1; | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html#Typescast",
    "relUrl": "/reference/sql_support/sql_support.html#Typescast"
  },"110": {
    "doc": "Поддержка SQL",
    "title": "Запросы с подзапросами",
    "content": "TRUNCATE HISTORY . | TRUNCATE HISTORY : ADB, ADQM, ADG, ADP | . | TRUNCATE HISTORY table1 FOR SYSTEM_TIME AS OF'2021-01-01 23:59:59'WHERE int_col &lt; 100; | . | TRUNCATE HISTORY : Не поддерживается | . | TRUNCATE HISTORY table1 FOR SYSTEM_TIME AS OF'2021-01-01 23:59:59'WHERE int_col IN (SELECT int_col FROM table2); | . DELETE . | DELETE : ADB, ADQM, ADG, ADP | . | DELETE FROM table1 WHERE id IN (1, 2, 3, 4); | . | DELETE : Не поддерживается | . | DELETE FROM table1 WHERE id IN (SELECT id FROM table2); | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html#Querieswithsubqueries",
    "relUrl": "/reference/sql_support/sql_support.html#Querieswithsubqueries"
  },"111": {
    "doc": "Поддержка SQL",
    "title": "Функции и операторы соединения",
    "content": "UNION . | UNION ALL: ADB, ADQM, ADG, ADP | . | SELECT a.*FROM ( SELECT b.id FROM (SELECT id from table2) b UNION ALL SELECT id FROM table1 ) as a datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . | UNION ALL: Не поддерживается | . | SELECT id FROM table1 order by id limit 2UNION ALLSELECT id from db99990.table3; | . INTERSECT . | INTERSECT: ADB, ADG, ADP | . | SELECT a.*FROM ( SELECT b.id FROM (SELECT id from table2) b INTERSECT SELECT id FROM table1 ) as a datasource_type = {'ADB' | 'ADP' | 'ADG'}; | . EXCEPT . | EXCEPT: ADB, ADG, ADP | . | SELECT a.*FROM ( SELECT b.id FROM (SELECT id from table2) b EXCEPT SELECT id FROM table1 ) as a datasource_type = {'ADB' | 'ADP' | 'ADG'}; | . | EXCEPT: Не поддерживается | . | SELECT id FROM table1 order by id limit 2EXCEPTSELECT id from table3; | . JOIN . | LEFT JOIN: ADB, ADQM, ADG, ADP | . | SELECT * FROM table1 LEFT JOIN (SELECT * FROM table3 t3) t2 ON table1.id = t2.idWHERE table1.id &gt; 10 AND t2.id &gt; 5ORDER BY table1.idDATASOURCE_TYPE = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . | LEFT JOIN: Не поддерживается | . | SELECT * FROM table1 LEFT JOIN (SELECT * FROM table3 t3 WHERE t3.id &gt; 5) t2 ON table1.id = t2.idWHERE table3.id &gt; 10ORDER BY table3.id; | . | RIGHT JOIN: ADB, ADP | . | SELECT * FROM table1 t1RIGHT JOIN table3 t3 on t1.id = t3.idORDER BY t1.id limit 5 datasource_type = {'ADB' | 'ADP'}; | . Вышеуказанный SELECT-запрос с RIGHT JOIN для ADQM считается неподдерживаемым, так как может возвращать некорректный результат, несмотря на формальное отсутствие ошибки исполнения. | RIGHT JOIN: Не поддерживается | . | SELECT * FROM table1 RIGHT JOIN (SELECT * FROM table3 t3 WHERE t3.id &gt; 5) t2 ON table1.id = t2.idWHERE table3.id &gt; 10ORDER BY table3.id; | . | FULL JOIN: ADB, ADP | . | SELECT * FROM table1 t1FULL JOIN&lt;&gt;br table2 t2 on t1.category_id = t2.idORDER BY t1.id limit 6 datasource_type = {'ADB' | 'ADP'}; | . | CROSS JOIN: ADB, ADG, ADP | . | SELECT * FROM table1 t1 CROSS JOIN table2 t2ORDER BY t1.id, t2.category_name limit 5datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | MULTI-TABLE LEFT JOIN: ADB, ADG, ADP | . | SELECT * FROM table1LEFT JOIN table2 ON table1.territory_id = table2.territory_idLEFT JOIN table3 ON table1.territory_id = table3.territory_idWHERE table3.last_name is NOT NULLORDER BY table1.territory_iddatasource_type = {'ADB' | 'ADP' | 'ADG'}; | . | MULTI-TABLE RIGHT JOIN: ADB, ADP | . | SELECT * FROM table1RIGHT JOIN table2 ON table1.territory_id = table2.territory_idRIGHT JOIN table3 ON table1.territory_id = table3.territory_idWHERE table3.last_name is NOT NULLORDER BY table1.territory_iddatasource_type = {'ADB' | 'ADP'}; | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html#Joinfunctions",
    "relUrl": "/reference/sql_support/sql_support.html#Joinfunctions"
  },"112": {
    "doc": "Поддержка SQL",
    "title": "Функции и операторы даты и времени",
    "content": "CAST AS DATE . | CAST AS DATE: ADB, ADQM, ADG, ADP | . | SELECT * FROM table1 WHERE date_col = '2021-01-02' datasource_type = {'ADB' | 'ADQM' | 'ADG' | 'ADP'}; | . | CAST AS DATE: ADB, ADP | . | SELECT * FROM table1 WHERE date_col = CAST('2021-01-02' AS DATE) datasource_type = {'ADB' | 'ADP'}; | . CURRENT_DATE . | CURRENT_DATE: ADB, ADP | . | SELECT CAST(CURRENT_DATE AS DATE) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CURRENT_DATE FROM table1 datasource_type = {'ADB' | 'ADP'}; | . CAST AS TIME . | CAST AS TIME: ADB, ADQM, ADG, ADP | . | SELECT * FROM table1 WHERE time_col = '12:12:12' datasource_type = {'ADB' | 'ADQM' | 'ADG' | 'ADP'}; | . | CAST AS TIME: ADB, ADP | . | SELECT * FROM table1 WHERE time_col = CAST('12:12:12' AS TIME) datasource_type = {'ADB' | 'ADP'}; | . CURRENT_TIME . | CURRENT_TIME: ADB, ADP | . | SELECT CAST(CURRENT_TIME AS TIME) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | CURRENT_TIME: Не поддерживается | . | SELECT CURRENT_TIME FROM table1; | . CAST AS TIMESTAMP . | CAST AS TIMESTAMP: ADB, ADQM, ADG, ADP | . | SELECT * FROM table1 WHERE timestamp_col = '2021-01-02 12:12:12' datasource_type = {'ADB' | 'ADQM' | 'ADG' | 'ADP'}; | . | CAST AS TIMESTAMP: ADB, ADP | . | SELECT * FROM table1 WHERE time_col = CAST('2021-01-02 12:12:12' AS TIMESTAMP) datasource_type = {'ADB' | 'ADP'}; | . CURRENT_TIMESTAMP . | CURRENT_TIMESTAMP: ADB, ADP | . | SELECT CAST(CURRENT_TIMESTAMP AS TIMESTAMP) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CURRENT_TIMESTAMP FROM table1 datasource_type = {'ADB' | 'ADP'}; | . EXTRACT . | EXTRACT(FROM DATE): ADB, ADQM, ADP | . | SELECT CAST(EXTRACT(EPOCH FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(DOY FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(DOW FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(WEEK FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(CENTURY FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(QUARTER FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(QUARTER FROM DATE '2001-02-16') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(YEAR FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(YEAR FROM DATE '2001-02-16') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(MONTH FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(MONTH FROM DATE '2001-02-16') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(DAY FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(DAY FROM DATE '2001-02-16') FROM table1 datasource_type = 'ADQM'; | . | EXTRACT(FROM DATE): ADB, ADP | . | SELECT CAST(EXTRACT(DECADE FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(ISOYEAR FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(ISODOW FROM DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | EXTRACT(FROM TIME): ADB, ADP | . | SELECT CAST(EXTRACT(HOUR FROM TIME '20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(MINUTE FROM TIME '20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(SECOND FROM TIME '20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(MILLISECOND FROM TIME '20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(MICROSECOND FROM TIME '20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | EXTRACT(FROM TIMESTAMP): ADB, ADQM, ADP | . | SELECT CAST(EXTRACT(DOW FROM TIMESTAMP '2001-02-16 00:00:00') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(WEEK FROM TIMESTAMP '2001-02-16 00:00:00') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(CENTURY FROM TIMESTAMP '2001-02-16 00:00:00') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(QUARTER FROM TIMESTAMP '2001-02-16 00:00:00') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(QUARTER FROM TIMESTAMP '2001-02-16 20:38:40') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(YEAR FROM TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(YEAR FROM TIMESTAMP '2001-02-16 20:38:40') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(MONTH FROM TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(MONTH FROM TIMESTAMP '2001-02-16 20:38:40') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(DAY FROM TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(DAY FROM TIMESTAMP '2001-02-16 20:38:40') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(HOUR FROM TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(HOUR FROM TIMESTAMP '2001-02-16 20:38:40') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(MINUTE FROM TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(MINUTE FROM TIMESTAMP '2001-02-16 20:38:40') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(SECOND FROM TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT EXTRACT(SECOND FROM TIMESTAMP '2001-02-16 20:38:40') FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(EXTRACT(MILLISECOND FROM TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(EXTRACT(MICROSECOND FROM TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . LOCALTIME . | LOCALTIME, LOCALTIME(precision): ADB, ADP | . | SELECT LOCALTIME FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(LOCALTIME AS TIME) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT LOCALTIME(3) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(LOCALTIME(3) AS TIME) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . LOCALTIMESTAMP . | LOCALTIMESTAMP, LOCALTIMESTAMP(precision): ADB, ADP | . | SELECT LOCALTIMESTAMP FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(LOCALTIMESTAMP AS TIMESTAMP) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT LOCALTIMESTAMP(3) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(LOCALTIMESTAMP(3) AS TIMESTAMP) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . MONTH, QUARTER, WEEK, YEAR . | MONTH, QUARTER, WEEK, YEAR: ADB, ADP | . | SELECT CAST(MONTH(DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(MONTH(TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(QUARTER(DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(QUARTER(DATE '2001-02-16') AS INT) FROM table1 datasource_type = 'ADP'; | . | SELECT CAST(QUARTER(TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(QUARTER(TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = 'ADP'; | . | SELECT CAST(WEEK(DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(WEEK(TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(YEAR(DATE '2001-02-16') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(YEAR(TIMESTAMP '2001-02-16 20:38:40') AS INT) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html#Datetimefunctions",
    "relUrl": "/reference/sql_support/sql_support.html#Datetimefunctions"
  },"113": {
    "doc": "Поддержка SQL",
    "title": "Системные функции и операторы",
    "content": "| CURRENT_USER, SESSION_USER, CURRENT_ROLE, CURRENT_SCHEMA: ADB, ADP | . | SELECT CURRENT_USER FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT SESSION_USER FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CURRENT_ROLE FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CURRENT_SCHEMA FROM table1 datasource_type = {'ADB' | 'ADP'}; | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html#Systemfunctions",
    "relUrl": "/reference/sql_support/sql_support.html#Systemfunctions"
  },"114": {
    "doc": "Поддержка SQL",
    "title": "Строковые функции и операторы",
    "content": "POSITION . | POSITION: ADB, ADP | . | SELECT POSITION('c' IN 'abcdef') FROM table1 datasource_type = 'ADB' | 'ADP'}; | . UPPER . | UPPER: ADB, ADQM, ADG, ADP | . | SELECT UPPER('abcdef') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . LOWER . | LOWER: ADB, ADP | . | SELECT LOWER('ABCDEG') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . SUBSTRING . | SUBSTRING: ADB, ADQM, ADP | . | SELECT SUBSTRING('ABCDEG', 3, 2) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . COALESCE . | COALESCE: ADB, ADG, ADP | . | SELECT COALESCE(boolean_col,true) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADG'}; | . | COALESCE: ADB, ADQM, ADG, ADP | . | SELECT COALESCE(int_col,1) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . | COALESCE: ADB, ADQM, ADP | . | SELECT COALESCE(bigint_col,1) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | COALESCE: ADB, ADQM, ADG, ADP | . | SELECT COALESCE(int32_col,1) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . | COALESCE: ADB, ADP | . | SELECT COALESCE(float_col,1.0) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | COALESCE: ADB, ADP | . | SELECT COALESCE(double_col,1.0) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | COALESCE: ADB, ADQM, ADG, ADP | . | SELECT COALESCE(varchar_col,'1.0') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADG'}; | . | SELECT COALESCE(CAST(varchar_col AS VARCHAR),'1.0') FROM table1 datasource_type = 'ADQM'; | . | COALESCE: Не поддерживается | . | SELECT COALESCE(date_col,'2001-01-01') FROM table1; | . | COALESCE: ADB, ADP | . | SELECT COALESCE(date_col,CAST('2001-01-01' AS DATE)) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | COALESCE: Не поддерживается | . | SELECT COALESCE(time_col,'11:12:13') FROM table1; | . | COALESCE: ADB, ADP | . | SELECT COALESCE(time_col,CAST('11:12:13' AS TIME)) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | COALESCE: Не поддерживается | . | SELECT COALESCE(timestamp_col,'2001-01-01 11:12:13') FROM table1; | . | COALESCE: ADB, ADP | . | SELECT COALESCE(timestamp_col,CAST('2001-01-01 11:12:13' AS TIMESTAMP)) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | COALESCE: ADB, ADQM, ADP | . | SELECT COALESCE(uuid_col,'1') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | COALESCE: ADB, ADG, ADP | . | SELECT COALESCE(char_col,'1') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADG'}; | . | COALESCE: ADB, ADQM, ADP | . | SELECT COALESCE(link_col,'http://www.google.com') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . TRIM . | TRIM: ADB, ADQM, ADG, ADP | . | SELECT TRIM(' ABC XYZ ') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . REPLACE . | REPLACE: ADB, ADQM, ADG, ADP | . | SELECT REPLACE(' abc xyz ','ab', 'x') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . CONCATENATION . | CONCATENATION: ADB, ADQM, ADG, ADP | . | SELECT 'abc' || 'xyz' FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . INITCAP . | INITCAP: ADB, ADP | . | SELECT INITCAP('abc def ghi xyz') FROM table1 datasource_type = {'ADB' | 'ADP'}; | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html#Stringfunctions",
    "relUrl": "/reference/sql_support/sql_support.html#Stringfunctions"
  },"115": {
    "doc": "Поддержка SQL",
    "title": "Математические функции и операторы",
    "content": "ABS . | ABS: ADB, ADQM, ADG, ADP | . | SELECT ABS(-2.0) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADG'}; | . | SELECT ABS(-2) FROM table1 datasource_type = 'ADQM'; | . ROUND . | ROUND: ADB, ADQM, ADG, ADP | . | SELECT ROUND(-2.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . FLOOR . | FLOOR: ADB, ADQM, ADP | . | SELECT FLOOR(-2.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . CEIL . | CEIL: ADB, ADQM, ADP | . | SELECT CEIL(-2.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . CEILING . | CEILING: ADB, ADQM, ADP | . | SELECT CEILING(-2.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . BIT_AND . | BIT_AND: ADB, ADP | . | SELECT BIT_AND(numeric_col) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . BIT_OR . | BIT_OR: ADB, ADP | . | SELECT BIT_OR(numeric_col) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . DEGREES . | DEGREES: ADB, ADP | . | SELECT DEGREES(3.1415269) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . RADIANS . | RADIANS: ADB, ADP | . | SELECT RADIANS(180.0) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . SIGN . | SIGN: ADB, ADP | . | SELECT SIGN(-2.0) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT SIGN(CAST(-2 AS FLOAT)) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . SIN, COS, TAN, COT . | SIN, COS, TAN, COT: ADB, ADQM, ADP | . | SELECT SIN(-2.0) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | SELECT COS(-2.0) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | SELECT TAN(-2.0) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | SELECT COT(-2.0) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . ASIN, ACOS, ATAN, ATAN2 . | SIN, COS, TAN, COT: ADB, ADQM, ADP | . | SELECT ASIN(0.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | SELECT ACOS(0.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | SELECT ATAN(0.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | SELECT ATAN2(3.0,2.0) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . POWER, EXP*, LOG* . | POWER, EXP, LN: ADB, ADQM*, ADP | . | SELECT POWER(0.5,2) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | SELECT EXP(1.0) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | SELECT LN(2.18281828) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | * Возвращает недостаточно точные значения для EXP и LN | . SQRT, CBRT . | SQRT: ADB, ADQM, ADP | . | SELECT SQRT(4) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | CBRT: ADB, ADP | . | SELECT CBRT(-8) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . MOD . | MOD: ADB, ADP | . | SELECT MOD(8,3) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . MAX, MIN . | MAX: ADB, ADQM, ADG, ADP | . | SELECT MAX(numeric_col) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . | MIN: ADB, ADQM, ADG, ADP | . | SELECT MIN(numeric_col) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . SUM, COUNT . | SUM: ADB, ADQM, ADG, ADP | . | SELECT SUM(numeric_col) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . | COUNT: ADB, ADQM, ADG, ADP | . | SELECT COUNT(numeric_col) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM' | 'ADG'}; | . AVG . | AVG: ADB*, ADQM*, ADG**, ADP* | . | SELECT AVG(CAST(numeric_col AS DOUBLE)) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADG'}; | . | SELECT AVG(CAST(numeric_col AS FLOAT)) FROM table1 datasource_type = 'ADQM'; | . | SELECT AVG(numeric_col) FROM table1 datasource_type = 'ADG'; | . | * Нет неявного преобразования из целочисленного типа | . | ** Результат возвращается по каждому шарду | . COVAR . | COVAR_POP: ADB, ADQM, ADP | . | SELECT COVAR_POP(CAST(numeric_col1 AS DOUBLE), numeric_col2) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT COVAR_POP(CAST(numeric_col1 AS FLOAT), numeric_col2) FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(COVAR_POP(numeric_col1, numeric_col2) AS FLOAT) FROM table1 datasource_type = 'ADQM'; | . | COVAR_SAMP: ADB, ADQM, ADP | . | SELECT COVAR_SAMP(CAST(numeric_col1 AS DOUBLE), numeric_col2) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT COVAR_SAMP(CAST(numeric_col1 AS FLOAT), numeric_col2) FROM table1 datasource_type = 'ADQM'; | . | SELECT CAST(COVAR_SAMP(numeric_col1, numeric_col2) AS FLOAT) FROM table1 datasource_type = 'ADQM'; | . VAR . | VAR_POP: ADB, ADQM, ADP | . | SELECT CAST(VAR_POP(numeric_col, numeric_col) AS DOUBLE) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(VAR_POP(numeric_col, numeric_col) AS FLOAT) FROM table1 datasource_type = 'ADQM'; | . | SELECT VAR_POP(CAST(numeric_col AS FLOAT)) FROM table1 datasource_type = 'ADQM'; | . | VAR_SAMP: ADB, ADQM, ADP | . | SELECT CAST(VAR_SAMP(numeric_col, numeric_col) AS DOUBLE) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(VAR_POP(numeric_col, numeric_col) AS FLOAT) FROM table1 datasource_type = 'ADQM'; | . | SELECT VAR_POP(CAST(numeric_col AS FLOAT)) FROM table1 datasource_type = 'ADQM'; | . STDDEV . | STDDEV_POP: ADB, ADQM, ADP | . | SELECT CAST(STDDEV_POP(numeric_col, numeric_col) AS DOUBLE) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(STDDEV_POP(numeric_col, numeric_col) AS FLOAT) FROM table1 datasource_type = 'ADQM'; | . | SELECT STDDEV_POP(CAST(numeric_col AS FLOAT)) FROM table1 datasource_type = 'ADQM'; | . | STDDEV_SAMP: ADB, ADQM, ADP | . | SELECT CAST(STDDEV_SAMP(numeric_col, numeric_col) AS DOUBLE) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | SELECT CAST(STDDEV_POP(numeric_col, numeric_col) AS FLOAT) FROM table1 datasource_type = 'ADQM'; | . | SELECT STDDEV_POP(CAST(numeric_col AS FLOAT)) FROM table1 datasource_type = 'ADQM'; | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html#Mathfunctions",
    "relUrl": "/reference/sql_support/sql_support.html#Mathfunctions"
  },"116": {
    "doc": "Поддержка SQL",
    "title": "Функции в SQL+ запросах",
    "content": "COALESCE: INSERT SELECT . | COALESCE: ADB, ADP | . | INSERT INTO table2 (id, boolean_col) SELECT COALESCE(boolean_col,true) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | COALESCE: ADB, ADQM, ADP | . | INSERT INTO table2 (id, int32_col) SELECT COALESCE(int32_col,10) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | INSERT INTO table2 (id, int_col) SELECT COALESCE(int_col,-20) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | INSERT INTO table2 (id, bigint_col) SELECT COALESCE(bigint_col,-20) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | INSERT INTO table2 (id, float_col) SELECT COALESCE(float_col,10.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | INSERT INTO table2 (id, double_col) SELECT COALESCE(double_col,-0.5) FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | INSERT INTO table2 (id, char10_col) SELECT COALESCE(char10_col,'0123456789') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | INSERT INTO table2 (id, varchar_col) SELECT COALESCE(varchar_col,'0123456789') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | INSERT INTO table2 (id, uuid_col) SELECT COALESCE(uuid_col,'0123456789') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | INSERT INTO table2 (id, link_col) SELECT COALESCE(link_col,'0123456789') FROM table1 datasource_type = {'ADB' | 'ADP' | 'ADQM'}; | . | COALESCE: ADB, ADP | . | INSERT INTO table2 (id, date_col) SELECT COALESCE(date_col,CAST('2001-02-03' AS DATE)) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | INSERT INTO table2 (id, time_col) SELECT COALESCE(time_col,CAST('12:12:12' AS TIME)) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . | INSERT INTO table2 (id, timestamp_col) SELECT COALESCE(timestamp_col,CAST('2001-02-03 12:12:12' AS TIMESTAMP)) FROM table1 datasource_type = {'ADB' | 'ADP'}; | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_support/sql_support.html#FinctionsinSQLplus",
    "relUrl": "/reference/sql_support/sql_support.html#FinctionsinSQLplus"
  },"117": {
    "doc": "Конфигурация системы",
    "title": "Конфигурация системы",
    "content": "Содержание раздела . | Конфигурация сервиса исполнения запросов . | Настройки журналирования | Настройки управления Prostore | Настройки сервиса исполнения запросов | Настройки СУБД ADB | Настройки СУБД ADG | Настройки СУБД ADQM | Настройки СУБД ADP | . | Конфигурация сервиса мониторинга статусов Kafka | . Конфигурация системы задается в текстовом YAML-файле. Параметры конфигурации организованы в иерархическую древовидную структуру. В разделе представлены примеры файлов конфигурации системы: конфигурации сервиса исполнения запросов и конфигурации сервиса мониторинга статусов Kafka. Перед каждым параметром указан комментарий, поясняющий назначение этого параметра. Для наглядности конфигурация сервиса исполнения запросов разделена на отдельные секции. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/system/system.html",
    "relUrl": "/maintenance/configuration/system/system.html"
  },"118": {
    "doc": "Конфигурация системы",
    "title": "Конфигурация сервиса исполнения запросов",
    "content": "Настройки журналирования . # настройки журналирования logging: # уровень важности сообщений, записываемых в лог-файл level: ru.datamart.prostore.query.execution: ${DTM_LOGGING_LEVEL:TRACE} . Настройки управления Prostore . # настройки сервера Prostore server: # номер порта сервиса метрик port: ${DTM_METRICS_PORT:8080} # настройки управления Prostore management: # настройки конечных точек Prostore endpoints: # признак генерации метрик со стороны Prostore enabled-by-default: ${DTM_METRICS_ENABLED:true} # настройки видимости метрик через веб-соединения web: exposure: # состав метрик, видимых через веб-соединения include: ${DTM_METRICS_SCOPE:info, health, requests} . Настройки сервиса исполнения запросов . # настройки сервиса исполнения запросов core: # настройки плагинов plugins: # список используемых СУБД active: ${CORE_PLUGINS_ACTIVE:ADG, ADB, ADP, ADQM} # порядок выбора СУБД хранилища для исполнения запросов на чтение и выгрузку данных category: # порядок выбора СУБД в зависимости от категории запроса; настройки используются, если отсутствует секция plugins.category.autoSelect mapping: # порядок для общих реляционных запросов RELATIONAL: ${DTM_CORE_PLUGINS_RELATIONAL:ADB, ADP, ADQM, ADG} # порядок для аналитических запросов ANALYTICAL: ${DTM_CORE_PLUGINS_ANALYTICAL:ADQM, ADB, ADP, ADG} # порядок для запросов ключ-значение DICTIONARY: ${DTM_CORE_PLUGINS_DICTIONARY:ADG, ADB, ADP, ADQM} # порядок для других категорий запросов UNDEFINED: ${DTM_CORE_PLUGINS_UNDEFINED:ADB, ADP, ADQM, ADG} # порядок выбора СУБД в зависимости от категории и подкатегории запроса autoSelect: # порядок для общих реляционных запросов RELATIONAL: # порядок для запросов, предназначенных для одного узла кластера SHARD_ONE: ${DTM_CORE_PLUGINS_AUTOSELECT_RELATIONAL_SHARDONE:ADB, ADP, ADQM, ADG} # порядок для запросов, предназначенных для нескольких узлов кластера (от 1 до всех) SHARD_SET: ${DTM_CORE_PLUGINS_AUTOSELECT_RELATIONAL_SHARDSET:ADB, ADP, ADQM, ADG} # порядок для запросов, предназначенных для всех узлов кластера SHARD_ALL: ${DTM_CORE_PLUGINS_AUTOSELECT_RELATIONAL_SHARDALL:ADB, ADP, ADQM, ADG} # порядок для аналитических запросов ANALYTICAL: # порядок для запросов, предназначенных для одного узла кластера SHARD_ONE: ${DTM_CORE_PLUGINS_AUTOSELECT_ANALYTICAL_SHARDONE:ADQM, ADB, ADP, ADG} # порядок для запросов, предназначенных для нескольких узлов кластера (от 1 до всех) SHARD_SET: ${DTM_CORE_PLUGINS_AUTOSELECT_ANALYTICAL_SHARDSET:ADQM, ADB, ADP, ADG} # порядок для запросов, предназначенных для всех узлов кластера SHARD_ALL: ${DTM_CORE_PLUGINS_AUTOSELECT_ANALYTICAL_SHARDALL:ADQM, ADB, ADP, ADG} # порядок для запросов ключ-значение DICTIONARY: # порядок для запросов, предназначенных для одного узла кластера SHARD_ONE: ${DTM_CORE_PLUGINS_AUTOSELECT_DICTIONARY_SHARDONE:ADG, ADB, ADP, ADQM} # порядок для запросов, предназначенных для нескольких узлов кластера (от 1 до всех) SHARD_SET: ${DTM_CORE_PLUGINS_AUTOSELECT_DICTIONARY_SHARDSET:ADG, ADB, ADP, ADQM} # порядок для запросов, предназначенных для всех узлов кластера SHARD_ALL: ${DTM_CORE_PLUGINS_AUTOSELECT_DICTIONARY_SHARDALL:ADG, ADB, ADP, ADQM} # порядок для других категорий запросов UNDEFINED: # порядок для запросов, предназначенных для одного узла кластера SHARD_ONE: ${DTM_CORE_PLUGINS_AUTOSELECT_UNDEFINED_SHARDONE:ADB, ADP, ADQM, ADG} # порядок для запросов, предназначенных для нескольких узлов кластера (от 1 до всех) SHARD_SET: ${DTM_CORE_PLUGINS_AUTOSELECT_UNDEFINED_SHARDSET:ADB, ADP, ADQM, ADG} # порядок для запросов, предназначенных для всех узлов кластера SHARD_ALL: ${DTM_CORE_PLUGINS_AUTOSELECT_UNDEFINED_SHARDALL:ADB, ADP, ADQM, ADG} # настройки сетевых подключений через HTTP-протокол http: # номер порта сервиса исполнения запросов port: ${DTM_CORE_HTTP_PORT:9090} # режим оптимизации работы сокета TCP_NODELAY tcpNoDelay: ${DTM_CORE_HTTP_TCP_NO_DELAY:true} # режим TCP FAST_OPEN tcpFastOpen: ${DTM_CORE_HTTP_TCP_FAST_OPEN:true} # режим оптимизации работы сокета TCP_QUICKACK tcpQuickAck: ${DTM_CORE_HTTP_TCP_QUICK_ACK:true} # настройки окружения env: # имя окружения для формирования полных имен логических БД name: ${DTM_NAME:test} # настройки восстановления состояния при запуске и перезапуске системы restoration: # признак восстановления состояния при запуске и перезапуске системы autoRestoreState: ${AUTO_RESTORE_STATE:true} # настройки синхронизации материализованных представлений matviewsync: # периодичность запуска синхронизации в миллисекундах; если значение равно 0, синхронизация отключена periodMs: ${MATERIALIZED_VIEWS_SYNC_PERIOD_MS:5000} # максимальное количество попыток синхронизации представления, после перезапуска системы счетчик обнуляется retryCount: ${MATERIALIZED_VIEWS_RETRY_COUNT:10} # максимальное количество представлений, синхронизируемых одновременно maxConcurrent: ${MATERIALIZED_VIEWS_CONCURRENT:2} # настройки генерации метрики сервиса исполнения запросов metrics: # признак генерации метрик сервиса исполнения запросов enabled: ${DTM_CORE_METRICS_ENABLED:true} # настройки источника данных datasource: # настройки для EDML-операторов edml: # количество записей, по умолчанию выгружаемых в одном сообщении топика Каfka defaultChunkSize: ${EDML_DEFAULT_CHUNK_SIZE:1000} # период проверки статуса плагина в миллисекундах pluginStatusCheckPeriodMs: ${EDML_STATUS_CHECK_PERIOD_MS:1000} # время ожидания (в миллисекундах) до тайм-аута при работе с первым смещением в топике Kafka firstOffsetTimeoutMs: ${EDML_FIRST_OFFSET_TIMEOUT_MS:15000} # время ожидания (в миллисекундах) до тайм-аута при ожидании смены смещения в топике Kafka changeOffsetTimeoutMs: ${EDML_CHANGE_OFFSET_TIMEOUT_MS:10000} # настройки Zookeeper zookeeper: # сетевой адрес хоста Zookeeper для сервисной БД connection-string: ${ZOOKEEPER_DS_ADDRESS:localhost} # время ожидания (в миллисекундах) соединения с хостом Zookeeper для сервисной БД до достижения тайм-аута connection-timeout-ms: ${ZOOKEEPER_DS_CONNECTION_TIMEOUT_MS:30000} # время бездействия (в миллисекундах) в сессии хоста Zookeeper для сервисной БД до достижения тайм-аута session-timeout-ms: ${ZOOKEEPER_DS_SESSION_TIMEOUT_MS:86400000} # корневой путь к хосту Zookeeper для сервисной БД chroot: ${ZOOKEEPER_DS_CHROOT:/adtm} # настройки взаимодействия сервиса исполнения запросов с брокером сообщений Kafka kafka: producer: property: # сериализатор строковых ключей key.serializer: org.apache.kafka.common.serialization.StringSerializer # сериализатор строковых значений value.serializer: org.apache.kafka.common.serialization.StringSerializer # настройки кластера Zookeeper для взаимодействия с брокером сообщений Kafka cluster: zookeeper: # сетевой адрес хоста Zookeeper для брокера сообщений Kafka connection-string: ${ZOOKEEPER_KAFKA_ADDRESS:localhost} # время ожидания (в миллисекундах) соединения с хостом Zookeeper для брокера сообщений Kafka до достижения тайм-аута connection-timeout-ms: ${ZOOKEEPER_KAFKA_CONNECTION_TIMEOUT_MS:30000} # время бездействия (в миллисекундах) в сессии хоста Zookeeper для брокера сообщений Kafka до достижения тайм-аута session-timeout-ms: ${ZOOKEEPER_KAFKA_SESSION_TIMEOUT_MS:86400000} # корневой путь к хосту Zookeeper для брокера сообщений Kafka chroot: ${ZOOKEEPER_KAFKA_CHROOT:} # настройки администратора Kafka admin: # время ожидания (в миллисекундах) входного потока данных для брокера сообщений Kafka до достижения тайм-аута inputStreamTimeoutMs: ${KAFKA_INPUT_STREAM_TIMEOUT_MS:2000} # настройки статусов публикации событий брокером сообщений Kafka status.event.publish: # имя топика Kafka, в который публикуются события topic: ${KAFKA_STATUS_EVENT_TOPIC:status.event.topic} # разрешение на публикацию событий enabled: ${KAFKA_STATUS_EVENT_ENABLED:false} # настройки подключения к сервису мониторинга статусов Kafka statusMonitor: # сетевой адрес и путь для получения информации о статусе сервиса statusUrl: ${STATUS_MONITOR_URL:http://localhost:9095/status} # сетевой адрес и путь для получения информации о версии сервиса versionUrl: ${STATUS_MONITOR_VERSION_URL:http://localhost:9095/versions} # настройки при использовании фреймворка vertx vertx: # время в (секундах), после которого заблокированный поток пишет stacktrace blocking-stacktrace-time: ${DTM_VERTX_BLOCKING_STACKTRACE_TIME:1} pool: # максимальный размер пула потоков, выполняющих долгие операции worker-pool: ${DTM_CORE_WORKER_POOL_SIZE:20} # максимальный размер пула потоков, обрабатывающих события vertx event-loop-pool: ${DTM_CORE_EVENT_LOOP_POOL_SIZE:20} # максимальный размер пула задач в сервисе исполнения запросов task-pool: ${DTM_CORE_TASK_POOL_SIZE:20} # время (в миллисекундах) завершения задачи, выполняемой в сервисе исполнения запросов task-timeout: ${DTM_CORE_TASK_TIMEOUT:86400000} # настройки кэширования запросов cache: # начальная емкость кэша initialCapacity: ${CACHE_INITIAL_CAPACITY:100000} # максимальный размер кэша maximumSize: ${CACHE_MAXIMUM_SIZE:100000} # время (в минутах) устаревания кэша после последнего обращения к нему expireAfterAccessMinutes: ${CACHE_EXPIRE_AFTER_ACCESS_MINUTES:99960} # настройки отката дельты delta: # периодичность (в миллисекундах) проверки операций записи, требующих остановки rollback-status-calls-ms: ${DELTA_ROLLBACK_STATUS_CALLS_MS:2000} . Настройки СУБД ADB . # настройки ADB adb: # настройки источника данных ADB datasource: # имя пользователя/логин для авторизации в ADB user: ${ADB_USERNAME:dtm} # пароль для авторизации в ADB password: ${ADB_PASS:dtm} # сетевой адрес хоста с ADB host: ${ADB_HOST:localhost} # сетевой адрес порта на хосте с ADB port: ${ADB_PORT:5432} # лимит подключений к ADB в одном потоке; лимит по всем потокам равен произведению poolSize и executorsCount poolSize: ${ADB_MAX_POOL_SIZE:3} # количество одновременных потоков, исполняющих запросы к ADB executorsCount: ${ADB_EXECUTORS_COUNT:3} # максимальный размер результата, возвращаемого по FETCH-запросу к ADB fetchSize: ${ADB_FETCH_SIZE:1000} # максимальный размер кэша запроса prepared statement preparedStatementsCacheMaxSize: ${ADB_PREPARED_CACHE_MAX_SIZE:256} # максимальный размер запроса prepared statement, который может быть закэширован preparedStatementsCacheSqlLimit: ${ADB_PREPARED_CACHE_SQL_LIMIT:2048} # признак кэширования запросов prepared statement preparedStatementsCache: ${ADB_PREPARED_CACHE:true} # максимальное количество попыток восстановить соединение (0 — неограниченно) maxReconnections: ${ADB_MAX_RECONNECTIONS:0} # максимальное количество запросов, проходящих через соединение перед его переподключением (0 - неограниченно) queriesByConnectLimit: ${ADB_QUERIES_BY_CONNECT_LIMIT:1000} # интервал (в миллисекундах) между попытками восстановить соединение (0 — без интервала) reconnectionInterval: ${ADB_RECONNECTION_INTERVAL:5000} # настройки механизма загрузки данных в ADB mppw: # признак использования улучшенного PXF-коннектора; при значении false данные загружаются с помощью FDW-коннектора usePxfConnector: ${ADB_MPPW_USE_ADVANCED_CONNECTOR:false} # имя консьюмер-группы ADB для взаимодействия с брокером сообщений Kafka consumerGroup: ${ADB_LOAD_GROUP:adb-emulator-load-adb} # максимальный размер пула подключений к ADB для операций загрузки данных poolSize: ${ADB_MPPW_POOL_SIZE:2} # время ожидания (в миллисекундах) до остановки загрузки stopTimeoutMs: ${ADB_MPPW_STOP_TIMEOUT_MS:86400000} # максимальное количество сообщений для операций загрузки данных в ADB defaultMessageLimit: ${ADB_MPPW_DEFAULT_MESSAGE_LIMIT:100} # время ожидания (в миллисекундах) для FDW-коннектора ADB fdwTimeoutMs: ${ADB_MPPW_FDW_TIMEOUT_MS:1000} # признак использования исторических таблиц with-history-table: ${ADB_WITH_HISTORY_TABLE:false} . Настройки СУБД ADG . # настройки ADG adg: tarantool: db: # сетевой адрес хоста с ADG host: ${TARANTOOL_DB_HOST:localhost} # сетевой адрес порта на хосте с ADG port: ${TARANTOOL_DB_PORT:3306} # имя пользователя/логин для авторизации в ADG user: ${TARANTOOL_DB_USER:admin} # пароль для авторизации в ADG password: ${TARANTOOL_DB_PASS:memstorage-cluster-cookie} # время ожидания (в миллисекундах) выполнения операции ADG operationTimeout: ${TARANTOOL_DB_OPER_TIMEOUT:60000} # максимальное количество повторных попыток выполнения операции retryCount: ${TARANTOOL_DB_RETRY_COUNT:0} # движок ADG engine: ${TARANTOOL_DEFAULT_ENGINE:MEMTX} # количество вертиклов, обрабатывающих запросы к ADG vertxWorkers: ${TARANTOOL_VERTX_WORKERS:10} # настройки синхронизации материализованных представлений в ADG sync: # тайм-аут подключения к ADG (в миллисекундах) timeout_connect: ${TARANTOOL_DB_SYNC_CONNECTION_TIMEOUT:5000} # тайм-аут чтения из ADG (в миллисекундах) timeout_read: ${TARANTOOL_DB_SYNC_READ_TIMEOUT:5000} # тайм-аут запроса в ADG (в миллисекундах) timeout_request: ${TARANTOOL_DB_SYNC_REQUEST_TIMEOUT:5000} # настройки картриджа Tatantool cartridge: # сетевой путь и порт к картриджу Tarantool url: ${TARANTOOL_CATRIDGE_URL:http://localhost:8086} # настройки механизма загрузки данных mppw: # имя консьюмер-группы ADG для взаимодействия с брокером сообщений Kafka consumerGroup: ${ADG_CONSUMER_GROUP:tarantool-group-csv} # максимальное количество сообщений в топике Kafka на раздел ADG maxNumberOfMessagesPerPartition: ${ADG_MAX_MSG_PER_PARTITION:200} # время простоя (в секундах) callback-функции callbackFunctionSecIdle: ${ADG_CB_FUNC_IDLE:100} # настройки отката операции rollback: # размер пакета операций при откате eraseOperationBatchSize: ${ADG_ROLLBACK_OPERATION_BATCH_SIZE:300} # настройки отказоустойчивости ADG по паттерну circuitbreaker circuitbreaker: # максимальное количество отказов ADG maxFailures: ${ADG_CIRCUIT_BREAKER_MAX_FAILURES:5} # время ожидания (в миллисекундах) отклика ADG до фиксации отказа timeout: ${ADG_CIRCUIT_BREAKER_TIMEOUT:30000} # использование паттерна fallback при отказе fallbackOnFailure: ${ADG_CIRCUIT_BREAKER_FALLBACK_ON_FAILURE:false} # время ожидания (в миллисекундах) до сброса по паттерну timeout resetTimeout: ${ADG_CIRCUIT_BREAKER_RESET_TIMEOUT:10000} # настройки для подключений веб-клиентов web-client: # максимальный размер пула подключений веб-клиентов к ADG max-pool-size: ${ADG_WEB_CLIENT_MAX_POOL_SIZE:100} . Настройки СУБД ADQM . # настройки ADQM adqm: # настройки источника данных ADQM datasource: # имя ADQM database: ${ADQM_DB_NAME:default} # имя пользователя/логин для авторизации в ADQM user: ${ADQM_USERNAME:} # пароль для авторизации в ADQM password: ${ADQM_PASS:} # сетевой адрес хоста с ADQM и номер порта на хосте hosts: ${ADQM_HOSTS:localhost:8123} # время ожидания (в миллисекундах) отклика соединения с ADQM до тайм-аута socketTimeout: ${ADQM_SOCKET_TIMEOUT:30000} # время ожидания (в миллисекундах) завершения обмена данными с ADQM до тайм-аута dataTransferTimeout: ${ADQM_DATA_TRANSFER_TIMEOUT:10000} # настройки DDL-операторов ddl: # имя кластера ADQM cluster: ${ADQM_CLUSTER:default_cluster} # алгоритм шардирования данных; # возможные значения: CITY_HASH_64 (значение по умолчанию в версии 5.3 и выше), INT_ADD (значение по умолчанию в версии 5.2 и ниже) shardingKeyExpr: ${ADQM_SHARDING_EXPR:CITY_HASH_64} # настройки механизма выгрузки данных из ADQM mppr: # сетевой адрес и путь для запросов на выгрузку данных loadingUrl: ${ADQM_MPPR_CONNECTOR_URL:http://localhost:8086/query} # сетевой адрес и путь для получения информации о версии коннектора versionUrl: ${ADQM_MPPR_CONNECTOR_VERSION_URL:http://localhost:8086/versions} # настройки механизма загрузки данных в ADQM mppw: # имя консьюмер-группы для загрузки данных в ADQM # не используется consumerGroup: ${ADQM_CONSUMER_GROUP:adqm} # сетевой адрес брокера сообщений Kafka kafkaBrokers: ${ADQM_BROKERS:localhost:9092} # тип интерфейса для загрузки данных в ADQM loadType: ${ADQM_MPPW_LOAD_TYPE:REST} # сетевой адрес и путь к REST-интерфейсу для загрузки новых данных в ADQM restStartLoadUrl: ${ADQM_REST_START_LOAD_URL:http://localhost:8090/newdata/start} # сетевой адрес и путь к REST-интерфейсу для остановки загрузки данных в ADQM restStopLoadUrl: ${ADQM_REST_STOP_LOAD_URL:http://localhost:8090/newdata/stop} # сетевой адрес и путь для получения информации о версии коннектора versionUrl: ${ADQM_MPPW_CONNECTOR_VERSION_URL:http://localhost:8090/versions} # имя коньсюмер-группы для загрузки данных в ADQM через REST API restLoadConsumerGroup: ${ADQM_REST_LOAD_GROUP:adb-emulator-load-adqm} # настройки подключений веб-клиентов web-client: # максимальный размер пула подключений веб-клиентов к ADQM max-pool-size: ${ADQM_WEB_CLIENT_MAX_POOL_SIZE:100} . Настройки СУБД ADP . # настройки ADP adp: # настройки источника данных ADP datasource: # имя пользователя/логин для авторизации в ADP user: ${ADP_USERNAME:dtm} # пароль для авторизации в ADP password: ${ADP_PASS:dtm} # сетевой адрес хоста с ADP host: ${ADP_HOST:localhost} # сетевой адрес порта на хосте с ADP port: ${ADP_PORT:5432} # лимит подключений к ADP в одном потоке; лимит по всем потокам равен произведению poolSize и executorsCount poolSize: ${ADP_MAX_POOL_SIZE:3} # количество одновременных потоков, исполняющих запросы к ADP executorsCount: ${ADP_EXECUTORS_COUNT:3} # максимальный размер результата, возвращаемого по FETCH-запросу к ADP fetchSize: ${ADP_FETCH_SIZE:1000} # максимальный размер кэша запроса prepared statement preparedStatementsCacheMaxSize: ${ADP_PREPARED_CACHE_MAX_SIZE:256} # максимальный размер запроса prepared statement, который может быть закэширован preparedStatementsCacheSqlLimit: ${ADP_PREPARED_CACHE_SQL_LIMIT:2048} # признак кэширования запросов prepared statement preparedStatementsCache: ${ADP_PREPARED_CACHE:true} # настройки механизма загрузки данных в ADP mppw: # сетевой адрес и путь к REST-интерфейсу для загрузки данных в ADP restStartLoadUrl: ${ADP_REST_START_LOAD_URL:http://localhost:8096/newdata/start} # сетевой адрес и путь к REST-интерфейсу для остановки загрузки данных в ADP restStopLoadUrl: ${ADP_REST_STOP_LOAD_URL:http://localhost:8096/newdata/stop} # сетевой адрес и путь для получения информации о версии коннектора restVersionUrl: ${ADP_MPPW_CONNECTOR_VERSION_URL:http://localhost:8096/versions} # имя коньсюмер-группы для загрузки данных в ADP через REST API kafkaConsumerGroup: ${ADP_KAFKA_CONSUMER_GROUP:adp-load} # настройки механизма выгрузки данных из ADP mppr: # сетевой адрес и путь для запросов на выгрузку данных из ADP restLoadUrl: ${ADP_MPPR_QUERY_URL:http://localhost:8094/query} # сетевой адрес и путь для получения информации о версии коннектора restVersionUrl: ${ADP_MPPR_CONNECTOR_VERSION_URL:http://localhost:8094/versions} . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/system/system.html#core_configuration",
    "relUrl": "/maintenance/configuration/system/system.html#core_configuration"
  },"119": {
    "doc": "Конфигурация системы",
    "title": "Конфигурация сервиса мониторинга статусов Kafka",
    "content": "# настройки cервиса мониторинга статусов Kafka monitor: # список адресов брокеров сообщений Kafka brokersList: ${STATUS_MONITOR_BROKERS:localhost:9092} # количество потребителей (консьюмеров) cервиса мониторинга Kafka consumersCount: ${STATUS_MONITOR_CONSUMERS:8} . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/configuration/system/system.html#status_monitor_configuration",
    "relUrl": "/maintenance/configuration/system/system.html#status_monitor_configuration"
  },"120": {
    "doc": "Введение",
    "title": "Введение",
    "content": "Введение . Prostore (далее — система) — система для построения витрин данных, позволяющая работать как с актуальными, так и архивными данными. Система выполняет роль интеграционного сервиса, объединяющего различные СУБД хранилища, и предоставляет следующие возможности: . | работа с данными с использованием единой логической схемы данных, которая не зависит от типа СУБД хранилища; | добавление данных: . | параллельная загрузка больших объемов данных из внешнего источника данных; | обновление небольших объемов данных с низкой задержкой; | . | получение данных, актуальных на указанный момент времени: . | параллельная выгрузка больших объемов данных во внешний приемник данных; | запрос небольших объемов данных с низкой задержкой; | . | работа с историей изменений данных: . | удаление архивных данных старше указанного момента времени; | полное удаление данных в соответствии с указанным условием. | . | . Работа с системой возможна с помощью любых программ, которые предоставляют подключение через JDBC-интерфейс. Для работы с системой используется декларативный язык запросов на основе SQL, в некоторых случаях совпадающий с SQL-стандартом (см. Запросы SQL+). ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/introduction/introduction.html",
    "relUrl": "/introduction/introduction.html"
  },"121": {
    "doc": "Поддерживаемые СУБД хранилища",
    "title": "Поддерживаемые СУБД хранилища",
    "content": "Поддерживаемые СУБД хранилища . Система поддерживает работу со следующими СУБД хранилища: . | Arenadata DB (ADB) — СУБД с массивно-параллельной архитектурой (Massive parallel processing, MPP), построенная на основе Greenplum; | Arenadata QuickMarts (ADQM) — кластерная колоночная СУБД на основе Yandex ClickHouse; | Arenadata Grid (ADG) — система распределенных вычислений в оперативной памяти, построенная на основе Tarantool; | PostgreSQL (ADP) — свободная объектно-реляционная СУБД на основе PostgreSQL. | . Система позволяет работать с перечисленными СУБД одинаковым образом, используя единый синтаксис запросов SQL+ и единую логическую схему данных. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/introduction/supported_DBMS/supported_DBMS.html",
    "relUrl": "/introduction/supported_DBMS/supported_DBMS.html"
  },"122": {
    "doc": "Термины и определения",
    "title": "Термины и определения",
    "content": "Термины и определения . Система — система Prostore, описываемая в этом документе. Внешняя информационная система — внешняя система, которая является источником загружаемых и обновляемых данных и (или) получателем выгружаемых и запрашиваемых данных. СУБД хранилища (СУБД) — СУБД хранилища данных из числа поддерживаемых системой. Загрузка данных — параллельная запись данных в систему из внешнего источника данных. Функция предназначена для записи большого объема данных: от сотен до миллионов строк. Обновление данных — запись данных в систему, выполняемая с низкой задержкой. Функция предназначена для записи небольшого объема данных (до нескольких десятков строк). Выгрузка данных — параллельная выгрузка данных из системы во внешний приемник данных. Функция предназначена для получения большого объема данных: от сотен до миллионов строк. Запрос данных — чтение данных из системы, выполняемое с низкой задержкой. Функция предназначена для получения небольшого объема данных (до нескольких десятков строк). СУБД выгрузки данных — СУБД, из которой выгружаются данные системы. СУБД выгрузки данных указывается в запросе или определяется системой на основе следующих факторов: параметров запроса, месторасположения данных и конфигурации системы. Фиксация изменений данных — процесс сохранения состояния данных системы, который должен быть запущен соответствующей командой после загрузки и (или) обновления данных. Горячая запись — запись, которая загружена в систему, но еще не зафиксирована. После фиксации изменений горячая запись перемещается в категорию актуальных. Актуальная запись — зафиксированная запись, которая является актуальной на данный момент. Архивная запись — зафиксированная запись, которая больше не является актуальной. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/introduction/terms/terms.html",
    "relUrl": "/introduction/terms/terms.html"
  },"123": {
    "doc": "Схемы развертывания",
    "title": "Схемы развертывания",
    "content": "Схемы развертывания . Систему можно разворачивать различными способами, устанавливая различные наборы связанных компонентов, — в зависимости от целей проекта. Однако есть основные схемы развертывания системы: . | с кластерами каждой из следующих СУБД хранилища: ADB, ADQM и ADG; | с сервером одной СУБД хранилища — ADP. | . На рисунке ниже показана схема развертывания системы с ADB, ADQM и ADG. Стрелки направлены от вызывающих компонентов к вызываемым. Схема развертывания с ADB, ADQM и ADG . На рисунке ниже показана схема развертывания системы с ADP. Стрелки направлены от вызывающих компонентов к вызываемым. Схема развертывания с ADP . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/deployment_diagrams/deployment_diagrams.html",
    "relUrl": "/maintenance/deployment_diagrams/deployment_diagrams.html"
  },"124": {
    "doc": "Настройка JSON-логов",
    "title": "Настройка JSON-логов",
    "content": "Настройка JSON-логов . Система поддерживает конфигурацию и отображение JSON-логов проекта Logback. Помимо стандартных параметров, таких как время сообщения, уровень логирования и т.д., система позволяет отображать в логах уникальные идентификаторы запросов. Если отображение идентификаторов настроено, для каждого запроса SQL+ отображается уникальный идентификатор, для внутреннего запроса системы — значение no_id. Чтобы настроить отображение идентификаторов запросов в логах, отредактируйте файл logback.xml (полный пример файла см. ниже): . | Перед объявлением appender добавьте строки: . &lt;conversionRule conversionWord=\"vcl\" converterClass=\"io.reactiverse.contextual.logging.LogbackConverter\"/&gt; . | В секцию appender.providers.pattern добавьте строку: . \"requestId\": \"%vcl{requestId:-no_id}\" . | . Ниже показан пример файла logback.xml с включенным отображением идентификаторов запросов: . &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;configuration&gt; &lt;conversionRule conversionWord=\"vcl\" converterClass=\"io.reactiverse.contextual.logging.LogbackConverter\"/&gt; &lt;appender name=\"rollingFile\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;logs/application.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- daily rollover --&gt; &lt;fileNamePattern&gt;logs/application.%d{yyyy-MM-dd}.log.gz&lt;/fileNamePattern&gt; &lt;!-- keep 30 days' worth of history capped at 3GB total size --&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;totalSizeCap&gt;3GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder\"&gt; &lt;providers&gt; &lt;pattern&gt; &lt;omitEmptyFields&gt;true&lt;/omitEmptyFields&gt; &lt;pattern&gt; { \"timestamp\": \"%date{ISO8601}\", \"logger\": \"%logger\", \"level\": \"%level\", \"thread\": \"%thread\", \"requestId\": \"%vcl{requestId:-no_id}\", \"message\": \"%message\" } &lt;/pattern&gt; &lt;/pattern&gt; &lt;stackTrace&gt; &lt;throwableConverter class=\"net.logstash.logback.stacktrace.ShortenedThrowableConverter\"&gt; &lt;maxDepthPerThrowable&gt;30&lt;/maxDepthPerThrowable&gt; &lt;maxLength&gt;2048&lt;/maxLength&gt; &lt;shortenedClassNameLength&gt;20&lt;/shortenedClassNameLength&gt; &lt;exclude&gt;^sun\\.reflect\\..*\\.invoke&lt;/exclude&gt; &lt;exclude&gt;^net\\.sf\\.cglib\\.proxy\\.MethodProxy\\.invoke&lt;/exclude&gt; &lt;rootCauseFirst&gt;true&lt;/rootCauseFirst&gt; &lt;/throwableConverter&gt; &lt;/stackTrace&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"rollingFile\" /&gt; &lt;/root&gt; &lt;/configuration&gt; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/json_logs_configuration/json_logs_configuration.html",
    "relUrl": "/maintenance/json_logs_configuration/json_logs_configuration.html"
  },"125": {
    "doc": "Минимальные системные требования",
    "title": "Минимальные системные требования",
    "content": "Минимальные системные требования . Аппаратные требования системы . Система предъявляет следующие минимальные аппаратные требования: . | ядро системы: 4 CPU, 16 RAM, 20 HDD; | сервис мониторинга статусов Kafka: 2 CPU, 8 RAM, 20 HDD. | . Программные требования системы . Система предъявляет следующие минимальные программные требования: . | компоненты Prostore: . | сервис исполнения запросов (query-execution-core) версии 5.3.0, | сервис мониторинга статусов Kafka (status-monitor) версии 5.3.0, | JDBC-драйвер версии 5.3.0, | . | ADB версии 6.17.5, . | коннектор Kafka-Greenplum reader (PXF) версии 1.0, | коннектор Kafka-Greenplum writer (FDW) версии 0.10.2, | . | ADQM версии 20.4.4.18, . | коннектор Kafka-Clickhouse reader версии 3.5.6, | коннектор Kafka-Clickhouse writer версии 3.5.6, | . | ADG версии 2.7.3, . | коннектор Kafka-Tarantool версии 0.8.5-1, | . | PostgreSQL версии 13.5, . | коннектор Kafka-Postgres reader версии 0.1.7, | коннектор Kafka-Postgres writer версии 0.1.7, | . | ADS: . | ADS версии 1.5, | Kafka версии 2.4, | Zookeeper версии 3.5.6. | . | . Ссылки на репозитории с исходным кодом коннекторов доступны в разделе Ресурсы. Аппаратные и программные требования компонентов . Компоненты, с которыми работает система, предъявляют минимальные требования, перечисленные в таблице ниже. | Компонент | Системные требования | . | ADB | https://docs.arenadata.io/adb/requirements/online.html#id2 | . | ADQM | https://docs.arenadata.io/adqm/requirements/index.html#clickhouse | . | ADG (Tarantool) | https://www.tarantool.io/en/sizing_calculator/ | . | PostgreSQL | https://postgrespro.ru/docs/postgresql/13/install-requirements | . | Kafka | https://docs.arenadata.io/ads/Requirements/min.html | . | Zookeeper | https://docs.arenadata.io/ads/Requirements/min.html | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/system_requirements/system_requirements.html",
    "relUrl": "/maintenance/system_requirements/system_requirements.html"
  },"126": {
    "doc": "Часовые пояса системы и компонентов",
    "title": "Часовые пояса системы и компонентов",
    "content": "Часовые пояса системы и компонентов . | Значения времени должны лежать в диапазоне от 00:00:00.000000 до 23:59:59.999999 включительно. | Все значения типа TIMESTAMP, загружаемые в систему и выгружаемые из нее, не содержат данных о часовых поясах и рассматриваются системой как время UTC. | Часовой пояс хранилища данных должен быть задан как UTC. | JDBC-функции getDate, getTime и getTimestamp системы возвращают дату и время SQL без указания часового пояса (значение java.sql.date, нормализованное относительно GMT+0). | . Загружаемое и возвращаемое значения типа TIMESTAMP . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/maintenance/time_zones/time_zones.html",
    "relUrl": "/maintenance/time_zones/time_zones.html"
  },"127": {
    "doc": "Компоненты системы",
    "title": "Компоненты системы",
    "content": "Компоненты системы . Система состоит из следующих компонентов (см. рисунок ниже): . | JDBC-драйвер — размещается на стороне внешней информационной системы; предоставляет JDBC-интерфейс подключения к Prostore и взаимодействует с сервисом исполнения запросов по REST API; | сервис исполнения запросов — анализирует и исполняет SQL-запросы; предоставляет REST API для JDBC-драйвера и взаимодействует с сервисом мониторинга статусов Kafka по REST API; | сервис мониторинга статусов Kafka — отслеживает состояние топиков брокера сообщений Kafka; предоставляет REST API для сервиса исполнения запросов. | . Версии используемых компонентов системы можно проверить с помощью запроса CHECK_VERSIONS. На рисунке ниже показана схема компонентов системы. Компоненты системы . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/components/components.html",
    "relUrl": "/overview/components/components.html"
  },"128": {
    "doc": "Порядок обработки запросов на обновление логической схемы",
    "title": "Порядок обработки запросов на обновление логической схемы",
    "content": "Порядок обработки запросов на обновление логической схемы . Запрос на обновление логической схемы данных обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос на обновление логической схемы данных, используя JDBC-драйвер Prostore. | Запрос поступает в сервис исполнения запросов Prostore. | Сервис исполнения запросов определяет, для каких СУБД хранилища предназначен запрос, модифицирует (обогащает) запрос нужным образом и отправляет в соответствующие СУБД команду на обновление физической схемы данных. | Сервис исполнения запросов сохраняет изменения логической схемы данных в сервисной базе данных. | Сервис исполнения запросов публикует сообщение об обновлении логической схемы данных в топике Kafka, указанном в конфигурации системы (см. параметр KAFKA_STATUS_EVENT_TOPIC). | После успешного обновления логической и физической схем данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/interactions/ddl_processing/ddl_processing.html",
    "relUrl": "/overview/interactions/ddl_processing/ddl_processing.html"
  },"129": {
    "doc": "Порядок обработки запросов на выгрузку данных",
    "title": "Порядок обработки запросов на выгрузку данных",
    "content": "Порядок обработки запросов на выгрузку данных . Запрос на выгрузку данных обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос INSERT INTO download_external_table, используя JDBC-драйвер Prostore. | Запрос поступает в сервис исполнения запросов Prostore. | Сервис исполнения запросов анализирует запрос и запрашивает актуальную информацию о логической схеме данных в сервисной базе данных. | Сервис исполнения запросов определяет, из какой СУБД хранилища следует выгрузить данные с учетом параметров запроса, месторасположения данных и конфигурации системы. Затем сервис отправляет в соответствующий коннектор команду на выгрузку данных из выбранной СУБД. | Коннектор выгружает данные в топик Kafka, который определен в свойствах внешней таблицы выгрузки, указанной в запросе. | После успешного выполнения выгрузки данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/interactions/download_processing/download_processing.html",
    "relUrl": "/overview/interactions/download_processing/download_processing.html"
  },"130": {
    "doc": "Связи с другими системами и компонентами",
    "title": "Связи с другими системами и компонентами",
    "content": "Связи с другими системами и компонентами . Система взаимодействует со следующими внешними системами и компонентами (см. рисунок ниже): . | внешней информационной системой-клиентом (по JDBC-интерфейсу), | сервисной базой данных (по API ZooKeeper), | СУБД хранилища данных (по интерфейсу JDBC или REST API — в зависимости от типа СУБД), | коннекторами (по API коннекторов); | брокером сообщений Kafka (по API Kafka). | . На рисунке ниже показаны взаимодействия системы с внешними системами и компонентами. Состав внешних компонентов, с которыми работает система, может меняться в зависимости от требований проекта (см. раздел Схемы развертывания). Внешние взаимодействия системы . Взаимодействия системы с внешними системами и компонентами при выполнении основных действий описаны в разделах: . | Порядок обработки запросов на обновление логической схемы, | Порядок обработки запросов на загрузку данных, | Порядок обработки запросов на выгрузку данных, | Порядок обработки запросов на чтение данных. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/interactions/interactions.html",
    "relUrl": "/overview/interactions/interactions.html"
  },"131": {
    "doc": "Порядок обработки запросов на чтение данных",
    "title": "Порядок обработки запросов на чтение данных",
    "content": "Порядок обработки запросов на чтение данных . Запросы на чтение данных обрабатываются в следующем порядке: . | Внешняя информационная система формирует запрос, используя JDBC-драйвер Prostore. | Запрос поступает в сервис исполнения запросов Prostore. | Сервис исполнения запросов анализирует запрос и запрашивает актуальную информацию о логической схеме данных в сервисной базе данных. | Сервис исполнения запросов определяет, для какой СУБД хранилища данных предназначен запрос, модифицирует (обогащает) запрос нужным образом и отправляет в эту СУБД команду на исполнение обогащенного запроса. | После успешного выполнения чтения данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/interactions/llr_processing/llr_processing.html",
    "relUrl": "/overview/interactions/llr_processing/llr_processing.html"
  },"132": {
    "doc": "Порядок обработки запросов на обновление данных",
    "title": "Порядок обработки запросов на обновление данных",
    "content": "Порядок обработки запросов на обновление данных . Запрос на обновление данных в логической таблице обрабатывается в следующем порядке: . | Внешняя информационная система отправляет запрос INSERT VALUES, INSERT SELECT, UPSERT VALUES или DELETE, используя JDBC-драйвер Prostore. | Запрос поступает в сервис исполнения запросов Prostore. | Сервис исполнения запросов анализирует запрос и сохраняет информацию о процессе обновления данных в сервисной базе данных. | Сервис исполнения запросов отправляет запрос на обновление данных в каждую из целевых СУБД хранилища. Под целевыми понимаются СУБД, в которых размещаются данные логической таблицы (см. CREATE TABLE). | По завершении загрузки всех данных сервис исполнения запросов отправляет в целевые СУБД команду на выполнение задач по версионированию данных. | После успешного обновления данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/interactions/llw_processing/llw_processing.html",
    "relUrl": "/overview/interactions/llw_processing/llw_processing.html"
  },"133": {
    "doc": "Порядок перезапуска системы",
    "title": "Порядок перезапуска системы",
    "content": "Порядок перезапуска системы . При перезапуске системы выполняются следующие действия: . | Возобновляются незавершенные операции записи: . | по всем операциям в статусе «Отменяется» запускается отмена, | по операциям загрузки данных в статусе «Выполняется» возобновляется отслеживание загрузки данных в СУБД хранилища. | . | Запускается синхронизация материализованных представлений окружения, если она включена в конфигурации системы. | . Синхронизацией материализованных представлений можно управлять с помощью параметра конфигурации MATERIALIZED_VIEWS_SYNC_PERIOD_MS. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/interactions/restart_processing/restart_processing.html",
    "relUrl": "/overview/interactions/restart_processing/restart_processing.html"
  },"134": {
    "doc": "Порядок обработки запросов на загрузку данных",
    "title": "Порядок обработки запросов на загрузку данных",
    "content": "Порядок обработки запросов на загрузку данных . Запрос на загрузку данных в логическую таблицу обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос INSERT INTO logical_table, используя JDBC-драйвер Prostore. | Запрос поступает в сервис исполнения запросов Prostore. | Сервис исполнения запросов анализирует запрос и сохраняет информацию о процессе загрузки данных в сервисной базе данных. | Сервис исполнения запросов отправляет в коннектор каждой из целевых СУБД хранилища команду на загрузку данных и отслеживает состояние загрузки с помощью сервиса мониторинга статусов Kafka. Под целевыми подразумеваются СУБД, в которых размещаются данные логической таблицы (см. CREATE TABLE). | Коннектор загружает данные из топика Kafka, который определен в свойствах внешней таблицы загрузки, указанной в запросе. | По завершении загрузки всех или каждого пакета данных (в зависимости от типа СУБД) сервис исполнения запросов отправляет в целевые СУБД команду на выполнение задач по версионированию данных. | После успешного выполнения загрузки данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/interactions/upload_processing/upload_processing.html",
    "relUrl": "/overview/interactions/upload_processing/upload_processing.html"
  },"135": {
    "doc": "Журнал",
    "title": "Журнал",
    "content": "Журнал . Журнал — список операций по созданию, удалению и изменению таблиц и представлений логической базы данных. В журнал записываются успешно выполненные и выполняемые в текущий момент изменения. Журнал содержит изменения по следующим сущностям логической БД: . | логическим таблицам, | логическим представлениям, | материализованным представлениям. | . Журнал хранится в сервисной базе данных и доступен для просмотра с помощью запроса GET_CHANGES. Журнал ведется в системе, начиная с версии 5.3. Изменения, выполненные в более ранних версиях, в журнале отсутствуют. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/changelog/changelog.html",
    "relUrl": "/overview/main_concepts/changelog/changelog.html"
  },"136": {
    "doc": "Хранилище данных",
    "title": "Хранилище данных",
    "content": "Хранилище данных . Физическое хранилище данных (далее — хранилище) — совокупность СУБД различных типов, в которых хранятся данные логических таблиц и материализованных представлений. Данные в хранилище хранятся в соответствии с физической схемой данных. Система предоставляет единый интерфейс взаимодействия с хранилищем в виде логической базы данных. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/data_storage/data_storage.html",
    "relUrl": "/overview/main_concepts/data_storage/data_storage.html"
  },"137": {
    "doc": "Дельта",
    "title": "Дельта",
    "content": "Дельта . Дельта — целостная совокупность изменений в логической базе данных. Дельта включает все операции записи, выполненные между открытием и закрытием этой дельты, и имеет порядковый номер, уникальный в рамках логической базы данных. Нумерация дельт начинается с 0. Дельты, упорядоченные в порядке возрастания их номеров, формируют историю состояний данных логической БД. На рисунке ниже показана последовательность операций записи, выполненных в дельтах 0 и 1. В дельте 0 выполнены операции записи с номерами 0-2, в дельте 1 — операции записи с номерами 3-4. Операции записи двух дельт . Дельту можно открыть, закрыть и отменить (откатить). Дельта, которая была открыта и еще не была закрыта, содержит горячие записи и называется открытой или горячей. Для каждой логической базы данных одновременно может быть открыто не более одной дельты. Дельта, которая была закрыта (зафиксирована), содержит актуальные и архивные записи и называется закрытой. На рисунке ниже показана последовательность дельт, где дельта с номером 3 является открытой, а все предыдущие — закрытыми. Открытая и закрытые дельты . Чтобы добавить или изменить данные логической БД, нужно открыть дельту, внести изменения в требуемые логические таблицы и затем зафиксировать изменения (закрыть дельту). Количество изменений в одной дельте не ограничено. Вносить изменения в таблицы можно с помощью загрузки, обновления данных или их сочетания. Пока дельта открыта, создание, удаление и изменение таблиц и представлений в логической БД недоступно. Дельта должна содержать непротиворечивые данные о состоянии объектов: каждая добавляемая запись таблицы должна иметь уникальный первичный ключ. Если в одной горячей дельте в таблицу добавляются разные записи с одинаковым первичным ключом, система не гарантирует сохранение определенной записи. Исключение — полные дубликаты записи, из которых система сохраняет только один экземпляр. Информацию о разных состояниях одного объекта необходимо разделять по разным дельтам, как показано в примере на рисунке ниже. В примере показано изменение данных магазина, сменившего адрес. Первоначальные данные добавлены в рамках дельты 0, а новые данные — в рамках дельты 1. Изменение данных магазина, сменившего адрес . Если нужно вернуть состояние данных, которое предшествовало изменениям открытой дельты, следует откатить дельту. Откатить можно только открытую дельту: после закрытия дельты возврат к предыдущему состоянию данных невозможен. Номер дельты можно указывать при запросе и выгрузке данных, чтобы определить момент или период, по состоянию на который запрашивается информация. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/delta/delta.html",
    "relUrl": "/overview/main_concepts/delta/delta.html"
  },"138": {
    "doc": "Окружение",
    "title": "Окружение",
    "content": "Окружение . Окружение — совокупность логических баз данных, доступных при работе с системой. Инсталляция системы работает с окружением, заданным в конфигурации системы. Допустимо создавать несколько окружений для одного набора кластеров СУБД и при необходимости перенастраивать инсталляцию системы на другое окружение. Попеременное использование независимых окружений может быть полезно, например, для разделения различных тестовых сред. На рисунке ниже показан пример инсталляции системы с тремя окружениями, где в настоящий момент внешняя информационная система работает с окружением test2. Инсталляция системы с тремя окружениями . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/environment/environment.html",
    "relUrl": "/overview/main_concepts/environment/environment.html"
  },"139": {
    "doc": "Внешняя таблица",
    "title": "Внешняя таблица",
    "content": "Внешняя таблица . Внешняя таблица задает набор параметров внешнего приемника данных (например, топика Kafka), используемого для параллельной загрузки или выгрузки данных. Набор включает следующие параметры: . | список передаваемых полей, | путь к внешнему приемнику данных, | формат обмена данными. | . Внешняя таблица представляет собой декларацию источника/приемника данных и формата загрузки/выгрузки данных и не хранит сами данные. Внешние таблицы разделяются по назначению: . | внешние таблицы загрузки используются для загрузки данных в систему, | внешние таблицы выгрузки используются для выгрузки данных из системы. | . Внешние таблицы можно создавать и удалять: . | создание внешней таблицы загрузки, | создание внешней таблицы выгрузки, | удаление внешней таблицы загрузки, | удаление внешней таблицы выгрузки. | . В зависимости от требований проекта созданная внешняя таблица может использоваться однократно или многократно. Следует учитывать, что потоки обмена данными с системой должны быть разделены по приемникам данных в следующих разрезах: . | по логическим таблицам, | по направлениям передачи данных (загрузка/выгрузка), | (опционально) на основе каких-либо дополнительных критериев (например, по целевым информационным системам). | . Например, если для логической таблицы нужно поддержать и загрузку, и выгрузку данных, следует создать хотя бы одну таблицу загрузки и хотя бы одну — выгрузки. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/external_table/external_table.html",
    "relUrl": "/overview/main_concepts/external_table/external_table.html"
  },"140": {
    "doc": "Логическая база данных",
    "title": "Логическая база данных",
    "content": "Логическая база данных . Логическая база данных (логическая БД) — совокупность логических сущностей (логических таблиц, логических представлений, материализованных представлений и внешних таблиц), сгруппированных по какому-либо принципу, например по направлению анализа. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/logical_db/logical_db.html",
    "relUrl": "/overview/main_concepts/logical_db/logical_db.html"
  },"141": {
    "doc": "Логическая схема данных",
    "title": "Логическая схема данных",
    "content": "Логическая схема данных . Логическая схема данных — внешнее представление структуры данных окружения, единое для всех поддерживаемых СУБД хранилища. Логическая схема данных представляет собой иерархию следующих объектов: . | логических баз данных, | логических таблиц, | логических представлений, | материализованных представлений, | внешних таблиц. | . Логическая схема данных хранится в сервисной базе данных системы. На рисунке ниже показана иерархия объектов логической схемы данных. Объекты логической схемы и их связи с объектами физической схемы . Внешняя информационная система (пользователь) отправляет системе запросы к данным, сформулированные в терминах логической схемы. Система разбирает полученные запросы, модифицирует (обогащает) их нужным образом и перенаправляет к физическим таблицам хранилища данных. В зависимости от момента времени, указанного в запросе, система обращается к горячим, актуальным или архивным данным. Такая модель взаимодействия позволяет работать с различными версиями данных, которые хранятся в различных СУБД хранилища, в едином формате. Связанные разделы: . | Управление схемой данных. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/logical_schema/logical_schema.html",
    "relUrl": "/overview/main_concepts/logical_schema/logical_schema.html"
  },"142": {
    "doc": "Логическая таблица",
    "title": "Логическая таблица",
    "content": "Логическая таблица . Логическая таблица — структурированная совокупность записей о состояниях объектов одного типа, например счетов или контрагентов. Логическая таблица не хранит сами данные, а предоставляет доступ к данным соответствующих физических таблиц хранилища. В отличие от реляционной таблицы, объекты которой обычно хранятся в актуальном (текущем) состоянии, логическая таблица предоставляет информацию обо всех исторических состояниях объектов: новых, актуальных и архивных. Например, данные одного клиента могут иметь нескольких версий в логической таблице clients: . | архивная запись с номером телефона +7(342)205-90-59 и адресом Пермь, | актуальная запись с номером телефона +7(495)777-77-77 и адресом Пермь (клиент сменил номер телефона), | горячая (новая) запись с номером телефона +7(495)777-77-77 и адресом Москва (клиент сменил адрес; запись загружена, но еще не зафиксирована). | . На рисунке ниже показана схема связей логической таблицы с ее физическими представлениями — физическими таблицами хранилища данных. Связи логической таблицы с физическими таблицами . Работа с логическими таблицами напоминает работу с реляционными таблицами. Логические таблицы можно создавать и удалять. Данные логической таблицы можно загружать, обновлять, запрашивать и выгружать. При необходимости можно получить информацию о запросе, с помощью которого была создана таблица (см. GET_ENTITY_DDL). При обращении к данным логической таблицы можно указать момент времени, по состоянию на который запрашиваются данные. Если момент времени не указан, система возвращает данные, актуальные на момент обработки запроса. Таким образом, можно получать данные из логической таблицы по состоянию на любой момент времени — независимо от того, являются они горячими (новыми), актуальными или архивными. При создании логической таблицы система автоматически создает и далее поддерживает набор физических таблиц для хранения данных. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/logical_table/logical_table.html",
    "relUrl": "/overview/main_concepts/logical_table/logical_table.html"
  },"143": {
    "doc": "Логическое представление",
    "title": "Логическое представление",
    "content": "Логическое представление . Логическое представление — сохраненный запрос к данным одной или нескольких логических таблиц, который имеет имя и может использоваться как источник данных в других запросах. Пример логического представления — список контрагентов, объединенный с их контактами и информацией о благонадежности. Работа с логическими представлениями напоминает работу с реляционными представлениями. Логические представления можно создавать, изменять и удалять. Данные логического представления можно запрашивать и выгружать. При необходимости можно получить информацию о запросе, с помощью которого было создано представление (см. GET_ENTITY_DDL). Логическое представление проецирует данные связанных логических таблиц и не отражается в хранилище. Загрузка и обновление данных недоступны для логических представлений. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/logical_view/logical_view.html",
    "relUrl": "/overview/main_concepts/logical_view/logical_view.html"
  },"144": {
    "doc": "Основные понятия",
    "title": "Основные понятия",
    "content": "Основные понятия . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/main_concepts.html",
    "relUrl": "/overview/main_concepts/main_concepts.html"
  },"145": {
    "doc": "Материализованное представление",
    "title": "Материализованное представление",
    "content": "Материализованное представление . Содержание раздела . | Синхронизация материализованных представлений . | Пример синхронизации материализованного представления | . | . Материализованное представление — структурированная совокупность записей, содержащих результаты запроса к данным одной или нескольких логических таблиц. Материализованное представление позволяет предварительно вычислить результат запроса и сохранить его для будущего использования. Материализованное представление строится на основе данных одной СУБД хранилища (далее — СУБД-источник), а его данные размещаются в других СУБД. Это позволяет создавать инсталляции, где одна СУБД служит полноценным хранилищем исходных данных, а остальные СУБД отвечают за быструю выдачу данных по запросам чтения. В текущей версии системы доступно создание материализованных представлений в ADQM и ADG на основе данных ADB. Материализованное представление помогает ускорить запросы к данным в следующих случаях: . | если представление содержит результаты сложного запроса, который на исходных данных выполняется дольше; | если запросы к представлению возвращают значительно меньше данных, чем запросы к исходным данным; | если запросы относятся к категории, которую СУБД хранилища, где размещены данные представления, выполняет более эффективно, чем СУБД-источник (например, ADG быстрее всех из поддерживаемых СУБД обрабатывает чтение по ключу). | . Материализованное представление дает доступ к актуальным и архивным данным. Чтение горячих данных из представления недоступно: это позволяет избежать чтения изменений, загруженных из СУБД-источника только частично. Данные материализованного представления хранятся аналогично данным логических таблиц — в физических таблицах хранилища, которые автоматически создаются при создании представления. Связи материализованного представления с физическими таблицами . Система поддерживает целостность данных материализованных представлений, периодически синхронизируя их с данными СУБД-источника (см. ниже). Синхронизация материализованного представления . Материализованные представления можно создавать и удалять. Из материализованного представления можно запрашивать и выгружать данные — так же, как из логических таблиц и логических представлений. Загрузка и обновление данных недоступны для материализованных представлений. При необходимости можно получить информацию о запросе, с помощью которого было создано представление (см. GET_ENTITY_DDL). При запросе или выгрузке данных из материализованного представления можно указать момент времени, по состоянию на который запрашиваются данные. Если момент времени не указан, система возвращает (выгружает) данные, актуальные на момент последней синхронизации представления, иначе — данные, актуальные на запрашиваемый момент времени. При запросе или выгрузке данных на указанный момент времени может оказаться, что материализованное представление отстало от СУБД-источника и не содержит запрошенные данные. В этом случае система перенаправляет запрос к исходным таблицам СУБД-источника (см. раздел Маршрутизация запросов к данным материализованных представлений). Перенаправленный запрос может выполняться дольше, однако это позволяет получить данные, полностью актуальные на указанный момент времени. Синхронизация материализованных представлений . Система периодически проверяет, нужно ли синхронизировать материализованные представления окружения с СУБД-источником. Периодичность проверки настраивается в конфигурации системы с помощью параметра MATERIALIZED_VIEWS_SYNC_PERIOD_MS; по умолчанию проверка запускается раз в 5 секунд. При необходимости синхронизацию материализованных представлений можно отключить, установив значение параметра MATERIALIZED_VIEWS_SYNC_PERIOD_MS равным 0. Проверка материализованных представлений запускается только по таймеру и не запускается по другим событиям, таким как создание материализованного представления или загрузка данных в СУБД-источник. При срабатывании таймера система проверяет, появились ли в СУБД-источнике дельты, закрытые после последней синхронизации и, если такие дельты появились, система синхронизирует материализованные представления с СУБД-источником. Количество одновременно синхронизируемых представлений задается в конфигурации системы с помощью параметра MATERIALIZED_VIEWS_CONCURRENT. По умолчанию одновременно синхронизируется максимум два представления, а остальные, если они есть, ожидают следующего цикла проверки. Данные представления синхронизируются отдельно по каждой закрытой дельте — с полным сохранением изменений, выполненных в этих дельтах. В каждой дельте для материализованного представления рассчитывается и сохраняется результат запроса, указанного при создании этого представления. Таким образом, материализованное представление имеет такой же уровень историчности данных, как и исходные логические таблицы, на которых построено представление. Если системе не удалось синхронизировать материализованное представление, она делает несколько повторных попыток. Максимальное количество попыток синхронизации представления задается в конфигурации системы (см. параметр MATERIALIZED_VIEWS_RETRY_COUNT), по умолчанию система делает до 10 попыток. Если количество попыток исчерпано, но материализованное представление так и не удалось синхронизировать, система прекращает попытки синхронизировать это представление (до перезапуска). После перезапуска системы счетчики попыток по всем представлениям обнуляются, и, если какие-либо представления остались несинхронизированными, система возобновляет попытки их синхронизировать. Статусы синхронизации материализованных представлений можно посмотреть с помощью запроса CHECK_MATERIALIZED_VIEW. Пример синхронизации материализованного представления . Рассмотрим пример со следующими условиями: . | логическая БД marketing содержит логическую таблицу marketing и материализованное представление sales_by_stores; | логическая БД содержит две дельты: . | дельта 0: в таблицу sales загружено две записи (с идентификаторами 100 и 101); | дельта 1: в таблицу sales загружено еще две записи (с идентификаторами 102 и 103); | . | материализованное представление sales_by_stores содержит результат агрегации и группировки данных таблицы sales и построено на основе следующего запроса: CREATE MATERIALIZED VIEW marketing.sales_by_stores ( store_id INT NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, PRIMARY KEY (store_id, product_code) ) DISTRIBUTED BY (store_id) DATASOURCE_TYPE (adg) AS SELECT store_id, product_code, SUM(product_units) FROM marketing.sales WHERE product_code &lt;&gt; 'ABC0001' GROUP BY store_id, product_code DATASOURCE_TYPE = 'adb' . | . На рисунках ниже показан порядок синхронизации материализованного представления sales_by_stores. В каждой дельте рассчитывается и сохраняется сумма по столбцу product_units таблицы sales с группировкой по столбцам store_id и product_code. При этом неважно, когда было создано материализованное представление: до дельты 0, после дельты 1 или в какой-то момент между этими дельтами. Состояние данных на момент дельты 0 . Состояние данных на момент дельты 1 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/materialized_view/materialized_view.html",
    "relUrl": "/overview/main_concepts/materialized_view/materialized_view.html"
  },"146": {
    "doc": "Физическая схема данных",
    "title": "Физическая схема данных",
    "content": "Физическая схема данных . Физическая схема данных — структура хранения данных логических сущностей в физических таблицах хранилища. Для каждой логической таблицы и каждого материализованного представления система автоматически создает и поддерживает набор связанных физических таблиц в некоторых или всех СУБД хранилища. Состав СУБД, в которых создаются физические таблицы и, соответственно, хранятся данные логических сущностей, можно регулировать с помощью ключевого слова DATASOURCE_TYPE в запросах на создание и удаление логических таблиц и материализованных представлений. Подробнее см. в разделах CREATE TABLE, DROP TABLE, CREATE MATERIALIZED VIEW и DROP MATERIALIZED VIEW. Состав и содержимое физических таблиц зависят от типа СУБД и описаны в таблице ниже. Например, в ADP все горячие записи хранятся в физической таблице с суффиксом _staging, а все актуальные и архивные записи — в таблице с суффиксом _actual. | Физическая таблица | ADB | ADG | ADQM | ADP | . | &lt;table&gt;_staging | +Горячие записи | +Горячие записи | − | +Горячие записи | . | tbl_buffer | − | − | +Идентификаторы горячих записей | − | . | &lt;table&gt;_actual | +Актуальные и архивные записи | +Актуальные записи | +Горячие, актуальные и архивные записи всех узлов кластера | +Актуальные и архивные записи | . | &lt;table&gt;_history | − | +Архивные записи | − | − | . | &lt;table&gt;_actual_shard | − | − | +Горячие, актуальные и архивные записи узла кластера | − | . | tbl_buffer_shard | − | − | +Идентификаторы горячих записей узла кластера | − | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/physical_schema/physical_schema.html",
    "relUrl": "/overview/main_concepts/physical_schema/physical_schema.html"
  },"147": {
    "doc": "Физическая таблица",
    "title": "Физическая таблица",
    "content": "Физическая таблица . Физическая таблица — таблица СУБД хранилища, в которой хранятся данные логической таблицы или материализованного представления. Запись физической таблицы содержит информацию об одном состоянии одного объекта в определенный период времени. Состояние может быть новым («горячим»), актуальным или архивным. Например, если клиент дважды сменил номер телефона, информация о клиенте в системе может быть представлена тремя записями: . | горячая запись с номером телефона number_3, | актуальная запись с номером телефона number_2, | архивная запись с номером телефона number_1. | . Подробнее о переходе данных из одного состояние в другое см. в разделе Версионирование данных. При создании логических таблиц и материализованных представлений система создает связанные физические таблицы. Физические таблицы автоматически удаляются, когда соответствующая логическая таблица или материализованное представление удаляется из последней СУБД хранилища, где размещались данные этой таблицы или представления. Состав и содержимое физических таблиц зависит от СУБД хранилища, в которых они располагаются. Подробнее о составе и содержимом физических таблиц см. в разделе Физическая схема данных. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/physical_table/physical_table.html",
    "relUrl": "/overview/main_concepts/physical_table/physical_table.html"
  },"148": {
    "doc": "Сервисная база данных",
    "title": "Сервисная база данных",
    "content": "Сервисная база данных . Сервисная база данных — сервис, используемый ядром системы для хранения метаданных, в частности логической схемы данных и информации о дельтах. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/service_db/service_db.html",
    "relUrl": "/overview/main_concepts/service_db/service_db.html"
  },"149": {
    "doc": "Операция записи",
    "title": "Операция записи",
    "content": "Операция записи . Операция записи — операция сохранения нового состояния объектов в логической таблице. Источником данных о состоянии объектов может быть внешний источник, сам запрос или СУБД хранилища. В дельте можно выполнить произвольное количество операций записи. Подробнее о способах добавления данных в систему см. в разделах Загрузка данных и Обновление данных. Каждая операция записи имеет порядковый номер, уникальный среди всех операций записи в логической базе данных. Нумерация начинается с 0. Номера операций записи используются в служебных целях: по ним система определяет период актуальности каждой из хранящихся записей. На рисунке ниже показан пример с двумя операциями записи в одной логической таблице stores. Для примера записи таблицы добавлены разными операциями. Операции записи в одной логической таблице . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/overview/main_concepts/write_operation/write_operation.html",
    "relUrl": "/overview/main_concepts/write_operation/write_operation.html"
  },"150": {
    "doc": "Формат выгрузки данных",
    "title": "Формат выгрузки данных",
    "content": "Формат выгрузки данных . Содержание раздела . | Структура сообщений | Формат данных | Примеры . | Пример выгружаемой схемы данных Avro | Пример выгружаемых записей Avro | . | . Структура сообщений . Данные выгружаются из системы в виде сообщений топиков Kafka. Каждое сообщение имеет структуру, показанную на рисунке ниже. Структура выгружаемых сообщений . Формат данных . Данные выгружаются из системы в следующем формате: . | Выгрузка данных выполняется в топик Kafka, указанный в настройках внешней таблицы выгрузки. | Каждое сообщение топика Kafka состоит из ключа и тела. | Тело сообщения представляет собой файл Avro (Object Container File), который состоит из заголовка и блоков данных. | Заголовок файла содержит схему данных Avro. | Схема данных тела сообщения содержит следующие элементы: имя, тип “record” и перечень полей. Для каждого поля указано имя, а также тип данных из числа перечисленных в разделе Выгружаемые типы данных (см. пример ниже). | Каждый блок данных содержит запись, представленную в бинарной кодировке. Запись соответствует схеме данных из заголовка файла Avro. | Каждая запись содержит перечень полей и их значений. Имена и порядок перечисления полей, а также типы данных их значений соответствуют схеме данных (см. пример ниже). | Состав и порядок полей совпадают в следующих объектах: . | во внешней таблице выгрузки, | в схеме данных тела сообщения, | в наборе выгружаемых записей. | . | . Типы данных Avro, доступные к выгрузке из системы, описаны в разделе Выгружаемые типы данных. Подробнее о формате Avro см. в официальной документации на сайте https://avro.apache.org. Примеры . Пример выгружаемой схемы данных Avro . Пример ниже содержит схему данных Avro, выгружаемую с данными о продажах из СУБД ADB. Для наглядности примера бинарные данные представлены в JSON-формате. { \"name\": \"row\", \"type\": \"record\", \"fields\": [ { \"name\": \"id\", \"type\": \"long\" }, { \"name\": \"transaction_date\", \"type\": \"long\" }, { \"name\": \"product_code\", \"type\": \"string\" }, { \"name\": \"product_units\", \"type\": \"long\" }, { \"name\": \"store_id\", \"type\": \"long\" }, { \"name\": \"description\", \"type\": \"string\" } ] } . Пример выгружаемых записей Avro . В примере ниже показан набор записей Avro о продажах, выгруженных из СУБД ADB и соответствующих схеме из предыдущего примера. Для наглядности примера бинарные данные представлены в JSON-формате. [ { \"id\": 1000111, \"transaction_date\": 1614269474000000, \"product_code\": \"ABC102101\", \"product_units\": 2, \"store_id\": 1000012345, \"description\": \"Покупка по акции 1+1\" }, { \"id\": 1000112, \"transaction_date\": 1614334214000000, \"product_code\": \"ABC102001\", \"product_units\": 1, \"store_id\": 1000000123, \"description\": \"Покупка без акций\" } ] . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/download_format/download_format.html",
    "relUrl": "/reference/download_format/download_format.html"
  },"151": {
    "doc": "Формат пути к внешнему приемнику данных",
    "title": "Формат пути к внешнему приемнику данных",
    "content": "Формат пути к внешнему приемнику данных . При создании внешних таблиц загрузки и выгрузки данных необходимо указать путь (URI-строку) к внешнему приемнику данных, из которого извлекаются или в который помещаются данные. Для обоих типов внешних таблиц используется одинаковый формат URI-строки. Доступны следующие способы указания пути к топику Kafka, расположенному на узлах кластера Zookeeper: . | полный путь к топику, | путь к топику с использованием переменной, определенной в конфигурации системы. | . Указание полного пути к топику . Чтобы указать полный путь к топику Kafka, задайте URI-строку в следующем формате: . kafka://zkhost_1:port_1,zkhost_2:port_2,zkhost_3:port_3/chroot/path/topic_name . Где: . | zkhost_N (обязательный) — имя хоста или IP-адрес хоста Zookeeper, к которому подключен брокер сообщений Kafka; | port_N (обязательный) — порт хоста Zookeeper, к которому подключен брокер сообщений Kafka. Должен соответствовать порту, заданному в конфигурации Zookeeper для подключения клиентов (по умолчанию — 2181); | chroot/path — путь chroot к метаданным кластера Kafka. Следует использовать при наличии нескольких узлов Kafka в одном кластере Zookeeper; | topic_name (обязательный) — имя топика Kafka. | . Примеры . Имена нескольких хостов с непустым путем chroot (chroot_kafka): . kafka://zk1:2181,zk2:2181,zk3:2181/chroot_kafka/sales . IP-адрес одного хоста: . kafka://192.168.60.97:2181/chroot_kafka/sales . Указание пути к топику с использованием переменной . Чтобы указать путь к топику Kafka с использованием переменной конфигурации, задайте URI-строку в следующем формате: . kafka://$kafka/topic_name . Пример . Пример пути к топику sales: . kafka://$kafka/sales . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/path_to_kafka_topic/path_to_kafka_topic.html",
    "relUrl": "/reference/path_to_kafka_topic/path_to_kafka_topic.html"
  },"152": {
    "doc": "Справочная информация",
    "title": "Справочная информация",
    "content": "Справочная информация . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/reference.html",
    "relUrl": "/reference/reference.html"
  },"153": {
    "doc": "ALLOW_CHANGES",
    "title": "ALLOW_CHANGES",
    "content": "ALLOW_CHANGES . Запрос позволяет снять запрет на изменение логических сущностей, установленный запросом DENY_CHANGES. При успешном выполнении запроса становится доступно создание, удаление и изменение сущностей логической базы данных: . | логических таблиц, | логических представлений, | материализованных представлений. | . Если при установке запрета был указан код, его необходимо ввести для снятия запрета. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . ALLOW_CHANGES([db_name, ['code']]) . Параметры: . | db_name — имя логической базы данных, для которой снимается запрет изменений. Опционально, если выбрана логическая БД, используемая по умолчанию; | code — код-пароль, заданный ранее в запросе DENY_CHANGES при установке запрета изменений. | . Ограничения . Выполнение запроса недоступно при наличии незавершенного запроса на создание, удаление или изменение таблицы или представления. Примеры . Снятие запрета без кода . Снятие запрета для указанной логической базы данных: . ALLOW_CHANGES(marketing) . Снятие запрета для логической БД, выбранной по умолчанию: . ALLOW_CHANGES() . На рисунке ниже показан пример ответа на запрос ALLOW_CHANGES в случае некорректного код-пароля. При установке запрета изменений был указан код my awesome code, который не был указан при снятии запрета. Ответ ALLOW_CHANGES в случае некорректного кода . Снятие запрета с кодом . Снятие запрета для указанной логической базы данных: . ALLOW_CHANGES(marketing, 'my awesome code') . Снятие запрета для логической базы данных, выбранной по умолчанию: . ALLOW_CHANGES('любой код') . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/ALLOW_CHANGES/ALLOW_CHANGES.html",
    "relUrl": "/reference/sql_plus_requests/ALLOW_CHANGES/ALLOW_CHANGES.html"
  },"154": {
    "doc": "BEGIN DELTA",
    "title": "BEGIN DELTA",
    "content": "BEGIN DELTA . Запрос позволяет открыть новую горячую дельту перед загрузкой или обновлением данных. Номер открываемой дельты может быть указан в запросе или установлен системой. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о номере открытой дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса открывается новая дельта. Дельта получает номер, указанный в запросе (если номер указан и корректен) или определенный системой (если номер не указан). Дельта всегда открывается с номером, следующим по порядку за номером последней закрытой дельты. После успешного выполнения запроса можно выполнять запросы на загрузку и обновление данных. Подробнее о порядке выполнения действий для загрузки данных см. в разделе Загрузка данных, для обновления данных — в разделе Обновление данных. Изменения данных открытой дельты можно отменить с помощью запроса ROLLBACK DELTA. Синтаксис . Открытие новой дельты: . BEGIN DELTA . Открытие новой дельты с указанным номером: . BEGIN DELTA SET delta_number . Параметры: . | delta_number — целочисленный номер открываемой дельты, равный номеру последней закрытой дельты + 1. Номер последней закрытой дельты можно узнать с помощью запроса GET_DELTA_OK. | . Ограничения . | Выполнение запроса невозможно при наличии незавершенного запроса на создание, удаление или изменение таблицы или представления. | Если в запросе указан номер открываемой дельты, он должен быть равен номеру последней закрытой дельты + 1. | . Пример . BEGIN DELTA SET 10 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/BEGIN_DELTA/BEGIN_DELTA.html",
    "relUrl": "/reference/sql_plus_requests/BEGIN_DELTA/BEGIN_DELTA.html"
  },"155": {
    "doc": "CHECK_DATA",
    "title": "CHECK_DATA",
    "content": "CHECK_DATA . Содержание раздела . | Синтаксис | Ограничения | Примеры . | Запрос без перечисления столбцов | Запрос с перечислением столбцов | Запрос с коэффициентом нормализации | . | Порядок проверки данных | Порядок расчета контрольной суммы . | Пример расчета контрольной суммы | . | . Запрос позволяет проверить идентичность данных логической таблицы во всех СУБД хранилища. Данные проверяются по дельтам в обратном порядке: с последней закрытой дельты до указанной в запросе (обе дельты включительно). При первом найденном расхождении система останавливает проверку и возвращает сообщение о расхождении в данных. Запрос не поддерживает проверку материализованных представлений. Идентичность данных представления можно проверить отдельно по каждой дельте запросом CHECK_SUM: если запрос вернул контрольную сумму, это означает, что в данных нет расхождений. Порядок проверки зависит от параметров запроса: . | если указаны столбцы к проверке, система сверяет контрольные суммы загруженных записей в каждой дельте; | иначе — система сверяет количество загруженных записей в каждой дельте. | . В проверке участвуют все СУБД хранилища, которые хранят данные логической таблицы, указанной в запросе. Если такая СУБД одна, проверка все равно проходит и считается успешной. Подробнее о порядке проверки см. в секции Порядок проверки данных, о расчете контрольной суммы — в секции Порядок расчета контрольной суммы. В ответе возвращается: . | объект ResultSet с результатом проверки при успешном выполнении запроса. Результат — это одна строка со списком проверенных дельт, где для каждой из дельт указано сообщение об успешной проверке или найденном расхождении; | исключение при неуспешном выполнении запроса. | . Значения типа FLOAT и DOUBLE могут приводить к расхождениям при проверке из-за разницы в точности типов. Чтобы избежать таких расхождений, используйте для всех значений с плавающей точкой тип DOUBLE (как более распространенный среди СУБД) или исключайте столбцы типа FLOAT и DOUBLE из запросов CHECK_DATA. Проверка может давать ложноположительный результат. Этому подвержены оба варианта проверок: со списком столбцов и без него. Чтобы снизить частоту ложных срабатываний, рекомендуется включать первичный ключ в список проверяемых столбцов. Синтаксис . CHECK_DATA([db_name.]table_name, delta_number[, normalization][, square-bracketed_column_list]) . Параметры: . | db_name (опциональный) — имя логической базы данных, которой принадлежит проверяемая логическая таблица. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя проверяемой логической таблицы; | delta_number — номер дельты, с которой начинается проверка. Должен быть меньше или равен номеру последней закрытой дельты. Номер последней закрытой дельты можно узнать с помощью запроса GET_DELTA_OK; | normalization (опциональный) — коэффициент, который повышает лимит на количество проверяемых записей в одной сущности, но снижает уникальность контрольных сумм. Может принимать любое целое значение, начиная с 1. Значение по умолчанию — 1. Если коэффициент не указан или равен 1, проверяемая сущность может содержать до 4'294'967'298 загруженных записей в дельте; при увеличении коэффициента лимит увеличивается пропорционально; | square_bracketed_column_list (опциональный) — список проверяемых столбцов таблицы. Элементы списка указываются в квадратных скобках через запятую, например [id, transaction_date]. Если столбцы указаны, система проверяет контрольную сумму записей, иначе — количество записей. | . Ограничения . | Существует вероятность совпадения контрольных сумм для разных наборов записей, поэтому возможен ложноположительный результат проверки. | Количество проверяемых записей в одной сущности ограничено и регулируется коэффициентом нормализации. Если количество загруженных записей какой-либо сущности в указанной дельте больше 4'294'967'298, нужно подобрать подходящее значение коэффициента нормализации. | . Примеры . Запрос без перечисления столбцов . Проверка целостности данных логической таблицы sales_july_2021 в диапазоне [дельта 0, последняя закрытая дельта]: . CHECK_DATA(marketing.sales_july_2021, 0) . На рисунке ниже показан пример ответа CHECK_DATA при успешной проверке логической таблицы sales_july_2021, данные которой размещены только в ADB. Ответ CHECK_DATA с проверкой только в ADB . Запрос с перечислением столбцов . Проверка целостности данных столбцов id, transaction_date и product_code таблицы sales: . CHECK_DATA(marketing.sales, 0, [id, transaction_date, product_code]) . На рисунке ниже показан пример ответа на запрос CHECK_DATA по столбцам таблицы при наличии расхождений: контрольная сумма нулевой дельты в ADB отличается от контрольной суммы в других СУБД. Ответ CHECK_DATA с расхождениями . Запрос с коэффициентом нормализации . Проверка целостности данных некоторых столбцов таблицы sales с коэффициентом нормализации 100: . CHECK_DATA(marketing.sales, 5, 100, [id, transaction_date, product_code]) . На рисунке ниже показан пример ответа на такой запрос. Запрос CHECK_DATA с коэффициентом нормализации . Порядок проверки данных . Идентичность данных проверяется в следующем порядке: . | В каждой из целевых СУБД: . | Выбираются проверяемые дельты: от указанной в запросе до последней закрытой (обе включительно). | По каждой дельте выбираются все записи, загруженные в логическую таблицу, которая указана в запросе. | По каждой дельте — в зависимости от наличия/отсутствия столбцов в запросе — рассчитывается контрольная сумма или количество загруженных записей. Порядок расчета контрольной суммы см. ниже. | . | Значения по каждой дельте сравниваются в целевых СУБД. | Если значение по одной из дельт отсутствует или не соответствует другим, для нее в ответе возвращается сообщение о расхождении в данных. Иначе по всем дельтам возвращаются сообщения об успешной проверке. | . Порядок расчета контрольной суммы . Контрольная сумма логической таблицы в дельте рассчитывается в следующем порядке: . | По каждой записи, загруженной в таблицу в этой дельте: . | Формируется текстовая строка: значения столбцов конвертируются в зависимости от типа данных (см. таблицу ниже) и записываются через точку с запятой. Значение NULL записывается как пустая строка. | Для полученной строки вычисляется MD5-хеш в виде байтовой последовательности в шестнадцатеричном формате. | Хеш интерпретируется как ASCII-строка в нижнем регистре. | Выбираются первые 4 символа строки, выстраиваются в порядке от младшего к старшему (little endian) и конвертируются в целое 32-битное число. | Полученное число делится на коэффициент нормализации, дробная часть результата отбрасывается — получается контрольная сумма записи. | . | Контрольные суммы всех записей в дельте суммируются — получается 64-битная контрольная сумма логической таблицы в дельте. | . В таблице ниже показано, как значения столбцов (column_value), указанных в запросе, конвертируются в зависимости от их типа данных. | Тип данных | Порядок конвертации | Пример | . | BOOLEAN | (column_value)::int | true -&gt; 1 | . | DATE | column_value - make_date(1970, 01, 01) | 2021-03-15 -&gt; 18701 | . | TIME | (extract(epoch from column_value)*1000000)::bigint | 13:01:44 -&gt; 46904000000 | . | TIMESTAMP | (extract(epoch from column_value)*1000000)::bigint | 2020-11-17 21:11:12 -&gt; 1605647472000000 | . | Другие типы данных | column_value | Иванов -&gt; Иванов | . Пример расчета контрольной суммы . Рассмотрим пример расчета контрольной суммы таблицы sales в дельте, в которой была загружена одна запись со следующими значениями: . | id = 10021, | transaction_date = 2020-11-17 21:11:12, | product_code = ABC1830. | . В качестве коэффициента нормализации возьмем число 10. Контрольная сумма таблицы рассчитывается так: . | Формируется строка для хеш-функции: 10021;1605647472000000;ABC1830. | Вычисляется MD5-хеш: bedbead6aea8ca373d8f0a15713639c1. | Выбираются первые 4 символа хеша: bedb. | Символы интерпретируются как ASCII-строка в нижнем регистре: 98 101 100 98. | Строка конвертируется в целое 32-битное число: 98*20 + 101*28 + 100*216 + 98*224 = 1650746722. | Полученное значение делится на коэффициент нормализации, остаток отбрасывается: 1650746722 : 10 = 165074672. | . Так как загруженная запись в дельте одна, контрольная сумма таблицы в этой дельте равна полученной контрольной сумме записи (165074672). ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CHECK_DATA/CHECK_DATA.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_DATA/CHECK_DATA.html"
  },"156": {
    "doc": "CHECK_DATABASE",
    "title": "CHECK_DATABASE",
    "content": "CHECK_DATABASE . Содержание раздела . | Синтаксис | Примеры | . Запрос позволяет проверить соответствие логических таблиц логической базы данных и их физических представлений — физических таблиц в хранилище данных. В проверке участвуют логические таблицы логической базы данных и все связанные с ними физические таблицы. Если СУБД хранилища не хранит данные логической таблицы, и, следовательно, не содержит связанные физические таблицы, она пропускается при проверке логической таблицы. Проверяется соответствие следующих элементов: . | имен столбцов, | типов данных столбцов, | первичного ключа. | . Имена проверяются для всех столбцов логических и физических таблиц, включая служебные столбцы, имеющиеся только у физических таблиц. Например, если служебный столбец sys_to удален из физической таблицы, в ответе вернется сообщение о расхождении. В ответе возвращается: . | объект ResultSet с одной записью, содержащей результаты проверки, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает сообщение об успешной проверке или найденных расхождениях, а также список проверенных СУБД хранилища. Примеры запросов и ответов см. в секции Примеры. Синтаксис . Проверка логической базы данных, выбранной по умолчанию: . CHECK_DATABASE() . Проверка указанной логической базы данных: . CHECK_DATABASE(db_name) . Параметры: . | db_name — имя логической базы данных, для таблиц которой выполняется проверка. | . Примеры . Проверка логической базы данных marketing: . CHECK_DATABASE(marketing) . На рисунках ниже показаны примеры ответов: на первом — ответ при отсутствии расхождений, на втором — при наличии расхождений. Расхождения вызваны тем, что таблица sales_logical создана только на логическом уровне. Ответ CHECK_DATABASE при успешной проверке . Ответ CHECK_DATABASE с расхождениями . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CHECK_DATABASE/CHECK_DATABASE.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_DATABASE/CHECK_DATABASE.html"
  },"157": {
    "doc": "CHECK_MATERIALIZED_VIEW",
    "title": "CHECK_MATERIALIZED_VIEW",
    "content": "CHECK_MATERIALIZED_VIEW . Запрос позволяет получить информацию по одному или всем материализованным представлениям логической базы данных. По каждому материализованному представлению доступна следующая информация: . | name — имя материализованного представления; | query — SELECT-запрос, который используется для синхронизации представления с источником; | source — СУБД хранилища, которая служит источником данных представления; | destination — список СУБД хранилища, в которых размещены данные представления. Возможные значения: adb, adqm; | last_sync_time — дата и время последней синхронизации представления с СУБД-источником; | last_sync_delta — номер последней дельты в представлении; | last_sync_error — ошибка последней синхронизации представления, если такая ошибка была; | is_sync_now — признак синхронизации представления в текущий момент. Возможные значения: флажок установлен, флажок снят; | retries_left — количество оставшихся попыток синхронизации представления. Когда значение опускается до 0, система перестает пытаться синхронизировать представление (до рестарта системы); | sync_period — периодичность синхронизации представления (в миллисекундах); | datamart_delta_ok — последняя закрытая дельта логической базы данных, в которой находится представление. | . Успешный ответ содержит объект ResultSet, где каждая строка соответствует одному материализованному представлению, неуспешный ответ содержит исключение. Подробнее о синхронизации представлений см. в разделе Синхронизация материализованных представлений. Синтаксис . CHECK_MATERIALIZED_VIEW([[db_name.]materialized_view_name]) . Параметры: . | db_name — имя логической базы данных, в которой находится материализованное представление. Параметр опционален, если выбрана логическая БД, используемая по умолчанию; | materialized_view_name — имя материализованного представления, по которому запрашивается информация. | . Примеры . Запрос информации по всем представлениям логической БД, выбранной по умолчанию . CHECK_MATERIALIZED_VIEW() . Запрос информации по одному представлению . Запрос в логической БД, выбранной по умолчанию: . CHECK_MATERIALIZED_VIEW(sales_and_stores) . Запрос в указанной логической БД: . CHECK_MATERIALIZED_VIEW(marketing.sales_and_stores) . На рисунках ниже показаны примеры ответов на запрос CHECK_MATERIALIZED_VIEW. На первом рисунке представление синхронизируется: в столбце is_sync_now стоит флажок, и столбец last_sync_delta пуст. На втором рисунке представление синхронизовано с источником: в столбце is_sync_now нет флажка, и значения в столбцах last_sync_delta и datamart_delta_ok совпадают. Пример ответа: представление еще синхронизируется с источником . Пример ответа: представление синхронизировано с источником . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CHECK_MATERIALIZED_VIEW/CHECK_MATERIALIZED_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_MATERIALIZED_VIEW/CHECK_MATERIALIZED_VIEW.html"
  },"158": {
    "doc": "CHECK_SUM",
    "title": "CHECK_SUM",
    "content": "CHECK_SUM . Содержание раздела . | Синтаксис | Ограничения | Примеры . | Запрос по отдельным столбцам логической таблицы | Запрос по всем столбцам логической таблицы | Запрос по всем столбцам материализованного представления | Запрос по логической базе данных | Запрос по логической базе данных с коэффициентом нормализации | . | Порядок расчета контрольных сумм . | Расчет контрольной суммы по логической таблице или материализованному представлению | Расчет контрольной суммы по логической базе данных | Пример расчета контрольной суммы по таблице | . | . Запрос позволяет рассчитать контрольную сумму изменений в указанной дельте. Под изменениями понимаются записи, загруженные и обновленные в дельте. Дельта может быть закрытой или открытой (горячей). Контрольную сумму можно рассчитать по следующим данным: . | отдельным столбцам логической таблицы или материализованного представления, | всем столбцам логической таблицы или материализованного представления, | всем логическим таблицам логической базы данных. | . Контрольная сумма рассчитывается по каждой СУБД хранилища, которая хранит данные проверяемой логической сущности. Порядок расчета описан ниже. При расчете контрольной суммы по отдельным столбцам рекомендуется добавлять первичный ключ в список столбцов. Это повысит уникальность контрольных сумм, рассчитываемых по разным данных. Чтобы рассчитать контрольную сумму по актуальным данным, а не изменениям данных, используйте запрос CHECK_SUM_SNAPSHOT. В ответе возвращается: . | объект ResultSet с контрольной суммой при успешном выполнении запроса и отсутствии расхождений между СУБД хранилища; | исключение при наличии расхождений или неуспешном выполнении запроса. | . Если контрольные суммы различаются между СУБД хранилища, система возвращает исключение Consistency breach detected for &lt;entity_name&gt;. Исключение содержит список контрольных сумм по всем проверенным СУБД. При расчете контрольной суммы по логической базе данных система возвращает исключение по первому найденному расхождению и не проверяет следующие сущности. Значения типа FLOAT и DOUBLE могут иметь разные контрольные суммы из-за разницы в точности типов. Чтобы избежать расхождения в контрольных суммах, используйте для всех значений с плавающей точкой тип DOUBLE (как более распространенный среди СУБД) или исключайте столбцы типа FLOAT и DOUBLE из запросов CHECK_SUM_SNAPSHOT. Синтаксис . CHECK_SUM(delta_num[, normalization][, [db_name.]entity_name[, square-bracketed_column_list]]) . Параметры: . | delta_num — номер дельты, по которой рассчитывается контрольная сумма изменений; | normalization (опциональный) — коэффициент, который повышает лимит на количество проверяемых записей в одной сущности, но снижает уникальность контрольных сумм. Может принимать любое целое значение, начиная с 1. Значение по умолчанию — 1. Если коэффициент не указан или равен 1, проверяемая сущность может содержать до 4'294'967'298 загруженных записей в дельте; при увеличении коэффициента лимит увеличивается пропорционально; | db_name (опциональный) — имя логической базы данных, которой принадлежит проверяемая сущность. Опционально, если выбрана логическая БД, используемая по умолчанию; | entity_name (опциональный) — имя логической таблицы или материализованного представления, по которому рассчитывается контрольная сумма; | square-bracketed_column_list (опциональный) — список имен столбцов, по которым рассчитывается контрольная сумма. Элементы списка перечисляются в квадратных скобках через запятую. Если столбцы не указаны, система рассчитывает контрольную сумму по всем столбцам таблицы или представления. | . Ограничения . | Контрольная сумма логической базы данных рассчитывается только по данным логических таблиц и не учитывает данные материализованных представлений. | Существует вероятность совпадения контрольных сумм для разных наборов данных. | Количество проверяемых записей в одной сущности ограничено и регулируется коэффициентом нормализации. Если количество загруженных записей какой-либо сущности в указанной дельте больше 4'294'967'298, нужно подобрать подходящее значение коэффициента нормализации. | . Примеры . Запрос по отдельным столбцам логической таблицы . Расчет контрольной суммы по трем столбцам таблицы sales в седьмой дельте: . CHECK_SUM(7, marketing.sales, [id, transaction_date, product_code]) . На рисунках ниже показаны примеры ответов на запрос CHECK_SUM с перечислением столбцов: на первом — ответ при отсутствии расхождений в данных между СУБД хранилища, на втором — ответ при наличии расхождений. Ответ CHECK_SUM по отдельным столбцам таблицы при отсутствии расхождений . Ответ CHECK_SUM при наличии расхождений . Запрос по всем столбцам логической таблицы . Расчет контрольной суммы по всей таблице sales в седьмой дельте: . CHECK_SUM(7, marketing.sales) . На рисунке ниже показан пример ответа на запрос CHECK_SUM по логической таблице. Ответ CHECK_SUM по логической таблице . Запрос по всем столбцам материализованного представления . Расчет контрольной суммы по всему материализованному представлению sales_by_stores в десятой дельте: . CHECK_SUM(10, marketing.sales_by_stores) . Запрос по логической базе данных . Расчет контрольной суммы по всем таблицам логической базы данных marketing в седьмой дельте: . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- расчет контрольной суммы логической БД CHECK_SUM(7); . На рисунке ниже показан пример ответа на запрос CHECK_SUM по логической базе данных. Ответ CHECK_SUM по логической базе данных . Запрос по логической базе данных с коэффициентом нормализации . Расчет контрольной суммы по всем таблицам логической базы данных marketing с коэффициентом нормализации, равным 100: . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- расчет контрольной суммы логической БД с указанным коэффициентом нормализации CHECK_SUM(7, 100); . На рисунке ниже показан пример ответа на такой запрос. Запрос CHECK_SUM с коэффициентом нормализации . Порядок расчета контрольных сумм . Расчет контрольной суммы по логической таблице или материализованному представлению . Контрольная сумма логической таблицы или материализованного представления рассчитывается, как описано в разделе CHECK_DATA. Расчет контрольной суммы по логической базе данных . Контрольная сумма логической базы данных рассчитывается так: . | По каждой логической таблице логической базы данных рассчитывается контрольная сумма, как описано в разделе CHECK_DATA. | Контрольные суммы всех логических таблиц суммируются — получается 64-битная контрольная сумма логической базы данных. | . Пример расчета контрольной суммы по таблице . Рассмотрим пример расчета контрольной суммы по таблице sales в дельте, в которой загружено две записи. Для простоты возьмем уже рассчитанные контрольные суммы записей: 165074672 (см. пример расчета в разделе CHECK_DATA) и 87891666. Контрольная сумма таблицы равна 165074672 + 87891666 = 252966338. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CHECK_SUM/CHECK_SUM.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_SUM/CHECK_SUM.html"
  },"159": {
    "doc": "CHECK_SUM_SNAPSHOT",
    "title": "CHECK_SUM_SNAPSHOT",
    "content": "CHECK_SUM_SNAPSHOT . Содержание раздела . | Синтаксис | Ограничения | Примеры . | Запрос по отдельным столбцам логической таблицы | Запрос по всем столбцам логической таблицы | Запрос по всем столбцам материализованного представления | Запрос по логической базе данных | Запрос по логической базе данных с коэффициентом нормализации | . | Порядок расчета контрольных сумм . | Расчет контрольной суммы по логической таблице или материализованному представлению | Расчет контрольной суммы по логической базе данных | . | . Запрос позволяет рассчитать контрольную сумму актуальных данных на момент закрытия указанной дельты. Запрос поддерживается для ADB, ADQM и ADP. Контрольную сумму можно рассчитать по следующим данным: . | отдельным столбцам логической таблицы или материализованного представления, | всем столбцам логической таблицы или материализованного представления, | всем логическим таблицам логической базы данных. | . Контрольная сумма рассчитывается по каждой СУБД хранилища, которая хранит данные проверяемой логической сущности. Порядок расчета описан ниже. При расчете контрольной суммы по отдельным столбцам рекомендуется добавлять первичный ключ в список столбцов. Это повысит уникальность контрольных сумм, рассчитываемых по разным данных. Чтобы рассчитать контрольную сумму по изменениям данных, а не актуальным данным, используйте запрос CHECK_SUM. В ответе возвращается: . | объект ResultSet с контрольной суммой при успешном выполнении запроса и отсутствии расхождений между СУБД хранилища; | исключение при наличии расхождений или неуспешном выполнении запроса. | . Если контрольные суммы различаются между СУБД хранилища, система возвращает исключение Consistency breach detected for &lt;entity_name&gt;. Исключение содержит список контрольных сумм по всем проверенным СУБД. При расчете контрольной суммы по логической базе данных система возвращает исключение по первому найденному расхождению и не проверяет следующие сущности. Значения типа FLOAT и DOUBLE могут иметь разные контрольные суммы из-за разницы в точности типов. Чтобы избежать расхождения в контрольных суммах, используйте для всех значений с плавающей точкой тип DOUBLE (как более распространенный среди СУБД) или исключайте столбцы типа FLOAT и DOUBLE из запросов CHECK_SUM_SNAPSHOT. Синтаксис . CHECK_SUM_SNAPSHOT(delta_num[, normalization][, [db_name.]entity_name[, square-bracketed_column_list]]) . Параметры: . | delta_num — номер дельты, на момент закрытия которой рассчитывается контрольная сумма актуальных данных; | normalization (опциональный) — коэффициент, который повышает лимит на количество проверяемых записей в одной сущности, но снижает уникальность контрольных сумм. Может принимать любое целое значение, начиная с 1. Значение по умолчанию — 1. Если коэффициент не указан или равен 1, проверяемая сущность может содержать до 4'294'967'298 актуальных записей в дельте; при увеличении коэффициента лимит увеличивается пропорционально; | db_name (опциональный) — имя логической базы данных, которой принадлежит проверяемая сущность. Опционально, если выбрана логическая БД, используемая по умолчанию; | entity_name (опциональный) — имя логической таблицы или материализованного представления, по которому рассчитывается контрольная сумма; | square-bracketed_column_list (опциональный) — список имен столбцов, по которым рассчитывается контрольная сумма. Элементы списка перечисляются в квадратных скобках через запятую. Если столбцы не указаны, система рассчитывает контрольную сумму по всем столбцам таблицы или представления. | . Ограничения . | Контрольная сумма логической базы данных рассчитывается только по данным логических таблиц и не учитывает данные материализованных представлений. | Существует вероятность совпадения контрольных сумм для разных наборов данных. | Количество проверяемых записей в одной сущности ограничено и регулируется коэффициентом нормализации. Если количество актуальных записей какой-либо сущности в указанной дельте больше 4'294'967'298, нужно подобрать подходящее значение коэффициента нормализации. | . Примеры . Запрос по отдельным столбцам логической таблицы . Расчет контрольной суммы по трем столбцам таблицы basic_stores_table в седьмой дельте: . CHECK_SUM_SNAPSHOT(7,marketing.basic_stores_table,[id, category, region]) . На рисунке ниже показан пример ответа на запрос CHECK_SUM_SNAPSHOT с перечислением столбцов таблицы. Ответ CHECK_SUM_SNAPSHOT по отдельным столбцам таблицы . Запрос по всем столбцам логической таблицы . Расчет контрольной суммы по всей таблице basic_stores_table в седьмой дельте: . CHECK_SUM_SNAPSHOT(7,marketing.basic_stores_table) . На рисунке ниже показан пример ответа на запрос CHECK_SUM_SNAPSHOT по логической таблице при наличии расхождений. Ответ CHECK_SUM_SNAPSHOT по логической таблице при наличии расхождений . Запрос по всем столбцам материализованного представления . Расчет контрольной суммы по всему материализованному представлению sales_by_stores в седьмой дельте: . CHECK_SUM_SNAPSHOT(7,marketing.sales_by_stores) . Запрос по логической базе данных . Расчет контрольной суммы по всем таблицам логической базы данных marketing_new в нулевой дельте: . -- выбор логической базы данных marketing_new в качестве базы данных по умолчанию USE marketing_new; -- расчет контрольной суммы логической БД CHECK_SUM_SNAPSHOT(0); . На рисунке ниже показан пример ответа на запрос CHECK_SUM_SNAPSHOT по логической базе данных. Ответ CHECK_SUM_SNAPSHOT по логической базе данных . Запрос по логической базе данных с коэффициентом нормализации . Расчет контрольной суммы по всем таблицам логической базы данных marketing_new с коэффициентом нормализации, равным 100: . -- выбор логической базы данных marketing_new в качестве базы данных по умолчанию USE marketing_new; -- расчет контрольной суммы логической БД с указанным коэффициентом нормализации CHECK_SUM_SNAPSHOT(7, 100); . На рисунке ниже показан пример ответа на такой запрос. Запрос CHECK_SUM_SNAPSHOT с коэффициентом нормализации . Порядок расчета контрольных сумм . Расчет контрольной суммы по логической таблице или материализованному представлению . Контрольная сумма логической таблицы или материализованного представления рассчитывается, как описано в разделе CHECK_DATA, с тем отличием, что контрольные суммы в шаге 1 рассчитываются не по записям, загруженным в дельте, а записям, актуальным на момент закрытия дельты. Расчет контрольной суммы по логической базе данных . Контрольная сумма логической базы данных рассчитывается так: . | По каждой логической таблице логической базы данных рассчитывается контрольная сумма (см. выше). | Контрольные суммы всех логических таблиц суммируются — получается 64-битная контрольная сумма логической базы данных. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CHECK_SUM_SNAPSHOT/CHECK_SUM_SNAPSHOT.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_SUM_SNAPSHOT/CHECK_SUM_SNAPSHOT.html"
  },"160": {
    "doc": "CHECK_TABLE",
    "title": "CHECK_TABLE",
    "content": "CHECK_TABLE . Содержание раздела . | Синтаксис | Примеры . | Ответ при успешной проверке | Ответ при наличии расхождений | . | . Запрос позволяет проверить соответствие логической таблицы и ее физических представлений — физических таблиц в хранилище данных. В проверке участвуют указанная логическая таблица и все связанные с ней физические таблицы. Если СУБД хранилища не хранит данные логической таблицы, и, следовательно, не содержит связанные физические таблицы, она пропускается при проверке. Проверяется соответствие следующих элементов: . | имен столбцов, | типов данных столбцов, | первичного ключа. | . Имена проверяются для всех столбцов логической и физических таблиц, включая служебные столбцы, имеющиеся только у физических таблиц. Например, если служебный столбец sys_to удален из физической таблицы, в ответе вернется сообщение о расхождении. В ответе возвращается: . | объект ResultSet с одной записью, содержащей результаты проверки, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает сообщение об успешной проверке или найденных расхождениях, а также список проверенных СУБД хранилища. Примеры запросов и ответов см. в секции Примеры. Синтаксис . CHECK_TABLE([db_name.]table_name) . Параметры: . | db_name — имя логической базы данных, которой принадлежит проверяемая логическая таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя проверяемой логической таблицы. | . Примеры . Проверка логической таблицы sales: . CHECK_TABLE(marketing.sales) . Ответ при успешной проверке . На рисунках ниже показаны примеры ответов в случае успешной проверки: на первом рисунке — по таблице, данные которой размещены во всех СУБД хранилища, на втором — по таблице, данные которой размещены только в ADB. Ответ CHECK_TABLE при успешной проверке . Ответ CHECK_TABLE с проверкой только в ADB . Ответ при наличии расхождений . На рисунке ниже показан пример ответа при наличии расхождений, которые вызваны тем, что в физической таблице ADB отсутствует столбец description. Ответ CHECK_TABLE с найденными расхождениями . На рисунке ниже показан пример ответа при наличии расхождений, которые вызваны тем, что логическая таблица была создана только на логическом уровне. Подробнее о создании и пересоздании логической таблицы на логическом уровне см. в разделе CREATE TABLE. Ответ CHECK_TABLE с найденными расхождениями . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CHECK_TABLE/CHECK_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_TABLE/CHECK_TABLE.html"
  },"161": {
    "doc": "CHECK_VERSIONS",
    "title": "CHECK_VERSIONS",
    "content": "CHECK_VERSIONS . Запрос позволяет получить информацию о версиях следующих программных компонентов: . | компонентов системы, | компонентов, с которыми работает система. | . В ответе возвращается: . | объект ResultSet с записями, содержащими информацию об именах и версиях компонентах, при успешном выполнении запроса (см. рисунок ниже); | исключение при неуспешном выполнении запроса. | . Ответ CHECK_VERSIONS . Синтаксис . CHECK_VERSIONS() . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CHECK_VERSIONS/CHECK_VERSIONS.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_VERSIONS/CHECK_VERSIONS.html"
  },"162": {
    "doc": "COMMIT DELTA",
    "title": "COMMIT DELTA",
    "content": "COMMIT DELTA . Запрос позволяет закрыть открытую (горячую) дельту. Дата и время закрытия дельты могут быть указаны в запросе или установлены системой. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дате и времени закрытия дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса горячие записи дельты становятся актуальными, а зафиксированные ранее записи, которые больше не являются актуальными, — архивными. Дельта закрывается и становится недоступна для загрузки и обновления данных. Подробнее о версионировании записей см. в разделе Версионирование данных. В качестве даты и времени закрытия дельты устанавливаются дата и время, указанные в запросе (если они указаны и корректны) или определенные системой (если дата и время не указаны). Если операция обновления данных зависла, дельту невозможно закрыть или откатить. В этом случае нужно повторить запрос, запустивший проблемную операцию. Действие перезапустит обработку операции, и после ее завершения можно будет закрыть или откатить дельту. После закрытия горячей дельты становятся доступны действия по созданию, удалению и изменению таблиц и представлений. Синтаксис . Закрытие открытой дельты: . COMMIT DELTA . Закрытие открытой дельты с указанными датой и временем закрытия: . COMMIT DELTA SET date_time_expression . Параметры: . | date_time_expression — метка даты и времени вида 'YYYY-MM-DD hh:mm:ss'. Возможные форматы см. в разделе Форматы даты и времени. | . Ограничения . Если в запросе указаны дата и время закрытия дельты, они должны быть больше, чем дата и время последней закрытой дельты. Дату и время последней закрытой дельты можно узнать, выполнив запрос GET_DELTA_OK. Пример . COMMIT DELTA SET '2021-03-21 09:29:54' . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/COMMIT_DELTA/COMMIT_DELTA.html",
    "relUrl": "/reference/sql_plus_requests/COMMIT_DELTA/COMMIT_DELTA.html"
  },"163": {
    "doc": "CONFIG_SHOW",
    "title": "CONFIG_SHOW",
    "content": "CONFIG_SHOW . Запрос позволяет получить информацию об одном или всех параметрах конфигурации системы. По каждому параметру доступна следующая информация: . | полный путь до параметра в дереве конфигурации; | значение параметра; | имя переменной окружения, с помощью которой можно переопределить значение параметра. | . В ответе возвращается: . | объект ResultSet, где каждая строка содержит информацию об одном параметре, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . Запрос информации об одном параметре конфигурации: . CONFIG_SHOW('parameter_name') . Запрос информации обо всех параметров конфигурации: . CONFIG_SHOW() . Параметры: . | parameter_name — полный путь до параметра конфигурации или имя соответствующей переменной окружения. Путь включает имена всех параметров, в которые вложен нужный параметр; имена перечисляются через двоеточие. | . Примеры . Запрос информации о параметре с указанием полного пути . Запрос информации по параметру connection-string с указанием полного пути до этого параметра в конфигурации: . CONFIG_SHOW('core:kafka:cluster:zookeeper:connection-string') . На рисунке ниже показан пример ответа на запрос по одному параметру. Ответ по одному параметру конфигурации . Запрос информации о параметре с указанием переменной окружения . Запрос информации по параметру connection-string с указанием переменной окружения, соответствующей этому параметру: . CONFIG_SHOW('ZOOKEEPER_KAFKA_ADDRESS') . Запрос информации обо всех параметрах конфигурации . Запрос информации обо всех параметрах конфигурации окружения: . CONFIG_SHOW() . На рисунке ниже показан фрагмент ответа на запрос по всем параметрам. Фрагмент ответа по всем параметрам конфигурации . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CONFIG_SHOW/CONFIG_SHOW.html",
    "relUrl": "/reference/sql_plus_requests/CONFIG_SHOW/CONFIG_SHOW.html"
  },"164": {
    "doc": "CONFIG_STORAGE_ADD",
    "title": "CONFIG_STORAGE_ADD",
    "content": "CONFIG_STORAGE_ADD . Запрос позволяет подключить к системе источник данных — СУБД указанного типа. После успешного выполнения запроса можно создавать логические таблицы с размещением данных в этой СУБД и загружать данные в нее. Перед выполнением запроса необходимо добавить параметры СУБД в конфигурацию системы. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса все логические базы данных окружения активируются для указанной СУБД хранилища. При этом копирование логических таблиц и их данных из других СУБД хранилища не происходит и не может быть выполнено средствами системы. Синтаксис . CONFIG_STORAGE_ADD('datasource_alias') . Параметры: . | datasource_alias — псевдоним СУБД хранилища. Возможные значения: adb, adqm, adg, adp. | . Пример . Подключение ADB к хранилищу: . CONFIG_STORAGE_ADD('adb') . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CONFIG_STORAGE_ADD/CONFIG_STORAGE_ADD.html",
    "relUrl": "/reference/sql_plus_requests/CONFIG_STORAGE_ADD/CONFIG_STORAGE_ADD.html"
  },"165": {
    "doc": "CREATE DATABASE",
    "title": "CREATE DATABASE",
    "content": "CREATE DATABASE . Запрос позволяет создать логическую базу данных в текущем окружении. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Перед работой с логической базой данных выберите ее в качестве используемой по умолчанию — это позволит обращаться к логическим сущностям без имени логической БД. Синтаксис . Создание логической БД: . CREATE DATABASE db_name . Создание логической БД только на логическом уровне: . CREATE DATABASE db_name LOGICAL_ONLY . Параметры: . | db_name — имя создаваемой логической базы данных. Может содержать латинские буквы, цифры и символы подчеркивания (“_”). | . Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет создать логическую базу данных только на логическом уровне (в логической схеме данных), без пересоздания связанной физической базы данных в хранилище данных. Если ключевое слово не указано, создается как логическая, так и связанная с ней физическая база данных. Ограничения . | Имя логической базы данных должно начинаться с латинской буквы, после первого символа могут следовать латинские буквы, цифры и символы подчеркивания в любом порядке. | Логическая БД не может иметь имя INFORMATION_SCHEMA, а также имена, перечисленные в разделе Зарезервированные слова. | . Примеры . Создание логической БД . CREATE DATABASE marketing . Создание логической БД только на логическом уровне . CREATE DATABASE marketing1 LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_DATABASE/CREATE_DATABASE.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_DATABASE/CREATE_DATABASE.html"
  },"166": {
    "doc": "CREATE DOWNLOAD EXTERNAL TABLE",
    "title": "CREATE DOWNLOAD EXTERNAL TABLE",
    "content": "CREATE DOWNLOAD EXTERNAL TABLE . Содержание раздела . | Синтаксис | Ограничения | Пример | . Запрос позволяет создать внешнюю таблицу выгрузки в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . После успешного выполнения запроса можно выполнять запросы INSERT INTO download_external_table на выгрузку данных. Подробнее о порядке выполнения действий для выгрузки данных см. в разделе Выгрузка данных. Изменение внешней таблицы недоступно. Для замены внешней таблицы необходимо удалить ее и создать новую. Синтаксис . CREATE DOWNLOAD EXTERNAL TABLE [db_name.]ext_table_name( column_name_1 datatype_1, column_name_2 datatype_2, column_name_3 datatype_3 ) LOCATION receiver_URI FORMAT 'AVRO' [CHUNK_SIZE records_per_message] . Параметры: . | db_name — имя логической базы данных, в которой создается внешняя таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя создаваемой внешней таблицы выгрузки. Для удобства различения таблиц выгрузки и таблиц загрузки рекомендуется задавать имя таблицы, указывающее на ее тип, например sales_ext_download; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | receiver_URI — путь к топику Kafka (см. Формат пути к внешнему приемнику данных); | records_per_message — максимальное количество записей, выгружаемых из хранилища в одном сообщении топика Каfka. | . Ограничения . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Имена таблицы и ее столбцов должны начинаться с латинской буквы, после первого символа могут следовать латинские буквы, цифры и символы подчеркивания в любом порядке. | Таблица и ее столбцы не могут иметь имена, перечисленные в разделе Зарезервированные слова. | . Пример . CREATE DOWNLOAD EXTERNAL TABLE marketing.sales_ext_download ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_DOWNLOAD_EXTERNAL_TABLE/CREATE_DOWNLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_DOWNLOAD_EXTERNAL_TABLE/CREATE_DOWNLOAD_EXTERNAL_TABLE.html"
  },"167": {
    "doc": "CREATE TABLE",
    "title": "CREATE TABLE",
    "content": "CREATE TABLE . Содержание раздела . | Синтаксис . | Ключевое слово DATASOURCE_TYPE | Ключевое слово LOGICAL_ONLY | . | Ограничения | Примеры . | Создание таблицы с размещением данных во всех СУБД хранилища | Создание таблицы с составным первичным ключом | Создание таблицы с размещением данных в ADQM и ADG | Создание таблицы только на логическом уровне | . | . Запрос позволяет создать логическую таблицу в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса система создает логическую таблицу, а также подготавливает хранилище к размещению данных таблицы — создает физические таблицы, связанные с логической таблицей и предназначенные для хранения ее данных. По умолчанию система создает физические таблицы во всех СУБД хранилища инсталляции. Это означает, что при добавлении данных в логическую таблицу система добавляет их во все СУБД. Чтобы настроить размещения данных логической таблицы только в некоторых СУБД хранилища, следует указать в запросе CREATE TABLE ключевое слово DATASOURCE_TYPE со списком нужных СУБД. Изменение логической таблицы недоступно. Для замены таблицы необходимо удалить ее и создать новую. Если при обработке запроса происходит ошибка, последующее изменение сущностей логической базы данных невозможно. В этом случае нужно повторить запрос. Действие перезапустит обработку запроса, и после ее завершения можно будет продолжить работу с логической БД. Каждое создание таблицы записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Синтаксис . CREATE TABLE [db_name.]table_name ( column_name_1 datatype_1 [ NULL | NOT NULL ], column_name_2 datatype_2 [ NULL | NOT NULL ], column_name_3 datatype_3 [ NULL | NOT NULL ], PRIMARY KEY (column_list_1) ) DISTRIBUTED BY (column_list_2) [DATASOURCE_TYPE (datasource_aliases)] [LOGICAL_ONLY] . Параметры: . | db_name — имя логической базы данных, в которой создается логическая таблица. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя создаваемой логической таблицы, уникальное среди логических сущностей логической БД; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | column_list_1 — список столбцов, входящих в первичный ключ таблицы; | column_list_2 — список столбцов, входящих в ключ шардирования таблицы. Столбцы должны быть из числа столбцов column_list_1; | datasource_aliases — список псевдонимов СУБД хранилища, в которых нужно разместить данные таблицы. Элементы списка перечисляются через запятую. Возможные значения: adb, adqm, adg, adp. Значения можно указывать без кавычек (например, adb) или двойных кавычках (например, \"adb\"). | . Ключевое слово DATASOURCE_TYPE . Ключевое слово DATASOURCE_TYPE позволяет указать СУБД хранилища, в которых необходимо размещать данные логической таблицы. Если ключевое слово не указано, данные таблицы размещаются во всех доступных СУБД хранилища. Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет создать логическую таблицу только на логическом уровне (в логической схеме данных), без пересоздания связанных физических таблиц в хранилище данных. Если ключевое слово не указано, создается как логическая, так и связанные с ней физические таблицы. Ограничения . | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Имена таблицы и ее столбцов должны начинаться с латинской буквы, после первого символа могут следовать латинские буквы, цифры и символы подчеркивания в любом порядке. | Таблица и ее столбцы не могут иметь имена, перечисленные в разделе Зарезервированные слова. Столбцы также не могут иметь имена, зарезервированные системой для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Имена столбцов должны быть уникальны в рамках логической таблицы. | Первичный ключ должен включать все столбцы ключа шардирования. | . Примеры . Создание таблицы с размещением данных во всех СУБД хранилища . CREATE TABLE marketing.sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) . Создание таблицы с составным первичным ключом . CREATE TABLE marketing.stores ( id INT NOT NULL, category VARCHAR(256) NOT NULL, region VARCHAR(256) NOT NULL, address VARCHAR(256) NOT NULL, description VARCHAR(256), PRIMARY KEY (id, region) ) DISTRIBUTED BY (id) . Создание таблицы с размещением данных в ADQM и ADG . CREATE TABLE marketing.clients ( id INT NOT NULL, first_name VARCHAR(256) NOT NULL, last_name VARCHAR(256) NOT NULL, patronymic_name VARCHAR(256), birth_date DATE, PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adqm,adg) . Создание таблицы только на логическом уровне . CREATE TABLE marketing.sales1 ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_TABLE/CREATE_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_TABLE/CREATE_TABLE.html"
  },"168": {
    "doc": "CREATE UPLOAD EXTERNAL TABLE",
    "title": "CREATE UPLOAD EXTERNAL TABLE",
    "content": "CREATE UPLOAD EXTERNAL TABLE . Содержание раздела . | Синтаксис | Ограничения | Пример | . Запрос позволяет создать внешнюю таблицу загрузки в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . После успешного выполнения запроса можно выполнять запросы INSERT INTO logical_table на загрузку данных. Подробнее о порядке выполнения действий для загрузки данных см. в разделе Загрузка данных. Изменение внешней таблицы недоступно. Для замены внешней таблицы необходимо удалить ее и создать новую. Синтаксис . CREATE UPLOAD EXTERNAL TABLE [db_name.]ext_table_name ( column_name_1 datatype_1, column_name_2 datatype_2, column_name_3 datatype_3 ) LOCATION source_URI FORMAT 'AVRO' [MESSAGE_LIMIT messages_per_segment] . Параметры: . | db_name — имя логической базы данных, в которой создается внешняя таблица. Указание опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя создаваемой внешней таблицы загрузки. Для удобства различения таблиц выгрузки и таблиц загрузки рекомендуется задавать имя таблицы, указывающее на ее тип, например sales_ext_upload; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | source_URI — путь к топику Kafka (см. Формат пути к внешнему приемнику данных); | messages_per_segment — максимальное количество сообщений, загружаемых в хранилище в составе одного блока на один поток загрузки. Значение подбирается в зависимости от параметров производительности инфраструктуры. | . Ограничения . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Имена таблицы и ее столбцов должны начинаться с латинской буквы, после первого символа могут следовать латинские буквы, цифры и символы подчеркивания в любом порядке. | Таблица и ее столбцы не могут иметь имена, перечисленные в разделе Зарезервированные слова. | . Пример . CREATE UPLOAD EXTERNAL TABLE marketing.sales_ext_upload ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_UPLOAD_EXTERNAL_TABLE/CREATE_UPLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_UPLOAD_EXTERNAL_TABLE/CREATE_UPLOAD_EXTERNAL_TABLE.html"
  },"169": {
    "doc": "CREATE VIEW",
    "title": "CREATE VIEW",
    "content": "CREATE VIEW . Запрос позволяет создать или заменить логическое представление в логической базе данных. Логическое представление можно создать на основе данных одной или нескольких логических таблиц. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Если при обработке запроса происходит ошибка, последующее изменение сущностей логической базы данных невозможно. В этом случае нужно повторить запрос. Действие перезапустит обработку запроса, и после ее завершения можно будет продолжить работу с логической БД. Каждое создание представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Синтаксис . Создание логического представления: . CREATE VIEW [db_name.]view_name AS SELECT query . Создание логического представления с заменой существующего представления, если такое будет найдено: . CREATE OR REPLACE VIEW [db_name.]view_name AS SELECT query . Параметры: . | db_name — имя логической базы данных, в которой создается или заменяется логическое представление. Опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя создаваемого или заменяемого логического представления. В запросе на создание представления имя должно быть уникально среди логических сущностей логической БД; | query — SELECT-подзапрос, на основе которого строится логическое представление. | . Ограничения . | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | Имена представления и его столбцов должны начинаться с латинской буквы, после первого символа могут следовать латинские буквы, цифры и символы подчеркивания в любом порядке. | Представление и его столбцы не могут иметь имена, перечисленные в разделе Зарезервированные слова. | В подзапросе query не допускается использование: . | логических представлений, | системных представлений INFORMATION_SCHEMA, | ключевого слова FOR SYSTEM_TIME. | . | Ключевое слово DATASOURCE_TYPE, указанное в подзапросе query, игнорируется. | . Пример . CREATE VIEW marketing.stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM marketing.sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 20 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/CREATE_VIEW/CREATE_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_VIEW/CREATE_VIEW.html"
  },"170": {
    "doc": "DENY_CHANGES",
    "title": "DENY_CHANGES",
    "content": "DENY_CHANGES . Запрос позволяет временно запретить создание, удаление и изменение сущностей логической базы данных: . | логических таблиц, | логических представлений, | материализованных представлений. | . В запросе можно указать произвольный код, без которого снятие запрета будет невозможно. При установленном запрете остаются доступны все действия с данными: загрузка, обновление, чтение и выгрузка. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Чтобы снять запрет на изменение сущностей, используйте запрос ALLOW_CHANGES. Синтаксис . DENY_CHANGES([db_name, ['code']]) . Параметры: . | db_name — имя логической базы данных, для которой устанавливается запрет изменений. Опциональный параметр, если выбрана логическая БД, используемая по умолчанию; | code — произвольный код-пароль, без которого будет невозможно снять запрет после установки. Опциональный параметр. | . Ограничения . Выполнение запроса недоступно при наличии другого запрета изменений или незавершенного запроса на создание, удаление или изменение таблицы или представления. Примеры . Установка запрета без кода . Установка запрета для указанной логической базы данных: . DENY_CHANGES(marketing) . Установка запрета для логической базы данных, выбранной по умолчанию: . DENY_CHANGES() . Установка запрета с кодом . Установка запрета для указанной логической базы данных: . DENY_CHANGES(marketing, 'my awesome code') . Установка запрета для логической базы данных, выбранной по умолчанию: . DENY_CHANGES('любой код') . На рисунке ниже показан пример ответа на запрос DROP VIEW после установки запрета изменений с помощью DENY_CHANGES. В ответе возвращается ошибка, поясняющая, что изменение логических сущностей запрещено. Ответ на запрос удаления представления после установки запрета изменений . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DENY_CHANGES/DENY_CHANGES.html",
    "relUrl": "/reference/sql_plus_requests/DENY_CHANGES/DENY_CHANGES.html"
  },"171": {
    "doc": "DROP DATABASE",
    "title": "DROP DATABASE",
    "content": "DROP DATABASE . Запрос позволяет удалить логическую базу данных и все ее данные. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При удалении логической базы данных без ключевого слова LOGICAL_ONLY удаляются все ее данные и вся история изменений этих данных. Кроме того, удаляются все сторонние данные, принадлежащие соответствующим пространствам имен в СУБД хранилища. Удаленные данные невозможно восстановить средствами системы. Синтаксис . Удаление логической базы данных: . DROP DATABASE db_name . Удаление логической базы данных только на логическом уровне: . DROP DATABASE db_name LOGICAL_ONLY . Параметры: . | db_name — имя удаляемой логической базы данных. | . Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет удалить логическую базу данных и все ее дочерние логические сущности только на логическом уровне (из логической схемы данных), без удаления связанной физической базы данных и размещенных в ней данных из хранилища данных. Если ключевое слово не указано, удаляется как логическая, так и связанная с ней физическая база данных. Ограничения . Недоступно удаление сервисной базы данных INFORMATION_SCHEMA. Примеры . Удаление логической БД . DROP DATABASE marketing . Удаление логической БД только на логическом уровне . DROP DATABASE marketing1 LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DROP_DATABASE/DROP_DATABASE.html",
    "relUrl": "/reference/sql_plus_requests/DROP_DATABASE/DROP_DATABASE.html"
  },"172": {
    "doc": "DROP DOWNLOAD EXTERNAL TABLE",
    "title": "DROP DOWNLOAD EXTERNAL TABLE",
    "content": "DROP DOWNLOAD EXTERNAL TABLE . Запрос позволяет удалить внешнюю таблицу выгрузки из логической базы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . DROP DOWNLOAD EXTERNAL TABLE [db_name.]ext_table_name . Параметры: . | db_name — имя логической базы данных, из которой удаляется внешняя таблица выгрузки. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя удаляемой внешней таблицы выгрузки. | . Ограничения . Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. Пример . DROP DOWNLOAD EXTERNAL TABLE marketing.sales_ext_download . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DROP_DOWNLOAD_EXTERNAL_TABLE/DROP_DOWNLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/DROP_DOWNLOAD_EXTERNAL_TABLE/DROP_DOWNLOAD_EXTERNAL_TABLE.html"
  },"173": {
    "doc": "DROP MATERIALIZED VIEW",
    "title": "DROP MATERIALIZED VIEW",
    "content": "DROP MATERIALIZED VIEW . Содержание раздела . | Синтаксис . | Ключевое слово IF EXISTS | Ключевое слово DATASOURCE_TYPE | Ключевое слово LOGICAL_ONLY | . | Ограничения | Примеры . | Удаление представления с удалением данных из всех СУБД | Удаление представления с проверкой его наличия | Удаление представления с удалением данных из ADG | Удаление представления только на логическом уровне | . | . Запрос позволяет удалить материализованное представление и его данные. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Если при обработке запроса происходит ошибка, последующее изменение сущностей логической базы данных невозможно. В этом случае нужно повторить запрос. Действие перезапустит обработку запроса, и после ее завершения можно будет продолжить работу с логической БД. Каждое удаление представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Синтаксис . DROP MATERIALIZED VIEW [IF EXISTS] [db_name.]materialized_view_name [DATASOURCE_TYPE = datasource_alias] [LOGICAL_ONLY] . Параметры: . | db_name — имя логической базы данных, из которой удаляется материализованное представление. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя удаляемого материализованного представления; | datasource_alias — псевдоним СУБД хранилища, из которой удаляются данные материализованного представления. Возможные значения: adqm, adg. Значение можно указывать без кавычек, в одинарных кавычках (например, 'adg') или двойных кавычках (например, \"adg\"). Если ключевое слово DATASOURCE_TYPE с псевдонимом не указано, данные удаляются из всех СУБД хранилища. | . Ключевое слово IF EXISTS . Ключевое слово IF EXISTS включает проверку наличия материализованного представления до попытки его удаления. Если ключевое слово указано в запросе, система возвращает успешный ответ как по успешно удаленному, так и несуществующему представлению; иначе — только по успешно удаленному представлению. Ключевое слово DATASOURCE_TYPE . Ключевое слово DATASOURCE_TYPE позволяет указать СУБД хранилища, из которых необходимо удалить данные материализованного представления. В текущей версии данные представления могут размещаться в ADG и (или) ADQM. Само материализованное представление удаляется из логической схемы данных при удалении его данных из последней СУБД хранилища. Если ключевое слово не указано, данные представления удаляются из всех СУБД хранилища. Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет удалить материализованное представление только на логическом уровне (из логической схемы данных), без удаления связанных физических таблиц и размещенных в них данных из хранилища данных. Если ключевое слово не указано, удаляется как материализованное представление, так и связанные с ним физические таблицы. Ограничения . | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . Примеры . Удаление представления с удалением данных из всех СУБД . DROP MATERIALIZED VIEW marketing.sales_and_stores . Удаление представления с проверкой его наличия . DROP MATERIALIZED VIEW IF EXISTS marketing.mat_view_with_unknown_existence . Удаление представления с удалением данных из ADG . DROP MATERIALIZED VIEW marketing.sales_and_stores DATASOURCE_TYPE = 'adg' . Удаление представления только на логическом уровне . DROP MATERIALIZED VIEW marketing.stores_by_sold_products_matview LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DROP_MATERIALIZED_VIEW/DROP_MATERIALIZED_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/DROP_MATERIALIZED_VIEW/DROP_MATERIALIZED_VIEW.html"
  },"174": {
    "doc": "DROP TABLE",
    "title": "DROP TABLE",
    "content": "DROP TABLE . Содержание раздела . | Синтаксис . | Ключевое слово IF EXISTS | Ключевое слово DATASOURCE_TYPE | Ключевое слово LOGICAL_ONLY | . | Ограничения | Примеры . | Удаление таблицы с удалением данных из всех СУБД | Удаление таблицы и ее данных с проверкой наличия таблицы | Удаление таблицы с удалением данных из ADB и ADG | Удаление таблицы только на логическом уровне | . | . Запрос позволяет удалить логическую таблицу и ее данные. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Для удаления данных логической таблицы только из некоторых СУБД хранилища можно указать ключевое слово DATASOURCE_TYPE (см. секцию Ключевое слово DATASOURCE_TYPE). Удаленные данные невозможно восстановить средствами системы. Если при обработке запроса происходит ошибка, последующее изменение сущностей логической базы данных невозможно. В этом случае нужно повторить запрос. Действие перезапустит обработку запроса, и после ее завершения можно будет продолжить работу с логической БД. Каждое удаление таблицы записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Синтаксис . DROP TABLE [IF EXISTS] [db_name.]table_name [DATASOURCE_TYPE = datasource_alias] [LOGICAL_ONLY] . Параметры: . | db_name — имя логической базы данных, из которой удаляется логическая таблица. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя удаляемой логической таблицы; | datasource_alias — псевдоним СУБД хранилища, из которой удаляются данные логической таблицы. Возможные значения: adb, adqm, adg, adp. Значение можно указывать без кавычек, в одинарных кавычках (например, 'adb') или двойных кавычках (например, \"adb\"). Если ключевое слово DATASOURCE_TYPE с псевдонимом не указано, данные удаляются из всех СУБД хранилища. | . Ключевое слово IF EXISTS . Ключевое слово IF EXISTS включает проверку наличия логической таблицы до попытки ее удаления. Если ключевое слово указано в запросе, система возвращает успешный ответ как по успешно удаленной, так и несуществующей таблице; иначе — только по успешно удаленной таблице. Ключевое слово DATASOURCE_TYPE . Ключевое слово DATASOURCE_TYPE позволяет указать СУБД хранилища, из которых необходимо удалить данные логической таблицы. Сама логическая таблица удаляется из логической схемы данных при удалении данных таблицы из последней СУБД хранилища. Если ключевое слово не указано, данные таблицы удаляются из всех СУБД хранилища. Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет удалить логическую таблицу только на логическом уровне (из логической схемы данных), без удаления связанных физических таблиц и размещенных в них данных из хранилища данных. Если ключевое слово не указано, удаляется как логическая, так и связанные с ней физические таблицы. Ограничения . | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . Примеры . Удаление таблицы с удалением данных из всех СУБД . DROP TABLE marketing.sales . Удаление таблицы и ее данных с проверкой наличия таблицы . DROP TABLE IF EXISTS marketing.sales_unknown_existence . Удаление таблицы с удалением данных из ADB и ADG . -- удаление таблицы из ADB DROP TABLE marketing.stores DATASOURCE_TYPE = adb; -- удаление таблицы из ADG DROP TABLE marketing.stores DATASOURCE_TYPE = adg; . Удаление таблицы только на логическом уровне . DROP TABLE marketing.sales1 LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DROP_TABLE/DROP_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/DROP_TABLE/DROP_TABLE.html"
  },"175": {
    "doc": "DROP UPLOAD EXTERNAL TABLE",
    "title": "DROP UPLOAD EXTERNAL TABLE",
    "content": "DROP UPLOAD EXTERNAL TABLE . Запрос позволяет удалить внешнюю таблицу загрузки из логической базы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . DROP UPLOAD EXTERNAL TABLE [db_name.]ext_table_name . Параметры: . | db_name — имя логической базы данных, из которой удаляется внешняя таблица загрузки. Опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя удаляемой внешней таблицы загрузки. | . Ограничения . Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. Пример . DROP UPLOAD EXTERNAL TABLE marketing.sales_ext_upload . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DROP_UPLOAD_EXTERNAL_TABLE/DROP_UPLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/DROP_UPLOAD_EXTERNAL_TABLE/DROP_UPLOAD_EXTERNAL_TABLE.html"
  },"176": {
    "doc": "DROP VIEW",
    "title": "DROP VIEW",
    "content": "DROP VIEW . Запрос позволяет удалить логическое представление из логической базы данных. При успешном выполнении запроса логическое представление удаляется из логической схемы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Если при обработке запроса происходит ошибка, последующее изменение сущностей логической базы данных невозможно. В этом случае нужно повторить запрос. Действие перезапустит обработку запроса, и после ее завершения можно будет продолжить работу с логической БД. Каждое удаление представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Синтаксис . DROP VIEW [db_name.]view_name . Параметры: . | db_name — имя логической базы данных, из которой удаляется логическое представление. Опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя удаляемого логического представления. | . Ограничения . | Выполнение запроса недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . | Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. | . Пример . DROP VIEW marketing.stores_by_sold_products . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/DROP_VIEW/DROP_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/DROP_VIEW/DROP_VIEW.html"
  },"177": {
    "doc": "GET_CHANGES",
    "title": "GET_CHANGES",
    "content": "GET_CHANGES . Запрос позволяет получить содержимое журнала — список всех операций по изменению сущностей в логической базе данных. Журнал ведется в системе, начиная с версии 5.3. Изменения, выполненные в более ранних версиях, в журнале отсутствуют. Для логических базы данных, которые создавались и изменялись только до версии 5.3, запрос GET_CHANGES возвращает пустой объект ResultSet`. По каждой операции доступна следующая информация: . | change_num — номер операции. Нумерация ведется в рамках логической базы данных; | entity_name — имя логической сущности; | change_query — содержимое запроса на изменение логической сущности; | start_time — дата и время начала выполнения запроса change_query; | end_time — дата и время окончания выполнения запроса change_query. Если поле пустое, это означает, что операция еще не завершена; | delta_num — последняя закрытая дельта в логической базе данных на момент запроса информации. Если закрытых дельт еще нет, поле имеет пустое значение. | . Успешный ответ содержит объект ResultSet, где каждая строка соответствует одной операции, неуспешный ответ содержит исключение. Синтаксис . GET_CHANGES([db_name]) . Параметры: . | db_name — имя логической базы данных, для которой запрашивается журнал. Опционально, если выбрана логическая БД, используемая по умолчанию. | . Примеры . Запрос журнала для указанной логической базы данных: . GET_CHANGES(marketing) . Запрос журнала для логической базы данных, выбранной по умолчанию: . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- запрос журнала для marketing GET_CHANGES(); . На рисунке ниже показан пример ответа на запрос GET_CHANGES. Ответ содержит информацию о пяти созданных таблицах: первая была создана до всех дельт, вторая — после нулевой дельты, остальные — после первой дельты. Ответ GET_CHANGES . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/GET_CHANGES/GET_CHANGES.html",
    "relUrl": "/reference/sql_plus_requests/GET_CHANGES/GET_CHANGES.html"
  },"178": {
    "doc": "GET_DELTA_BY_DATETIME",
    "title": "GET_DELTA_BY_DATETIME",
    "content": "GET_DELTA_BY_DATETIME . Запрос позволяет получить информацию о последней закрытой дельте на указанные дату и время. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дельте, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия дельты, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_BY_DATETIME(date_time_expression) . Параметры: . | date_time_expression — момент даты-времени вида 'YYYY-MM-DD hh:mm:ss'. Возможные форматы см. в разделе Форматы даты и времени. | . Пример . GET_DELTA_BY_DATETIME('2021-03-25 07:30:32') . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/GET_DELTA_BY_DATETIME/GET_DELTA_BY_DATETIME.html",
    "relUrl": "/reference/sql_plus_requests/GET_DELTA_BY_DATETIME/GET_DELTA_BY_DATETIME.html"
  },"179": {
    "doc": "GET_DELTA_BY_NUM",
    "title": "GET_DELTA_BY_NUM",
    "content": "GET_DELTA_BY_NUM . Запрос позволяет получить информацию о закрытой дельте по ее номеру. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дельте, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия дельты, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_BY_NUM(delta_num) . Параметры: . | delta_num — целый неотрицательный номер дельты. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/GET_DELTA_BY_NUM/GET_DELTA_BY_NUM.html",
    "relUrl": "/reference/sql_plus_requests/GET_DELTA_BY_NUM/GET_DELTA_BY_NUM.html"
  },"180": {
    "doc": "GET_DELTA_HOT",
    "title": "GET_DELTA_HOT",
    "content": "GET_DELTA_HOT . Запрос позволяет получить информацию о горячей дельте. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью при успешном выполнении запроса. Если дельта присутствует, запись содержит информацию о дельте, иначе — возвращается пустая запись; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты; | [cn_from, cn_to] — диапазон порядковых номеров непрерывной последовательности операций записи, выполненных в рамках дельты; | cn_max — максимальный номер операции среди операций записи, выполненных в рамках дельты. До успешного завершения операций записи возвращается максимальный номер операции записи в последней закрытой дельте; | is_rolling_back — флаг отката; | write_op_finished — массив операций записей, выполненных в рамках дельты. | . В связи с многопоточной обработкой операций значения cn_to и cn_max горячей дельты могут отличаться. Например, если в рамках горячей дельты завершены операции записи с номерами 1, 2, 3 и 7, то значение cn_to этой дельты равно 3, а значение cn_max равно 7. Синтаксис . GET_DELTA_HOT() . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/GET_DELTA_HOT/GET_DELTA_HOT.html",
    "relUrl": "/reference/sql_plus_requests/GET_DELTA_HOT/GET_DELTA_HOT.html"
  },"181": {
    "doc": "GET_DELTA_OK",
    "title": "GET_DELTA_OK",
    "content": "GET_DELTA_OK . Запрос позволяет получить информацию о последней закрытой дельте. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью при успешном выполнении запроса. Если дельта присутствует, запись содержит информацию о дельте, иначе — возвращается пустая запись; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_OK() . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/GET_DELTA_OK/GET_DELTA_OK.html",
    "relUrl": "/reference/sql_plus_requests/GET_DELTA_OK/GET_DELTA_OK.html"
  },"182": {
    "doc": "GET_ENTITY_DDL",
    "title": "GET_ENTITY_DDL",
    "content": "GET_ENTITY_DDL . Запрос позволяет получить содержимое запроса на создание логической сущности в текущем состоянии. Информацию можно получить по следующим логическим сущностям: . | логической таблице, | логическому представлению, | материализованному представлению. | . Успешный ответ содержит объект ResultSet с одной строкой, в которой представлен запрос на создание сущности. Неуспешный ответ содержит исключение. Синтаксис . GET_ENTITY_DDL([db_name.]entity_name) . Параметры: . | db_name — имя логической базы данных, которой принадлежит запрашиваемая сущность. Опционально, если выбрана логическая БД, используемая по умолчанию; | entity_name — имя таблицы или представления, по которому запрашивается информация. | . Примеры . Запрос по сущности указанной логической БД . GET_ENTITY_DDL(marketing.stores) . Запрос по сущности логической БД, выбранной по умолчанию . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- запрос информации по представлению sales_and_stores GET_ENTITY_DDL(sales_and_stores); . На рисунке ниже показан фрагмент ответа на запрос GET_ENTITY_DDL по материализованному представлению sales_and_stores. Фрагмент ответа на запрос GET_ENTITY_DDL . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/GET_ENTITY_DDL/GET_ENTITY_DDL.html",
    "relUrl": "/reference/sql_plus_requests/GET_ENTITY_DDL/GET_ENTITY_DDL.html"
  },"183": {
    "doc": "GET_WRITE_OPERATIONS",
    "title": "GET_WRITE_OPERATIONS",
    "content": "GET_WRITE_OPERATIONS . Запрос позволяет получить информацию об операциях записи горячей дельты, находящихся в статусах «Выполняется» и «Отменяется». Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. По каждой операции доступна следующая информация: . | sys_cn — номер операции записи; | status — статус операции записи. Возможные значения: 0 — выполняется, 2 — отменяется; | destination_table_name — имя логической таблицы-приемника данных; | external_table_name — имя внешней таблицы загрузки, которая была задействована в операции записи. Значение отсутствует, если внешняя таблица не была задействована в операции (например, операция была запущена функцией обновления данных); | query — исходный запрос операции записи. | . Успешный ответ содержит объект ResultSet, где каждая строка соответствует одной операции, неуспешный ответ содержит исключение. Если среди операций в ответе есть долго выполняемые (зависшие) или неуспешные операции, следует перезапустить их обработку с помощью запроса RESUME_WRITE_OPERATION. Синтаксис . GET_WRITE_OPERATIONS() . На рисунке ниже показан пример ответа с одной операцией в статусе «Выполняется». Операция запущена запросом INSERT INTO logical_table, который загружает данные в логическую таблицу sales с использованием внешней таблицы загрузки sales_ext_upload. Пример ответа на запрос GET_WRITE_OPERATIONS . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/GET_WRITE_OPERATIONS/GET_WRITE_OPERATIONS.html",
    "relUrl": "/reference/sql_plus_requests/GET_WRITE_OPERATIONS/GET_WRITE_OPERATIONS.html"
  },"184": {
    "doc": "INSERT INTO logical_table",
    "title": "INSERT INTO logical_table",
    "content": "INSERT INTO logical_table . Содержание раздела . | Синтаксис | Ограничения | Пример | . Запрос позволяет загрузить данные в логическую таблицу логической базы данных из внешнего источника данных. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на загрузку данных. Загружаемые данные должны соответствовать формату, указанному при создании внешней таблицы загрузки и описанному в разделе Формат загрузки данных. Для загрузки небольшого объема данных можно использовать обновление данных. Перед выполнением запроса необходимо создать внешнюю таблицу, загрузить данные в топик Kafka и открыть дельту. Подробнее о порядке выполнения действий для загрузки данных см. в разделе Загрузка данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса данные загружаются в СУБД хранилища, выбранные для размещения данных таблицы. Месторасположение данных таблицы можно задавать запросами CREATE TABLE и DROP TABLE. Загрузка данных возможна только в логическую таблицу. Загрузка данных в логические и материализованные представления недоступна. Синтаксис . Запрос с явным перечислением столбцов внешней таблицы: . INSERT INTO [db_name.]table_name SELECT column_list FROM [db_name.]ext_table_name . Запрос с использованием символа *: . INSERT INTO [db_name.]table_name SELECT * FROM [db_name.]ext_table_name . Параметры: . | db_name — имя логической базы данных. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя логической таблицы, в которую загружаются данные; | column_list — список имен всех столбцов внешней таблицы загрузки. Имена и порядок следования указанных столбцов должны совпадать с именами и порядком следования столбцов (полей) в логической таблице, куда загружаются данные, и топике Kafka, из которого загружаются данные; | ext_table_name — имя внешней таблицы загрузки. | . В загружаемых сообщениях топика Kafka последним полем обязательно указывается служебное поле sys_op. Соответствующий столбец sys_op отсутствует в логической таблице и внешней таблице загрузки, однако имена и порядок всех остальных столбцов (полей) должны совпадать во всех трех объектах: в сообщении, логической и внешней таблицах (см. раздел Формат загрузки данных). Ограничения . Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). Пример . Пример загрузки данных с открытием и закрытием дельты: . -- выбор логической базы данных marketing в качестве БД по умолчанию USE marketing; -- открытие новой (горячей) дельты BEGIN DELTA; -- запуск загрузки данных в логическую таблицу sales INSERT INTO sales SELECT * FROM sales_ext_upload; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_INTO_logical_table/INSERT_INTO_logical_table.html",
    "relUrl": "/reference/sql_plus_requests/INSERT_INTO_logical_table/INSERT_INTO_logical_table.html"
  },"185": {
    "doc": "INSERT VALUES",
    "title": "INSERT VALUES",
    "content": "INSERT VALUES . Содержание раздела . | Синтаксис | Ограничения | Пример . | Вставка данных во все столбцы таблицы | Вставка данных в указанные столбцы таблицы | . | . Запрос позволяет вставить новые записи и обновить существующие записи в логической таблице. Существование записи в таблице определяется по значению первичного ключа. Если в таблице существует запись со значением первичного ключа, указанным в запросе, запись обновляется; иначе добавляется новая запись. Новые и существующие записи заполняются одинаково: поля, указанные в запросе, заполняются значениями из запроса, а пропущенные поля — значениями по умолчанию. Запрос поддерживается для ADB, ADQM и ADP. В отличие от UPSERT VALUES, запрос INSERT VALUES полностью обновляет существующую запись. Для частичного обновления существующих записей следует использовать запрос UPSERT VALUES. Для обновления большого объема данных следует использовать загрузку данных. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на обновление данных. Вставка данных в логические и материализованные представления недоступна. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса записи вставляются в СУБД хранилища, в которых размещены данные логической таблицы. При фиксации изменений каждая вставленная запись становится актуальной записью таблицы, а предыдущая актуальная запись, если такая есть, становится архивной. Месторасположение данных таблицы можно задавать запросами CREATE TABLE и DROP TABLE с ключевым словом DATASOURCE_TYPE. Все записи таблицы с одинаковым первичным ключом рассматриваются системой как различные исторические состояния одного объекта. Подробнее о версионировании см. в разделе Версионирование данных. Если операция записи, запущенная запросом INSERT VALUES, зависла, горячую дельту невозможно закрыть или откатить. В этом случае нужно повторить запрос. Действие перезапустит обработку операции, и после ее завершения можно будет закрыть или откатить дельту. Список незавершенных (в том числе — зависших) операций можно посмотреть с помощью запроса GET_WRITE_OPERATIONS. Синтаксис . Вставка данных во все столбцы логической таблицы: . INSERT INTO [db_name.]table_name VALUES (value_list_1), (value_list_2), ... Вставка данных только в некоторые столбцы логической таблицы (с заполнением остальных столбцов значениями, которые определены в СУБД хранилища как значения по умолчанию): . INSERT INTO [db_name.]table_name (column_list) VALUES (value_list_1), (value_list_2), ... Параметры: . | db_name — имя логической базы данных. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя логической таблицы, в которую вставляются данные; | column_list — список имен столбцов логической таблицы. Имена указываются в круглых скобках через запятую. Список опционален, если количество и порядок вставляемых значений (в списке value_list_N) соответствуют количеству и порядку столбцов в логической таблице; | value_list_N — список значений, вставляемых в столбцы логической таблицы. Значения указываются в круглых скобках через запятую. Каждый такой список — это строка, вставляемая в таблицу. | . Ограничения . | Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). | Столбцы в запросе не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | . Пример . Вставка данных во все столбцы таблицы . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка трех записей в логическую таблицу sales INSERT INTO sales VALUES (100011, '2021-08-21 23:34:10', 'ABC0001', 2, 123, 'Покупка по акции \"1+1\"'), (100012, '2021-08-22 10:05:56', 'ABC0001', 1, 234, 'Покупка без акций'), (100113, '2021-08-22 13:17:47', 'ABC0002', 4, 123, 'Покупка по акции \"Лето\"'); -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Вставка данных в указанные столбцы таблицы . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка двух записей в логическую таблицу sales (без опционального значения description) INSERT INTO sales (id, transaction_date, product_code, product_units, store_id) VALUES (100014, '2021-08-23 09:34:10', 'ABC0003', 3, 123), (100012, '2021-08-23 20:05:56', 'ABC0001', 6, 234); -- закрытие дельты (фиксация изменений) COMMIT DELTA; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/INSERT_VALUES/INSERT_VALUES.html",
    "relUrl": "/reference/sql_plus_requests/INSERT_VALUES/INSERT_VALUES.html"
  },"186": {
    "doc": "RESUME_WRITE_OPERATION",
    "title": "RESUME_WRITE_OPERATION",
    "content": "RESUME_WRITE_OPERATION . Запрос позволяет возобновить обработку операций записи горячей дельты со статусами «Выполняется» и «Отменяется» (далее — незавершенные операции). Если операция имеет статус «Отменяется», то запускается отмена этой операции; если операция имеет статус «Выполняется», то возобновляется отслеживание загрузки данных в СУБД хранилища. Аналогичный процесс автоматически выполняется для всех незавершенных операций при рестарте системы. Возобновление обработки недоступно для операций обновления данных со статусом «Выполняется». Статусы операций и исходные запросы, которыми были запущены эти операции, можно узнать с помощью запроса GET_WRITE_OPERATIONS. Возобновить обработку можно для одной или всех незавершенных операций горячей дельты. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса или отсутствии незавершенных операций записи. | . Для возобновления обработки операций только со статусом «Отменяется» можно использовать запрос ROLLBACK CRASHED_WRITE_OPERATIONS. Синтаксис . Возобновление обработки одной незавершенной операции: . RESUME_WRITE_OPERATION(write_operation_number) . Возобновление обработки всех незавершенных операций: . RESUME_WRITE_OPERATION() . Параметры: . | write_operation_number — номер операции записи, обработку которой нужно возобновить. Если номер не указан, возобновляется обработка всех незавершенных операций, которые есть в горячей дельте логической базы данных. | . Номер операции можно узнать с помощью запроса GET_WRITE_OPERATIONS. Пример . RESUME_WRITE_OPERATION(14) . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/RESUME_WRITE_OPERATION/RESUME_WRITE_OPERATION.html",
    "relUrl": "/reference/sql_plus_requests/RESUME_WRITE_OPERATION/RESUME_WRITE_OPERATION.html"
  },"187": {
    "doc": "ROLLBACK CRASHED_WRITE_OPERATIONS",
    "title": "ROLLBACK CRASHED_WRITE_OPERATIONS",
    "content": "ROLLBACK CRASHED_WRITE_OPERATIONS . Запрос позволяет возобновить обработку операций записи горячей дельты, находящихся в статусе «Отменяется». При ошибках загрузки и обновления данных система автоматически отменяет неуспешные операции записи и возвращает данные СУБД хранилища в состояние, которое предшествовало загрузке или обновлению. Однако, если произошел сбой, например из-за неполадок в сети, операция может остаться в статусе «Отменяется». В этом случае следует устранить причины, по которым операция не была завершена, и возобновить ее обработку с помощью запроса ROLLBACK CRASHED_WRITE_OPERATIONS или RESUME_WRITE_OPERATION. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. Успешный ответ содержит объект ResultSet, где каждая строка соответствует одной возобновленной операции записи со статусом «Отменяется», неуспешный ответ содержит исключение. Пустая строка в ответе означает, что в горячей дельте нет операций со статусом «Отменяется». По каждой возобновленной операции записи возвращается следующая информация: . | table_name — имя логической таблицы-приемника данных; | sys_cn_operations — номер операции записи. | . Синтаксис . ROLLBACK CRASHED_WRITE_OPERATIONS . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/ROLLBACK_CRASHED_WRITE_OPERATIONS/ROLLBACK_CRASHED_WRITE_OPERATIONS.html",
    "relUrl": "/reference/sql_plus_requests/ROLLBACK_CRASHED_WRITE_OPERATIONS/ROLLBACK_CRASHED_WRITE_OPERATIONS.html"
  },"188": {
    "doc": "ROLLBACK DELTA",
    "title": "ROLLBACK DELTA",
    "content": "ROLLBACK DELTA . Запрос позволяет откатить горячую (открытую) дельту — отменить все ее завершенные операции записи (загрузки и обновления данных), а также незавершенные операции загрузки данных. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. После запуска запроса невозможно закрыть дельту, даже если система не смогла откатить дельту и вернула исключение. Невозможен откат незавершенных операций обновления данных горячей дельты, а также откат любых операций закрытой дельты. Система не гарантирует остановку и отмену всех операций за один вызов. Если в ответ на запрос вернулась ошибка Can't rollback delta by datamart &lt;db_name&gt;, это означает, что не все операции записи горячей дельты были отменены. В этом случае необходимо повторить запрос. Откат горячей дельты выполняется в следующем порядке: . | Останавливаются выполняемые операции загрузки данных. Операции останавливаются асинхронно, и система периодически проверяет, остались ли неостановленные операции. Проверка запускается раз в интервал, равный значению параметра DELTA_ROLLBACK_STATUS_CALLS_MS в конфигурации системы. | Отменяются следующие операции горячей дельты (и связанные с ними изменения): все операции, завершенные успешно или с ошибкой, а также остановленные операции загрузки данных. Незавершенные операции обновления данных не отменяются. | Горячая дельта удаляется из сервисной базы данных, и зарезервированный ранее номер горячей дельты освобождается. | . В ответе возвращается: . | объект ResultSet c одной записью, содержащей номер последней закрытой дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Если операция обновления данных зависла, дельту невозможно закрыть или откатить. В этом случае нужно повторить запрос, запустивший проблемную операцию. Действие перезапустит обработку операции, и после ее завершения можно будет откатить или закрыть дельту. После отката горячей дельты становятся доступны действия по созданию, удалению и изменению таблиц и представлений. Синтаксис . ROLLBACK DELTA . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/ROLLBACK_DELTA/ROLLBACK_DELTA.html",
    "relUrl": "/reference/sql_plus_requests/ROLLBACK_DELTA/ROLLBACK_DELTA.html"
  },"189": {
    "doc": "SELECT FROM INFORMATION_SCHEMA",
    "title": "SELECT FROM INFORMATION_SCHEMA",
    "content": "SELECT FROM INFORMATION_SCHEMA . Содержание раздела . | Синтаксис | Параметры | Ограничения | Примеры . | Запрос списка всех логических БД окружения | Запрос информации о сущностях логической БД | Запрос имен, типов и столбцов логических сущностей | . | . Запрос позволяет получить метаданные объектов логической схемы, описанные в разделе Системные представления (INFORMATION_SCHEMA). Возможности запроса отличаются от возможностей SELECT-запроса к логическим базам данных. В ответе возвращается: . | объект ResultSet c выбранными записями при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . SELECT column_list FROM [INFORMATION_SCHEMA.]system_view_name [AS alias_name] . Описание параметров запроса см. ниже. Префикс INFORMATION_SCHEMA перед именем системного представления опционален, если до этого был выполнен запрос USE INFORMATION_SCHEMA. Для имен системных представлений и столбцов можно использовать псевдонимы. В запросе поддерживаются следующие ключевые слова, которые должны быть указаны в порядке их перечисления: . | JOIN ON — для соединения данных нескольких системных представлений; | WHERE — для указания условий выбора данных; | GROUP BY — для группировки данных; | ORDER BY — для сортировки данных; | LIMIT — для ограничения количества возвращаемых строк. | . Строковые значения столбцов для ключевого слова WHERE необходимо указывать в верхнем регистре (например, WHERE table_schema = 'MARKETING'). Поддерживаются следующие типы соединений системных представлений: . | [INNER] — внутреннее соединение, | LEFT [OUTER] — левое внешнее соединение, | RIGHT [OUTER] — правое внешнее соединение, | FULL [OUTER] — полное внешнее соединение, | CROSS — декартово произведение, ключи соединения не указываются. | . Параметры . | column_list — список выбираемых столбцов. Допустимо указывать символ * для выбора всех столбцов; | system_view_name — имя системного представления, из которого запрашивается информация. Возможные значения см. в разделе Системные представления (INFORMATION_SCHEMA); | alias_name — псевдоним системного представления. | . Ограничения . Не допускается комбинирование подзапросов к INFORMATION_SCHEMA с подзапросами к логическим базам данных. Примеры . Запрос списка всех логических БД окружения . Запрос списка всех логических БД окружения с лексической сортировкой по возрастанию: . SELECT schema_name FROM INFORMATION_SCHEMA.schemata ORDER BY schema_name . Запрос информации о сущностях логической БД . Запрос информации о логических сущностях логической БД MARKETING: . SELECT * FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'MARKETING' . Запрос имен, типов и столбцов логических сущностей . Запрос списка имен, типов и столбцов логических сущностей окружения: . SELECT TC.table_schema, TC.table_name, TT.table_type, TC.column_name FROM information_schema.columns AS TC JOIN information_schema.tables AS TT ON TC.table_schema = TT.table_schema and TC.table_name = TT.table_name ORDER BY TC.table_schema, TC.table_name . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/SELECT_FROM_INFORMATION_SCHEMA/SELECT_FROM_INFORMATION_SCHEMA.html",
    "relUrl": "/reference/sql_plus_requests/SELECT_FROM_INFORMATION_SCHEMA/SELECT_FROM_INFORMATION_SCHEMA.html"
  },"190": {
    "doc": "TRUNCATE HISTORY",
    "title": "TRUNCATE HISTORY",
    "content": "TRUNCATE HISTORY . Содержание раздела . | Синтаксис | Ограничения | Пример | . Запрос позволяет удалить актуальные записи логической таблицы с историей или только историю изменений. Данные выбираются по условию, указанному в блоке запроса WHERE. Данные удаляются окончательно и не подлежат восстановлению средствами системы. Запрос поддерживает два режима работы: . | если в запросе указан момент (метка) времени, удаляется только история — архивные записи таблицы, которые соответствуют условию и стали архивными до последней закрытой на тот момент дельты (включительно); | если в запросе указано ключевое слово infinite, удаляются записи с историей — архивные и актуальные записи таблицы, которые соответствуют условию. | . В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Удаление данных с помощью TRUNCATE HISTORY не версионируется системой и не записывается в журнал. Данные, удаленные таким образом, невозможно восстановить средствами системы. На рисунке ниже показан пример удаления истории изменений из таблицы, в которую в течение года было добавлено три версии записи по одной торговой точке. Запрос с меткой времени '2021-04-10 01:00:00' удаляет первую версию записи: на тот момент времени последней закрытой дельтой была дельта со второй версией записи и только первая версия записи была архивной. Удаление истории изменений старше 2021-04-10 01:00:00 . Синтаксис . TRUNCATE HISTORY [db_name.]table_name FOR SYSTEM_TIME AS OF date_time_expression [WHERE filter_expression] . Параметры: . | db_name — имя логической базы данных. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя логической таблицы, данные которой удаляются; | date_time_expression — выражение, определяющее категорию удаляемых данных. Может принимать следующие значения: . | 'YYYY-MM-DD hh:mm:ss' — удаление истории старше указанного момента времени. Возможные форматы см. в разделе Форматы даты и времени; | 'infinite' — удаление записей с историей; | . | filter_expression — условие выбора удаляемых данных. | . Ограничения . Выполнение запроса недоступно в сервисной базе данных INFORMATION_SCHEMA. Пример . Удаление истории изменений тех записей, чье значение product_units меньше 10, из таблицы sales по момент времени '2019-12-23 15:15:14': . TRUNCATE HISTORY marketing.sales FOR SYSTEM_TIME AS OF '2019-12-23 15:15:14' WHERE product_units &lt; 10 . Удаление записей, чье значение id равно 123456, с историей изменений из таблицы stores: . TRUNCATE HISTORY marketing.stores FOR SYSTEM_TIME AS OF 'infinite' WHERE id = 123456 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/TRUNCATE_HISTORY/TRUNCATE_HISTORY.html",
    "relUrl": "/reference/sql_plus_requests/TRUNCATE_HISTORY/TRUNCATE_HISTORY.html"
  },"191": {
    "doc": "USE",
    "title": "USE",
    "content": "USE . Запрос позволяет изменить логическую базу данных по умолчанию на указанную логическую базу данных. Логическую базу данных по умолчанию необходимо определить перед выполнением запросов, предназначенных для управления дельтой и получения информации о ней. Это действие также можно выполнить перед другими запросами, что позволит не указывать имя логической БД перед именами логических сущностей в запросах к одной и той же логической базе данных. В ответе возвращается: . | объект ResultSet c одной записью, содержащей имя выбранной логической базы данных, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса указанная логическая база данных выбирается и используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или закрытие соединения с системой. Альтернативно можно определить логическую базу данных по умолчанию в настройках JDBC-подключения (см. Определение логической БД по умолчанию). Синтаксис . USE db_name . Параметры: . | db_name — имя логической базы данных, подлежащей установке по умолчанию. | . Пример . USE marketing . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/USE/USE.html",
    "relUrl": "/reference/sql_plus_requests/USE/USE.html"
  },"192": {
    "doc": "USE INFORMATION_SCHEMA",
    "title": "USE INFORMATION_SCHEMA",
    "content": "USE INFORMATION_SCHEMA . Запрос позволяет изменить логическую базу данных по умолчанию на сервисную базу данных. В ответе возвращается: . | объект ResultSet c одной записью, содержащей имя сервисной базы данных (information_schema), при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Если выполнить запрос перед запросами к сервисной базе данных, это позволит не указывать в запросах префикс INFORMATION_SCHEMA перед именами системных представлений. Синтаксис . USE INFORMATION_SCHEMA . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/USE_INFORMATION_SCHEMA/USE_INFORMATION_SCHEMA.html",
    "relUrl": "/reference/sql_plus_requests/USE_INFORMATION_SCHEMA/USE_INFORMATION_SCHEMA.html"
  },"193": {
    "doc": "Запросы SQL+",
    "title": "Запросы SQL+",
    "content": "Запросы SQL+ . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/sql_plus_requests/sql_plus_requests.html",
    "relUrl": "/reference/sql_plus_requests/sql_plus_requests.html"
  },"194": {
    "doc": "Выгружаемые типы данных Avro",
    "title": "Выгружаемые типы данных Avro",
    "content": "Выгружаемые типы данных Avro . Типы данных Avro, выгружаемые из системы, зависят от СУБД хранилища, из которой выгружаются данные. В таблице ниже для каждого логического типа данных указаны выгружаемые типы данных Avro. Подробнее о типах данных Avro см. в официальной документации Apache Avro. | Логический тип данных | Тип данных Avro, выгружаемый из ADB | Тип данных Avro, выгружаемый из ADG | Тип данных Avro, выгружаемый из ADQM | Тип данных Avro, выгружаемый из ADP | . | BOOLEAN | boolean | boolean | int | boolean | . | VARCHAR (n) | string | string | string | string | . | UUID | string | string | string | string | . | INT32 | int | int | int | int | . | INT | long | long | long | long | . | BIGINT | long | long | long | long | . | DOUBLE | double | double | double | double | . | FLOAT | float | float | float | float | . | DATE | int | int | int | int | . | TIME (precision) | long | long | long | long | . | TIMESTAMP (precision) | long | long | long | long | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/supported_data_types/download_data_types/download_data_types.html",
    "relUrl": "/reference/supported_data_types/download_data_types/download_data_types.html"
  },"195": {
    "doc": "Поддерживаемые типы данных",
    "title": "Поддерживаемые типы данных",
    "content": "Поддерживаемые типы данных . В разделе описаны следующие типы данных: . | логические типы данных системы и соответствующие им физические типы данных СУБД хранилища (см. Логические типы данных); | загружаемые типы данных Avro и соответствующие им логические типы данных (см. Загружаемые типы данных); | логические типы данных и соответствующие им выгружаемые типы данных Avro (см. Выгружаемые типы данных). | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/supported_data_types/supported_data_types.html",
    "relUrl": "/reference/supported_data_types/supported_data_types.html"
  },"196": {
    "doc": "Загружаемые типы данных Avro",
    "title": "Загружаемые типы данных Avro",
    "content": "Загружаемые типы данных Avro . Система поддерживает загрузку типов данных Avro, перечисленных в таблице ниже. Для каждого типа данных Avro указан соответствующий логический тип данных. Подробнее о типах данных Avro см. в официальной документации Apache Avro. | Загружаемый тип данных Avro | Логический тип данных | . | boolean | BOOLEAN | . | string | VARCHAR (n) | . | int | INT32 | . | long | BIGINT | . | float | FLOAT | . | double | DOUBLE | . | (int) date | DATE | . | (long) time-micros | TIME (precision) | . | (long) timestamp-micros | TIMESTAMP (precision) | . Значение типа данных (long) time-micros считается корректным, если лежит в интервале [0; 86399999999] микросекунд. Для значений этого типа данных, лежащих вне указанного интервала, успешная загрузка и дальнейшая корректная обработка не гарантируются. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/supported_data_types/upload_data_types/upload_data_types.html",
    "relUrl": "/reference/supported_data_types/upload_data_types/upload_data_types.html"
  },"197": {
    "doc": "Системные представления (INFORMATION_SCHEMA)",
    "title": "Системные представления (INFORMATION_SCHEMA)",
    "content": "Системные представления (INFORMATION_SCHEMA) . Содержание раздела . | Представление schemata | Представление tables | Представление columns | Представление table_constraints | Представление key_column_usage | Взаимосвязь системных представлений | . Набор системных представлений (INFORMATION_SCHEMA) предоставляет доступ к метаданным логической схемы данных и содержит следующие элементы: . | schemata, | tables, | columns, | table_constraints, | key_column_usage. | . Набор системных представлений и их свойств фиксирован и недоступен для изменения. Представление schemata . Системное представление schemata содержит список логических баз данных окружения. По каждой логической базе доступна следующая информация: . | catalog_name — наименование каталога, в который помещена логическая база данных. Значение по умолчанию — public; | schema_name — наименование логической базы данных. | . Представление tables . Системное представление tables содержит список логических таблиц, логических представлений и материализованных представлений окружения. По каждой таблице или представлению доступна следующая информация: . | table_catalog — наименование каталога, в который помещена таблица или представление. Значение по умолчанию — public; | table_schema — наименование логической базы данных, к которой относится таблица или представление; | table_name — наименование таблицы или представления; | table_type — тип сущности. Возможные значения: BASE TABLE — логическая таблица, MATERIALIZED VIEW — материализованное представление, VIEW — логическое представление; | table_datasource_type — список СУБД хранилища, в которых размещены данные таблицы или материализованного представления. Для логических представлений поле остается пустым. | . Представление columns . Системное представление columns содержит список столбцов логических таблиц и представлений окружения. По каждому столбцу доступна следующая информация: . | table_catalog — наименование каталога, в который помещена таблица или представление. Значение по умолчанию — public; | table_schema — наименование логической базы данных, к которой относится таблица или представление; | table_name — наименование таблицы или представления, к которому относится столбец; | column_name — наименование столбца, по которому предоставлена информация; | is_nullable — признак того, может ли значение столбца иметь пустое значение (null). Возможные значения: YES — столбец может содержать пустое значение; NO — столбец должен содержать непустое значение; | ordinal_position — порядковый номер столбца в таблице или представлении (нумерация начинается с 1); | character_maximum_length — максимально допустимое количество символов (для строковых значений); | datetime_precision — степень отображаемой точности значений типа TIMESTAMP. Возможное значение: от 0 (точность до секунд) до 6 (точность до микросекунд). | data_type — тип данных столбца. Возможные значения см. в разделе Логические типы данных. | . Представление table_constraints . Системное представление table_constraints содержит список ограничений логических таблиц и представлений окружения. По каждому ограничению доступна следующая информация: . | constraint_catalog — наименование каталога, в который помещена таблица или представление с ограничением. Значение по умолчанию — public; | constraint_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | constraint_name — наименование ограничения; | table_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | table_name — наименование таблицы или представления, к которому относится ограничение; | constraint_type — тип ограничения. Возможные значения: primary key — первичный ключ, sharding key — ключ шардирования. | . Представление key_column_usage . Системное представление key_column_usage содержит список столбцов окружения, с которыми связаны какие-либо ограничения. По каждому столбцу доступна следующая информация: . | constraint_catalog — наименование каталога, в который помещена таблица или представление с ограничением. Значение по умолчанию — public; | constraint_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | constraint_name — наименование ограничения; | table_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | table_name — наименование таблицы или представления, к которому относится ограничение; | column_name — наименование столбца, на который накладывается ограничение; | ordinal_position — порядковый номер поля в ключе (нумерация начинается с 1). | . Взаимосвязь системных представлений . На рисунке ниже показана взаимосвязь системных представлений. Взаимосвязь системных представлений . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/system_views/system_views.html",
    "relUrl": "/reference/system_views/system_views.html"
  },"198": {
    "doc": "Форматы даты и времени в запросах",
    "title": "Форматы даты и времени в запросах",
    "content": "Форматы даты и времени в запросах . Дату и время в запросах можно указывать в следующих форматах: . | с точностью до секунд: YYYY-MM-DD hh:mm:ss (например, 2021-05-25 18:00:17); | с любой точностью от десятых секунд (S) до микросекунд (SSSSSS): . | YYYY-MM-DD hh:mm:ss.S, | YYYY-MM-DD hh:mm:ss.SS, | YYYY-MM-DD hh:mm:ss.SSS (например, 2021-05-25 18:00:17.876), | YYYY-MM-DD hh:mm:ss.SSSS, | YYYY-MM-DD hh:mm:ss.SSSSS, | YYYY-MM-DD hh:mm:ss.SSSSSS (например, 2021-05-25 18:00:17.876784). | . | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/timestamp_formats/timestamp_formats.html",
    "relUrl": "/reference/timestamp_formats/timestamp_formats.html"
  },"199": {
    "doc": "Формат загрузки данных",
    "title": "Формат загрузки данных",
    "content": "Формат загрузки данных . Содержание раздела . | Структура сообщений | Формат данных | Примеры . | Пример загружаемой схемы данных Avro | Пример загружаемых записей Avro | . | . Структура сообщений . Данные загружаются в систему в виде сообщений топиков Kafka. Каждое сообщение имеет структуру, показанную на рисунке ниже. Структура загружаемых сообщений . Формат данных . Для успешной загрузки данные должны соответствовать следующим условиям: . | Данные представлены в виде сообщений топика Kafka. | Каждое сообщение состоит из ключа и тела. Требования к ключу сообщения не предъявляются. | Тело сообщения представляет собой файл Avro (Object Container File), который состоит из заголовка и блоков данных. | Заголовок файла содержит схему данных Avro. | Схема данных содержит следующие элементы: имя, тип “record” и перечень полей. Для каждого поля указано имя, а также тип данных Avro из перечисленных в разделе Загружаемые типы данных (см. пример ниже). Последним полем схемы указано служебное поле sys_op с типом данных int. | Каждый блок данных содержит запись, представленную в бинарной кодировке. Запись соответствует схеме данных из заголовка файла Avro. | Каждая запись содержит перечень полей и их значений. Имена и порядок перечисления полей, а также типы данных их значений соответствуют схеме данных (см. пример ниже). Последним полем каждой записи указано служебное поле sys_op со значением 0 (если нужно добавить новую запись или обновить соответствующую актуальную запись) или 1 (если нужно удалить соответствующую актуальную запись). | Состав и порядок полей совпадают во всех следующих объектах: . | в схеме данных заголовка файла Avro, | в наборе загружаемых записей, | во внешней таблице загрузки (поле sys_op должно отсутствовать), | в логической таблице, в которую загружаются данные (поле sys_op должно отсутствовать). | . | . В схеме данных можно использовать логические типы Avro, а также элементы unions (см. пример ниже). Типы данных Avro, доступные к загрузке в систему, описаны в разделе Загружаемые типы данных. Подробнее о формате Avro см. в официальной документации на сайте https://avro.apache.org. Примеры . Пример загружаемой схемы данных Avro . Пример ниже содержит схему данных Avro, используемую для загрузки данных о продажах в логическую таблицу sales. Для поля transaction_date указан логический тип Avro, для поля description — элемент union. Для наглядности примера бинарные данные представлены в JSON-формате. { \"name\": \"sales\", \"type\": \"record\", \"fields\": [ { \"name\": \"id\", \"type\": \"long\" }, { \"name\": \"transaction_date\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\" }, { \"name\": \"product_code\", \"type\": \"string\" }, { \"name\": \"product_units\", \"type\": \"long\" }, { \"name\": \"store_id\", \"type\": \"long\" }, { \"name\": \"description\", \"type\": [ \"null\", \"string\" ] }, { \"name\": \"sys_op\", \"type\": \"int\" } ] } . Пример загружаемых записей Avro . Пример ниже содержит набор записей о продажах, загружаемых в логическую таблицу sales. Для наглядности примера бинарные данные представлены в JSON-формате. [ { \"id\": 1000111, \"transaction_date\": 1614269474000000, \"product_code\": \"ABC102101\", \"product_units\": 2, \"store_id\": 1000012345, \"description\": \"Покупка по акции 1+1\", \"sys_op\": 0 }, { \"id\": 1000112, \"transaction_date\": 1614334214000000, \"product_code\": \"ABC102001\", \"product_units\": 1, \"store_id\": 1000000123, \"description\": \"Покупка без акций\", \"sys_op\": 0 }, { \"id\": 1000020, \"transaction_date\": 1614636614000000, \"product_code\": \"ABC102010\", \"product_units\": 4, \"store_id\": 1000000123, \"description\": \"Покупка по акции 1+1\", \"sys_op\": 1 } ] . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/reference/upload_format/upload_format.html",
    "relUrl": "/reference/upload_format/upload_format.html"
  },"200": {
    "doc": "Ресурсы",
    "title": "Ресурсы",
    "content": "Ресурсы . Основные репозитории . | Prostore: Data Lake Engine | Greenplum-Kafka PXF-connector | Kafka-Greenplum connector | Kafka-Clickhouse connector (reader+writer) | Kafka-Tarantool loader (reader+writer+api) | Greenplum-Tarantool PXF-connector | Kafka-Postgres connector | . Репозитории зависимостей . | Avro-библиотека для kafka-adb-os | Lua-Avro-библиотека для kafka-tarantool | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/resources/resources.html",
    "relUrl": "/resources/resources.html"
  },"201": {
    "doc": "Выгрузка данных",
    "title": "Выгрузка данных",
    "content": "Выгрузка данных . Система позволяет выгружать большие объемы данных, а также изменений, выполненных в указанных дельтах. Данные можно выгружать из логических таблиц, логических и материализованных представлений. Под большим объемом данных подразумевается количество записей от нескольких сотен до нескольких миллионов. Для получения небольшого объема данных можно использовать функцию запроса данных. Система определяет СУБД хранилища, оптимальную для выгрузки данных, в зависимости от параметров запроса, месторасположения данных и конфигурации системы. Возможные способы выбора данных к выгрузке см. в секции FOR SYSTEM_TIME раздела SELECT. Данные выгружаются в виде сообщений Kafka, поэтому для их загрузки нужен топик Kafka. Если в брокере сообщений Kafka настроено автоматическое создание топиков, то дополнительные действия не требуются. Иначе топик необходимо создать, если он отсутствует. Подробнее о создании топиков см. в документации Kafka: . | раздел Quick Start, | раздел Adding and removing topics. | . Чтобы выгрузить данные из таблицы или представления во внешнюю информационную систему: . | Создайте внешнюю таблицу выгрузки, если она еще не создана. | Выполните запрос INSERT INTO download_external_table на выгрузку данных в топик. В запросе нужно указать внешнюю таблицу выгрузки, определяющую параметры выгрузки. | Выгрузите данные из топика во внешнюю информационную систему. | . Созданные внешние таблицы выгрузки можно использовать повторно или удалить. Пример . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- создание внешней таблицы для выгрузки из логической таблицы sales CREATE DOWNLOAD EXTERNAL TABLE sales_ext_download ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000; -- запуск выгрузки данных из логической таблицы sales INSERT INTO sales_ext_download SELECT * FROM sales WHERE product_units &gt; 2 FOR SYSTEM_TIME AS OF DELTA_NUM 10; -- создание внешней таблицы для выгрузки из материализованного представления sales_by_stores CREATE DOWNLOAD EXTERNAL TABLE sales_by_stores_ext_download ( store_id INT, product_code VARCHAR(256), product_units INT ) LOCATION 'kafka://$kafka/sales_by_stores_out' FORMAT 'AVRO' CHUNK_SIZE 1000; -- запуск выгрузки данных из материализованного представления sales_by_stores INSERT INTO sales_by_stores_ext_download SELECT * FROM sales_by_stores WHERE product_code IN ('ABC0002', 'ABC0003', 'ABC0004') DATASOURCE_TYPE = 'adqm'; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/data_download/data_download.html",
    "relUrl": "/working_with_system/data_download/data_download.html"
  },"202": {
    "doc": "Запрос данных",
    "title": "Запрос данных",
    "content": "Запрос данных . Система позволяет запрашивать небольшие объемы данных. Возможные способы выбора данных см. в секции FOR SYSTEM_TIME раздела SELECT. Под небольшим объемом данных подразумевается результат, содержащий десятки строк. Для получения большого объема данных следует использовать выгрузку данных. Чтобы запросить данные из логических таблиц, логических представлений или материализованного представления, выполните запрос SELECT. В запросе можно указать СУБД хранилища для исполнения запроса, иначе, если СУБД не указана, система определяет наиболее оптимальную СУБД для запроса. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на чтение данных. Успешный ответ содержит запрошенные данные, неуспешный — исключение. На рисунке ниже показан пример запроса из логической таблицы sales с двумя строками в ответе. Запрос небольшого объема данных . Примеры . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- запрос данных из логической таблицы sales SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC LIMIT 20; -- запрос данных из логического представления stores_by_sold_products SELECT sold.store_id, sold.product_amount FROM stores_by_sold_products AS sold; -- запрос данных из материализованного представления sales_by_stores SELECT * FROM sales_by_stores WHERE store_id IN (1234, 1235, 1236); . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/data_reading/data_reading.html",
    "relUrl": "/working_with_system/data_reading/data_reading.html"
  },"203": {
    "doc": "Маршрутизация запросов к данным",
    "title": "Маршрутизация запросов к данным",
    "content": "Маршрутизация запросов к данным . Содержание раздела . | Определение категории и подкатегории запроса | Стандартный порядок выбора СУБД | Примеры запросов по категориям . | Реляционные запросы | Запросы агрегации и группировки | Запрос чтения по ключу | Запрос неопределенной категории | . | Примеры запросов по подкатегориям . | Запросы для одного узла | Запросы для набора узлов | Запросы для всех узлов | . | Маршрутизация запросов к данным материализованных представлений | . Запросы на чтение и выгрузку данных маршрутизируются следующим образом: . | Если в запросе указано ключевое слово DATASOURCE_TYPE с СУБД хранилища для исполнения запроса, запрос направляется в указанную СУБД. | Иначе: . | Определяются те СУБД хранилища, в которых можно выполнить запрос, — выбираются СУБД, содержащие данные всех запрашиваемых логических сущностей. | Определяется категория и подкатегория запроса (или только категория — в зависимости от конфигурации системы). | Запрос направляется в ту из выбранных СУБД, которая имеет в конфигурации системы самый высокий приоритет для исполнения таких запросов (см. ниже). | . | Если запрос обращается к материализованному представлению, он проходит дополнительные этапы маршрутизации. | . Определение категории и подкатегории запроса . В зависимости от конфигурации системы система выбирает СУБД хранилища для исполнения запроса, учитывая категорию и подкатегорию запроса или только категорию запроса: . | если в конфигурации системы задана секция параметров plugins.category.autoSelect, система использует настройки этой секции и при маршрутизации запроса учитывает как категорию, так и подкатегорию запроса; | иначе, если секция plugins.category.autoSelect не задана, система использует настройки секции plugins.category.mapping и учитывает только категорию запроса, без учета его подкатегории. | . Категории запросов: . | Реляционный запрос (Relational) — запрос с ключевым словом JOIN и (или) подзапросами. | Аналитический запрос (Analytical) — запрос с ключевым словом GROUP BY и агрегатными функциями. | Запрос чтения по ключу (Dictionary) — запрос с условием WHERE на значения первичного ключа. | Другой запрос (Undefined) — запрос, который не соответствует ни одной из предыдущих категорий. | . Подкатегории запросов: . | один узел (ShardOne) — запрос предназначен для одного узла кластера; | набор узлов (ShardSet) — запрос предназначен для определенных узлов кластера (от 1 до всех); | все узлы (ShardAll) — запрос требует исполнения на всех узлах кластера. | . Система определяет категорию запроса следующим образом: проверяет запрос на соответствие первой категории, и, если у него есть признаки этой категории, то система относит запрос к первой категории, иначе система проверяет запрос на соответствие второй категории и т.д. Например, запрос с ключевым словом JOIN соответствует первой категории («Реляционный запрос») независимо от наличия признаков других категорий — агрегации, группировки и чтения по ключу. Подкатегория запроса выбирается похожим образом с той разницей, что в этом случае порядок проверки неважен. Примеры запросов по категориям и подкатегориям и см. ниже. Если при маршрутизации запросов нужно учитывать только категорию запросов, без учета подкатегории, скорректируйте конфигурацию системы: удалите секцию параметров plugins.category.autoSelect и настройте секцию plugins.category.mapping. Стандартный порядок выбора СУБД . По умолчанию для запросов чтения и выгрузки данных действует порядок выбора СУБД хранилища, описанный в таблице ниже. Например, реляционный запрос, предназначенный для одного узла кластера, будет по возможности исполнен в ADB, иначе, если в ADB нет нужных таблиц, — в ADP, и далее в указанном порядке. Такой порядок эффективно использует возможности каждой из СУБД хранилища, однако при необходимости его можно изменить. | Категория запроса | Порядок выбора СУБД для исполнения запроса | . | 1. Реляционный запрос | Один узел: 1. ADB, 2. ADP, 3. ADQM, 4. ADGНабор узлов: 1. ADB, 2. ADP, 3. ADQM, 4. ADGВсе узлы: 1. ADB, 2. ADP, 3. ADQM, 4. ADG | . | 2. Аналитический запрос | Один узел: 1. ADQM, 2. ADB, 3. ADP, 4. ADGНабор узлов: 1. ADQM, 2. ADB, 3. ADP, 4. ADGВсе узлы: 1. ADQM, 2. ADB, 3. ADP, 4. ADG | . | 3. Запрос чтения по ключу | Один узел: 1. ADG, 2. ADB, 3. ADP, 4. ADQMНабор узлов: 1. ADG, 2. ADB, 3. ADP, 4. ADQMВсе узлы: 1. ADG, 2. ADB, 3. ADP, 4. ADQM | . | 4. Другой запрос | Один узел: 1. ADB, 2. ADP, 3. ADQM, 4. ADGНабор узлов: 1. ADB, 2. ADP, 3. ADQM, 4. ADGВсе узлы: 1. ADB, 2. ADP, 3. ADQM, 4. ADG | . Наиболее полный синтаксис запросов доступен в ADB и ADP. ADG и ADQM имеют ограничения на выполнение запросов, вызванные особенностями этих СУБД (см. Поддержка SQL). Примеры запросов по категориям . Реляционные запросы . Реляционный запрос: . SELECT * FROM marketing.sales AS s JOIN marketing.stores AS st ON s.store_id = st.id . Реляционный запрос, который включает агрегацию, группировку и чтение по ключу (st.id): . SELECT st.id, st.category, SUM(s.product_units) AS product_amount FROM marketing.stores AS st JOIN marketing.sales AS s ON st.id = s.store_id WHERE st.id &lt;&gt; 10004 GROUP BY st.id, st.category ORDER BY product_amount DESC . Запросы агрегации и группировки . Запрос агрегации и группировки: . SELECT s.product_code, SUM(s.product_units) AS product_amount FROM marketing.sales AS s GROUP BY s.product_code ORDER BY product_amount ASC . Запрос агрегации и группировки, который включает чтение по ключу (s.id): . SELECT s.product_code, SUM(s.product_units) AS product_amount FROM marketing.sales AS s WHERE s.id &gt; 20000 GROUP BY s.product_code . Запрос чтения по ключу . SELECT * FROM marketing.sales as s WHERE s.id BETWEEN 1001 AND 2000 . Запрос неопределенной категории . SELECT * FROM marketing.sales AS s WHERE s.product_units &gt; 2 . Примеры запросов по подкатегориям . Запросы для одного узла . Запрос к логическим таблицам transactions1 (шардирование по col1) и accounts1 (шардирование по colA): . SELECT * FROM transactions1 t JOIN accounts1 a ON a.colA = t.col1 WHERE t.col1 = 1 . Запрос к логической таблице transactions2 (шардирование col1 и col2): . SELECT * FROM transactions2 t WHERE t.col1 = 1 AND t.col2 = 2 AND amount &gt; 0 . Запросы к логическим таблицам transactions2 (шардирование по col1 и col2) и accounts2 (шардирование по colA и colB): . -- столбцы col1 and colA имеют один тип данных; столбцы col2 and colB также имеют один тип данных -- запрос объединения таблиц SELECT * FROM transactions2 t JOIN accounts a ON a.id = t.account_id WHERE t.col1 = 1 AND t.col2 = 2 AND a.colA = 1 AND t.colB = 2; -- запрос с подзапросом SELECT * FROM transactions2 t WHERE t.account_id IN ( SELECT id FROM accounts2 a WHERE t.col1 = 1 AND t.col2 = 2 AND a.colA = 1 AND a.colB = 2; . Запросы для набора узлов . Запрос к логическим таблицам transactions1 (шардирование по col1) и accounts1 (шардирование по colA): . SELECT * FROM transactions1 WHERE col1 IN ( SELECT id FROM accounts1 WHERE colA = 1 ) . Запрос к логической таблице transactions2 (шардирование по col1 и col2): . SELECT * FROM transactions2 t WHERE (t.col1 = 1 AND t.col2 = 2) OR ((t.col1 = 1 AND t.col2 = 1) AND amount &gt; 0) . Запросы к логическим таблицам transactions2 (шардирование по col1 и col2) и accounts2 (шардирование по colA и colB): . -- столбцы col1 and colA имеют РАЗНЫЕ типы данных; столбцы col2 and colB имеют один тип данных SELECT * FROM transactions2 t JOIN accounts2 a ON a.id = t.account_id WHERE t.col1 = 1 AND t.col2 = 2 AND a.colA = 1 AND t.colB = 2 . Запросы для всех узлов . Запрос к логическим таблицам transactions1 (шардирование по col1) и accounts1 (шардирование по colA): . SELECT * FROM transactions1 t JOIN accounts1 a ON a.id = t.account_id WHERE t.col1 = 1 OR a.colA = 1 . Запрос к логической таблице transactions2 (шардирование по col1 и col2): . SELECT * FROM transactions2 t WHERE (t.col1 = 1 AND t.col2 = 2) OR amount &gt; 0 . Запросы к логическим таблицам transactions2 (шардирование по col1 и col2) и accounts2 (шардирование по colA и colB): . -- столбцы col1 and colA имеют один тип данных; столбцы col2 and colB также имеют один тип данных SELECT * FROM transactions2 t JOIN accounts2 a ON a.id = t.account_id WHERE (t.col1 = 1 AND t.col2 = 2) OR (a.colA = 1 AND t.colB = 2) . Маршрутизация запросов к данным материализованных представлений . Запросы к данным материализованных представлений проходят все этапы маршрутизации, описанные выше, и затем — дополнительные этапы: . | Если для материализованного представления не указано ключевое слово FOR SYSTEM_TIME, запрос направляется в СУБД, где размещены данные этого представления. Из представления выбираются данные, актуальные на момент его последней синхронизации. | Иначе, если ключевое слово FOR SYSTEM_TIME указано, система проверяет, присутствуют ли запрашиваемые данные в материализованном представлении. | Если данные присутствуют в представлении, запрос направляется в СУБД, где размещены данные этого представления. | Иначе запрос направляется к исходным таблицам СУБД-источника, на которых построено представление. | . | . В запросах к материализованным представлениям доступны не все сочетания с ключевым словом FOR SYSTEM_TIME. Подробнее см. в секции Ключевое слово FOR SYSTEM_TIME раздела SELECT. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/data_reading/routing/routing.html",
    "relUrl": "/working_with_system/data_reading/routing/routing.html"
  },"204": {
    "doc": "Обновление данных",
    "title": "Обновление данных",
    "content": "Обновление данных . Система позволяет обновлять небольшие объемы данных, добавляя новые и удаляя устаревшие данные. Обновлять данные можно только в логических таблицах. Обновление данных в логических и материализованных представлениях недоступно. Под небольшим объемом данных подразумеваются десятки записей. Для обновления большого объема данных следует использовать загрузку данных. Обновление данных в ADG не поддерживается. Чтобы обновить данные в логической таблице: . | Создайте логическую таблицу, если она еще не создана. | Выполните запрос BEGIN DELTA на открытие дельты, если она еще не открыта. | Выполните запрос на обновление данных: . | INSERT VALUES, INSERT SELECT или UPSERT VALUES — для добавления новых или изменения актуальных данных; | DELETE — для удаления актуальных данных. | . | Если необходимо, обновите или загрузите другие данные. В открытой дельте можно выполнить произвольное количество запросов на обновление и загрузку данных, а также отменить изменения. При этом не допускается загрузка различных состояний объекта (то есть различных записей с одинаковым первичным ключом) в одной дельте. | Выполните запрос COMMIT DELTA для сохранения изменений и закрытия дельты. | . При успешном выполнении действий состояние данных системы обновляется, как описано в разделе Версионирование данных. Пока дельта не закрыта, изменения по ее операциям записи можно отменить с помощью запроса ROLLBACK DELTA. Примеры . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- открытие новой (горячей) дельты BEGIN DELTA; -- вставка трех записей в логическую таблицу sales INSERT INTO sales VALUES (100011, '2021-08-21 23:34:10', 'ABC0001', 2, 123, 'Покупка по акции \"1+1\"'), (100012, '2021-08-22 10:05:56', 'ABC0001', 1, 234, 'Покупка без акций'), (1000113, '2021-08-22 13:17:47', 'ABC0002', 4, 123, 'Покупка по акции \"Лето\"'); -- удаление записей логической таблицы sales о покупках в магазине, который был закрыт DELETE FROM sales WHERE store_id = 234; -- создание логической таблицы sales_july_2021, которая будет содержать данные о продажах за июль 2021 и размещаться в ADB CREATE TABLE sales_july_2021 ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adb); -- вставка данных из таблицы sales в новую таблицу sales_july_2021 INSERT INTO sales_july_2021 SELECT * FROM sales WHERE CAST(EXTRACT(MONTH FROM transaction_date) AS INT) = 7 AND CAST(EXTRACT(YEAR FROM transaction_date) AS INT) = 2021 DATASOURCE_TYPE = 'adb'; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/data_update/data_update.html",
    "relUrl": "/working_with_system/data_update/data_update.html"
  },"205": {
    "doc": "Загрузка данных",
    "title": "Загрузка данных",
    "content": "Загрузка данных . Система позволяет параллельно загружать большие объемы данных. Данные можно загружать только в логические таблицы. Загрузка данных в логические и материализованные представления недоступна. Под большим объемом данных подразумевается количество записей от нескольких сотен до нескольких миллионов. Для загрузки небольшого объема данных можно использовать функцию обновления данных. Данные загружаются в виде сообщений Kafka, поэтому для их загрузки нужен топик Kafka. Если в брокере сообщений Kafka настроено автоматическое создание топиков, то дополнительные действия не требуются. Иначе топик необходимо создать, если он отсутствует. Подробнее о создании топиков см. в документации Kafka: . | раздел Quick Start, | раздел Adding and removing topics. | . Чтобы загрузить данные из внешней информационной системы в логическую таблицу: . | Загрузите данные из внешней информационной системы в топик Kafka. Данные должны иметь формат, описанный в разделе Формат загрузки данных. | Создайте логическую таблицу, если она еще не создана. | Создайте внешнюю таблицу загрузки, если она еще не создана. | Выполните запрос BEGIN DELTA на открытие дельты, если она еще не открыта. | Выполните запрос INSERT INTO logical_table на загрузку данных из топика в логическую таблицу. В запросе нужно указать внешнюю таблицу загрузки, определяющую параметры загрузки. | Если необходимо, загрузите и (или) обновите другие данные. В открытой дельте можно выполнить произвольное количество запросов на обновление и загрузку данных, а также отменить изменения. При этом не допускается добавление информации о различных состояниях одного объекта (то есть различных записей с одинаковым первичным ключом) в одной дельте. | Выполните запрос COMMIT DELTA для сохранения изменений и закрытия дельты. | . При успешном выполнении действий состояние данных системы обновляется, как описано в разделе Версионирование данных. Пока дельта не закрыта, изменения данных этой дельты можно отменить с помощью запроса ROLLBACK DELTA. Созданные внешние таблицы загрузки можно использовать повторно или удалить. Примеры . -- выбор логической базы данных marketing в качестве базы данных по умолчанию USE marketing; -- создание логической таблицы sales CREATE TABLE sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id); -- создание внешней таблицы загрузки CREATE UPLOAD EXTERNAL TABLE sales_ext_upload ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000; -- открытие новой (горячей) дельты BEGIN DELTA; -- запуск загрузки данных в логическую таблицу sales INSERT INTO sales SELECT * FROM sales_ext_upload; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/data_upload/data_upload.html",
    "relUrl": "/working_with_system/data_upload/data_upload.html"
  },"206": {
    "doc": "Версионирование данных",
    "title": "Версионирование данных",
    "content": "Версионирование данных . Все записи логической таблицы с одинаковым первичным ключом рассматриваются системой как исторические состояния одного объекта. Объект может одновременно иметь множество архивных состояний, а также не более одного актуального и не более одного нового (“горячего”) состояния. Данные, добавленные в систему с помощью функций загрузки и обновления данных, считаются новым состоянием объектов и сохраняются в виде горячих записей. При фиксации изменений система одномоментно обновляет состояние объектов, исключая возможность чтения “грязных” данных. Обновление происходит в следующем порядке: . | По каждой горячей записи: . | Выполняется поиск соответствующей актуальной записи. Записи сопоставляются по значению первичного ключа. | Если актуальная запись найдена, она становится архивной. При этом горячая запись становится актуальной, если содержит признак добавления, или удаляется, если содержит признак удаления. | Если актуальная запись не найдена, горячая запись перемещается в категорию актуальных. | . | В историю изменений данных системы добавляется новая дельта с номером, равным номеру предыдущей зафиксированной дельты + 1. | . Под признаком добавления или удаления записи понимается значение sys_op (0 — добавление, 1 — удаление), если запись была загружена, и тип запроса (INSERT VALUES, INSERT SELECT и UPSERT VALUES — добавление, DELETE — удаление), если запись была обновлена. Пример версионирования данных . Рассмотрим пример версионирования данных для одного объекта логической таблицы stores — набора данных одного магазина. Адрес магазина был ранее изменен со значения ул. Старая, 9 на ул. Новая, 11, это изменение было зафиксировано, и теперь фиксируется изменение категории магазина со значения basic на vip. В этом случае данные магазина обновляются в следующем порядке (см. рисунок ниже): . | В горячей дельте (до фиксации изменений): запись с новой категорией сохраняется в качестве горячей записи. | При закрытии дельты и фиксации изменений: запись с предыдущей категорией становится архивной, а запись с новой категорией — актуальной. Обновление записей происходит одномоментно. | . На рисунке ниже показаны версии записей до закрытия и после закрытия одной дельты. Актуальные версии записей помечены значком пользователя: именно они по умолчанию возвращаются в ответ на запрос внешней системы, если в запросе не указан момент времени, на который запрашиваются данные. Обновление данных магазина . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/data_upload/data_versioning/data_versioning.html",
    "relUrl": "/working_with_system/data_upload/data_versioning/data_versioning.html"
  },"207": {
    "doc": "Изменение логического представления",
    "title": "Изменение логического представления",
    "content": "Изменение логического представления . Чтобы изменить логическое представление в логической БД, выполните запрос ALTER VIEW или CREATE OR REPLACE VIEW (см. CREATE VIEW). При успешном выполнении запроса логическое представление изменит свой вид. Изменение представления недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . Каждое изменение представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Примеры . Создание логического представления . -- выбор marketing как логической базы данных по умолчанию USE marketing; -- создание логического представления CREATE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 10; . Изменение логического представления . ALTER VIEW marketing.stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM marketing.sales GROUP BY store_id ORDER BY product_amount ASC LIMIT 20 . Пересоздание логического представления . CREATE OR REPLACE VIEW marketing.stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM marketing.sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 30 . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/alter_view/alter_view.html",
    "relUrl": "/working_with_system/logical_schema_update/alter_view/alter_view.html"
  },"208": {
    "doc": "Создание логической базы данных",
    "title": "Создание логической базы данных",
    "content": "Создание логической базы данных . Чтобы создать логическую базу данных, выполните запрос CREATE DATABASE (см. примеры ниже). Если логическую базу данных нужно создать только на логическом уровне, без пересоздания связанной физической базы данных в хранилище данных, добавьте в запрос ключевое слово LOGICAL_ONLY. Наличие логической базы данных можно проверить, как описано в разделе Проверка наличия логической базы данных. Для удобства написания последующих запросов к этой логической базе данных можно выбрать ее в качестве используемой по умолчанию. Примеры . Создание логической базы данных . CREATE DATABASE marketing . Создание логической базы данных только на логическом уровне . CREATE DATABASE marketing1 LOGICAL_ONLY . Выбор логической БД по умолчанию . USE marketing . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/create_db/create_db.html",
    "relUrl": "/working_with_system/logical_schema_update/create_db/create_db.html"
  },"209": {
    "doc": "Создание внешней таблицы выгрузки",
    "title": "Создание внешней таблицы выгрузки",
    "content": "Создание внешней таблицы выгрузки . Чтобы создать внешнюю таблицу выгрузки в логической БД, выполните запрос CREATE DOWNLOAD EXTERNAL TABLE. При успешном выполнении запроса внешняя таблица загрузки появляется в логической схеме данных. Для удобства разделения таблиц выгрузки и загрузки рекомендуется задавать имя таблицы, указывающее на ее тип (например, transactions_ext_download или transactions_ext_upload). Внешняя таблица представляет собой декларацию приемника данных и формата выгрузки данных и не хранит сами данные. Наличие внешней таблицы можно проверить, как описано в разделе Проверка наличия внешней таблицы. Пример . -- выбор базы данных marketing по умолчанию USE marketing; -- создание внешней таблицы выгрузки CREATE DOWNLOAD EXTERNAL TABLE marketing.sales_ext_download ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/create_download_table/create_download_table.html",
    "relUrl": "/working_with_system/logical_schema_update/create_download_table/create_download_table.html"
  },"210": {
    "doc": "Создание материализованного представления",
    "title": "Создание материализованного представления",
    "content": "Создание материализованного представления . Чтобы создать материализованное представление в логической базе данных, выполните запрос CREATE MATERIALIZED VIEW. Если нужно создать представление только на логическом уровне, добавьте в запрос ключевое слово LOGICAL_ONLY. Создание материализованных представлений возможно в ADG и ADQM на основе данных ADB. Создание представления недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . Наличие представления можно проверить, как описано в разделе Проверка наличия материализованного представления. Наличие физических таблиц, связанных с материализованным представлением, можно проверить, как описано в разделе Проверка месторасположения логической сущности. Каждое создание представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Примеры . Создание материализованного представления . -- выбор базы данных marketing по умолчанию USE marketing; -- создание материализованного представления sales_and_stores CREATE MATERIALIZED VIEW sales_and_stores ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, description VARCHAR(256), store_id INT NOT NULL, store_category VARCHAR(256) NOT NULL, region VARCHAR(256) NOT NULL, PRIMARY KEY (id, region) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adg, adqm) AS SELECT s.id, s.transaction_date, s.product_code, s.product_units, s.description, st.id AS store_id, st.category as store_category, st.region FROM sales AS s JOIN stores AS st ON s.store_id = st.id DATASOURCE_TYPE = 'adb'; . Создание материализованного представления только на логическом уровне . CREATE MATERIALIZED VIEW marketing.stores_by_sold_products_matview ( store_id INT NOT NULL, product_amount INT NOT NULL, PRIMARY KEY (store_id) ) DISTRIBUTED BY (store_id) DATASOURCE_TYPE (adg) AS SELECT store_id, SUM(product_units) AS product_amount FROM marketing.sales GROUP BY store_id DATASOURCE_TYPE = 'adb' LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/create_materialized_view/create_materialized_view.html",
    "relUrl": "/working_with_system/logical_schema_update/create_materialized_view/create_materialized_view.html"
  },"211": {
    "doc": "Создание логической таблицы",
    "title": "Создание логической таблицы",
    "content": "Создание логической таблицы . Чтобы создать логическую таблицу в логической базе данных, выполните запрос CREATE TABLE. При необходимости добавьте в запрос ключевое слово: . | DATASOURCE_TYPE со списком СУБД хранилища — чтобы разместить данные таблицы только в некоторых СУБД хранилища; | LOGICAL_ONLY — чтобы создать таблицу только на логическом уровне. | . Создание таблицы недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . Наличие логической таблицы можно проверить, как описано в разделе Проверка наличия логической таблицы. Наличие физических таблиц, связанных с логической, можно проверить, как описано в разделе Проверка месторасположения логической сущности. Каждое создание таблицы записывается в журнал. Журнал доступен с помощью запроса GET_CHANGES. Примеры . Создание логической таблицы . -- выбор базы данных marketing по умолчанию USE marketing; -- создание таблицы sales CREATE TABLE sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id); . Создание логической таблицы только на логическом уровне . CREATE TABLE marketing.sales1 ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) LOGICAL_ONLY . Создание логической таблицы с размещением данных в ADQM и ADG . CREATE TABLE marketing.clients ( id INT NOT NULL, first_name VARCHAR(256) NOT NULL, last_name VARCHAR(256) NOT NULL, patronymic_name VARCHAR(256), birth_date DATE, PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adqm,adg) . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/create_table/create_table.html",
    "relUrl": "/working_with_system/logical_schema_update/create_table/create_table.html"
  },"212": {
    "doc": "Создание внешней таблицы загрузки",
    "title": "Создание внешней таблицы загрузки",
    "content": "Создание внешней таблицы загрузки . Чтобы создать внешнюю таблицу загрузки в логической БД, выполните запрос CREATE UPLOAD EXTERNAL TABLE. При успешном выполнении запроса внешняя таблица загрузки появляется в логической схеме данных. Для удобства разделения таблиц загрузки и выгрузки рекомендуется задавать имя таблицы, указывающее на ее тип (например, transactions_ext_upload или transactions_ext_download). Внешняя таблица представляет собой декларацию источника данных и формата загрузки данных и не хранит сами данные. Наличие внешней таблицы можно проверить, как описано в разделе Проверка наличия внешней таблицы. Пример . -- выбор базы данных marketing по умолчанию USE marketing; -- создание внешней таблицы загрузки CREATE UPLOAD EXTERNAL TABLE sales_ext_upload ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/create_upload_table/create_upload_table.html",
    "relUrl": "/working_with_system/logical_schema_update/create_upload_table/create_upload_table.html"
  },"213": {
    "doc": "Создание логического представления",
    "title": "Создание логического представления",
    "content": "Создание логического представления . Чтобы создать логическое представление в логической БД, выполните запрос CREATE VIEW. При успешном выполнении запроса логическое представление появляется в логической схеме данных. Создание представления недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . Наличие представления можно проверить, как описано в разделе Проверка наличия логического представления. Каждое создание представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Пример . -- выбор базы данных marketing по умолчанию USE marketing; -- создание представления stores_by_sold_products CREATE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 30; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/create_view/create_view.html",
    "relUrl": "/working_with_system/logical_schema_update/create_view/create_view.html"
  },"214": {
    "doc": "Удаление логической базы данных",
    "title": "Удаление логической базы данных",
    "content": "Удаление логической базы данных . Чтобы удалить логическую базу данных и ее данные, выполните запрос DROP DATABASE (см. примеры ниже). Если нужно удалить логическую базу данных только на логическом уровне, без удаления связанной физической базы данных и размещенных в ней данных из хранилища, добавьте в запрос ключевое слово LOGICAL_ONLY. Наличие логической базы данных можно проверить, как описано в разделе Проверка наличия логической базы данных. Примеры . Удаление логической базы данных . DROP DATABASE marketing . Удаление логической базы данных только на логическом уровне . DROP DATABASE marketing1 LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/drop_db/drop_db.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_db/drop_db.html"
  },"215": {
    "doc": "Удаление внешней таблицы выгрузки",
    "title": "Удаление внешней таблицы выгрузки",
    "content": "Удаление внешней таблицы выгрузки . Чтобы удалить внешнюю таблицу выгрузки, выполните запрос DROP DOWNLOAD EXTERNAL TABLE. При успешном выполнении запроса внешняя таблица выгрузки удаляется из логической схемы данных. Наличие внешней таблицы можно проверить, как описано в разделе Проверка наличия внешней таблицы. Пример . -- выбор базы данных marketing по умолчанию USE marketing; -- удаление внешней таблицы выгрузки DROP DOWNLOAD EXTERNAL TABLE sales_ext_download; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/drop_download_table/drop_download_table.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_download_table/drop_download_table.html"
  },"216": {
    "doc": "Удаление материализованного представления",
    "title": "Удаление материализованного представления",
    "content": "Удаление материализованного представления . Чтобы удалить материализованное представление и его данные, выполните запрос DROP MATERIALIZED VIEW. При необходимости добавьте в запрос ключевое слово: . | DATASOURCE_TYPE со списком СУБД хранилища — чтобы указать, из каких СУБД нужно удалить данные представления; | LOGICAL_ONLY — чтобы удалить представление только на логическом уровне. | . Удаление представления недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . Наличие представления можно проверить, как описано в разделе Проверка наличия материализованного представления. Наличие физических таблиц, связанных с материализованным представлением, можно проверить, как описано в разделе Проверка месторасположения логической сущности. Каждое удаление представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Примеры . Удаление материализованного представления из одной СУБД . -- выбор базы данных marketing по умолчанию USE marketing; -- удаление представления sales_and_stores DROP MATERIALIZED VIEW sales_and_stores DATASOURCE_TYPE = 'adg'; . Удаление материализованного представления из всех СУБД . DROP MATERIALIZED VIEW marketing.sales_and_stores . Удаление материализованного представления только на логическом уровне . DROP MATERIALIZED VIEW marketing.stores_by_sold_products_matview LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/drop_materialized_view/drop_materialized_view.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_materialized_view/drop_materialized_view.html"
  },"217": {
    "doc": "Удаление логической таблицы",
    "title": "Удаление логической таблицы",
    "content": "Удаление логической таблицы . Чтобы удалить логическую таблицу и ее данные, выполните запрос DROP TABLE. При необходимости добавьте в запрос ключевое слово: . | DATASOURCE_TYPE со списком СУБД хранилища — чтобы удалить данные таблицы только из некоторых СУБД хранилища; | LOGICAL_ONLY — чтобы удалить таблицу только на логическом уровне. | . Удаление таблицы недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . Наличие логической таблицы можно проверить, как описано в разделе Проверка наличия логической таблицы. Наличие физических таблиц, связанных с логической, можно проверить, как описано в разделе Проверка месторасположения логической сущности. Каждое удаление таблицы записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Примеры . Удаление логической таблицы из одной СУБД . -- выбор базы данных marketing по умолчанию USE marketing; -- удаление таблицы sales из СУБД ADQM DROP TABLE sales DATASOURCE_TYPE = 'adqm'; . Удаление логической таблицы из всех СУБД . DROP TABLE marketing.sales . Удаление логической таблицы только на логическом уровне . DROP TABLE marketing.sales1 LOGICAL_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/drop_table/drop_table.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_table/drop_table.html"
  },"218": {
    "doc": "Удаление внешней таблицы загрузки",
    "title": "Удаление внешней таблицы загрузки",
    "content": "Удаление внешней таблицы загрузки . Чтобы удалить внешнюю таблицу загрузки, выполните запрос DROP UPLOAD EXTERNAL TABLE. При успешном выполнении запроса внешняя таблица удаляется из логической схемы данных. Наличие внешней таблицы можно проверить, как описано в разделе Проверка наличия внешней таблицы. Пример . -- выбор базы данных marketing по умолчанию USE marketing; -- удаление внешней таблицы загрузки DROP UPLOAD EXTERNAL TABLE sales_ext_upload; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/drop_upload_table/drop_upload_table.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_upload_table/drop_upload_table.html"
  },"219": {
    "doc": "Удаление логического представления",
    "title": "Удаление логического представления",
    "content": "Удаление логического представления . Чтобы удалить логическое представление из логической БД, выполните запрос DROP VIEW. При успешном выполнении запроса логическое представление удаляется из логической схемы данных. Удаление логического представления никак не отражается в хранилище. Удаление представления недоступно при наличии любого из факторов: . | горячей дельты, | незавершенного запроса на создание, удаление или изменение таблицы или представления, | запрета на изменение сущностей (см. раздел DENY_CHANGES). | . Наличие представления можно проверить, как описано в разделе Проверка наличия логического представления. Каждое удаление представления записывается в журнал. Журнал можно посмотреть с помощью запроса GET_CHANGES. Пример . -- выбор базы данных marketing по умолчанию USE marketing; -- удаление представления stores_by_sold_products DROP VIEW stores_by_sold_products; . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/drop_view/drop_view.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_view/drop_view.html"
  },"220": {
    "doc": "Проверка наличия логической сущности",
    "title": "Проверка наличия логической сущности",
    "content": "Проверка наличия логической сущности . Содержание раздела . | Проверка наличия логической базы данных | Проверка наличия логической таблицы | Проверка наличия логического представления | Проверка наличия материализованного представления | Проверка наличия внешней таблицы | . При успешном создании любой логической сущности — логической базы данных, логической таблицы, логического представления, внешней таблицы загрузки, внешней таблицы выгрузки или материализованного представления — система возвращает в ответе пустой объект ResultSet. Если сущность не удалось создать, система возвращает исключение. Таким образом, по ответу на запрос можно определить, создалась ли логическая сущность, но при необходимости можно проверить наличие сущности, как описано в этом разделе. Наличие логической сущности можно проверить любым из способов: . | запросить метаданные из соответствующего системного представления (способ недоступен для внешних таблиц); | выполнить SELECT-запрос к проверяемой логической сущности (способ недоступен для логической БД и внешних таблиц); | проверить дерево объектов в SQL-клиенте. | . Примеры запросов для каждого типа сущности доступны в секциях ниже: . | Проверка наличия логической базы данных; | Проверка наличия логической таблицы; | Проверка наличия логического представления; | Проверка наличия материализованного представления; | Проверка наличия внешней таблицы. | . Наличие внешних таблиц загрузки и выгрузки можно проверить только в дереве объектов SQL-клиента. Внешние таблицы не отображаются в системных представлениях, и для них недоступны SELECT-запросы. Проверка наличия логической базы данных . Чтобы проверить наличие логической базы данных, используйте любой из способов: . | Выполните запрос к системному представлению schemata (вместо DB_NAME подставьте имя логической БД в верхнем регистре): SELECT CASE WHEN count(*) &gt; 0 THEN 'БД существует' ELSE 'БД не существует' END FROM INFORMATION_SCHEMA.schemata WHERE schema_name = '&lt;DB_NAME&gt;' . Если логическая база данных существует, в ответе возвращается строка «БД существует», иначе — строка «БД не существует». | Проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). Если логическая база данных существует, она присутствует среди объектов в SQL-клиенте, иначе — отсутствует среди объектов. | . На рисунке ниже показана логическая БД в дереве объектов SQL-клиента. Логическая БД в дереве объектов . Проверка наличия логической таблицы . Чтобы проверить наличие логической таблицы, используйте любой из способов: . | Выполните запрос к системному представлению tables (вместо DB_NAME и TABLE_NAME подставьте имя логической БД и имя таблицы в верхнем регистре): SELECT CASE WHEN count(*) &gt; 0 THEN 'таблица существует' ELSE 'таблица не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND (table_name = '&lt;TABLE_NAME&gt;' AND table_type = 'BASE TABLE') . Если логическая таблица существует, в ответе возвращается строка «таблица существует», иначе — строка «таблица не существует». | Выполните SELECT-запрос к логической таблице, например: SELECT * FROM &lt;db_name&gt;.&lt;table_name&gt; LIMIT 5 . Если логическая таблица существует, запрос возвращает от ноля до пяти записей (в зависимости от содержимого таблицы), иначе — исключение Entity &lt;table_name&gt; does not exist. | Проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). Если логическая таблица существует, она присутствует среди объектов логической БД в SQL-клиенте, иначе — отсутствует среди таких объектов. Логические таблицы в дереве объектов . | . Проверка наличия логического представления . Чтобы проверить наличие логического представления, используйте любой из способов: . | Выполните запрос к системному представлению tables (вместо DB_NAME и VIEW_NAME подставьте имя логической БД и имя логического представления в верхнем регистре): SELECT CASE WHEN count(*) &gt; 0 THEN 'представление существует' ELSE 'представление не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND (table_name = '&lt;VIEW_NAME&gt;' AND table_type = 'VIEW') . Если логическое представление существует, в ответе возвращается строка «представление существует», иначе — строка «представление не существует». | Выполните SELECT-запрос к логическому представлению, например: SELECT * FROM &lt;db_name&gt;.&lt;view_name&gt; LIMIT 5 . Если логическое представление существует, запрос возвращает от ноля до пяти записей, иначе — исключение Entity &lt;view_name&gt; does not exist. | Проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). Если логическое представление, оно присутствует среди объектов логической БД в SQL-клиенте, иначе — отсутствует среди объектов логической БД. Логическое представление в дереве объектов . | . Проверка наличия материализованного представления . Чтобы проверить наличие материализованного представления, используйте любой из способов: . | Выполните запрос к системному представлению tables (вместо DB_NAME и MATERIALIZED_VIEW_NAME подставьте имя логической БД и имя представления в верхнем регистре): SELECT CASE WHEN count(*) &gt; 1 THEN 'представление существует' ELSE 'представление не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND (table_name = '&lt;MATERIALIZED_VIEW_NAME&gt;' AND table_type = 'MATERIALIZED VIEW') . Если материализованное представление существует, в ответе возвращается строка «представление существует», иначе — строка «представление не существует». | Выполните SELECT-запрос к материализованному представлению, например: SELECT * FROM &lt;db_name&gt;.&lt;materialized_view_name&gt; LIMIT 5 . Если материализованное представление существует, запрос возвращает от ноля до пяти записей, иначе — исключение Entity &lt;materialized_view_name&gt; does not exist. | Проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). Если материализованное представление существует, оно присутствует среди объектов логической БД в SQL-клиенте, иначе — отсутствует среди объектов логической БД. Материализованное представление в дереве объектов . | . Проверка наличия внешней таблицы . Чтобы проверить наличие внешней таблицы загрузки или выгрузки, проверьте дерево объектов в вашем SQL-клиенте (см. рисунки ниже). Если внешняя таблица существует, она присутствует среди объектов логической БД в SQL-клиенте, иначе — отсутствует среди объектов логической БД. На рисунках ниже показаны фрагменты дерева объектов SQL-клиента: с внешней таблицей загрузки sales_ext_upload и внешней таблицей выгрузки sales_ext_download соответственно. Внешняя таблица загрузки в дереве объектов . Внешняя таблица выгрузки в дереве объектов . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/entity_presence_check/entity_presence_check.html",
    "relUrl": "/working_with_system/logical_schema_update/entity_presence_check/entity_presence_check.html"
  },"221": {
    "doc": "Управление схемой данных",
    "title": "Управление схемой данных",
    "content": "Управление схемой данных . Система позволяет организовать структуру данных с помощью логической схемы данных. Доступны следующие действия по управлению логической схемой данных: . | Создание логической базы данных | Удаление логической базы данных | Создание логической таблицы | Удаление логической таблицы | Создание логического представления | Изменение логического представления | Удаление логического представления | Создание материализованного представления | Удаление материализованного представления | Создание внешней таблицы загрузки | Удаление внешней таблицы загрузки | Создание внешней таблицы выгрузки | Удаление внешней таблицы выгрузки | Проверка наличия логической сущности | Запрос метаданных логической схемы | . Запросы на обновление логической схемы данных обрабатываются в порядке, описанном в разделе Порядок обработки запросов на обновление логической схемы. ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/logical_schema_update.html",
    "relUrl": "/working_with_system/logical_schema_update/logical_schema_update.html"
  },"222": {
    "doc": "Запрос метаданных логической схемы",
    "title": "Запрос метаданных логической схемы",
    "content": "Запрос метаданных логической схемы . Чтобы запросить метаданные объектов логической схемы данных, выполните запрос SELECT FROM INFORMATION_SCHEMA. Доступно получение информации о сущностях и их свойствах, перечисленных в разделе Системные представления (INFORMATION_SCHEMA). Примеры . Запрос списка логических БД окружения . SELECT schema_name FROM INFORMATION_SCHEMA.schemata ORDER BY schema_name . Запрос списка сущностей в логической БД . SELECT * FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'MARKETING' . Запрос списка столбцов сущностей в логической БД . SELECT TC.table_schema, TC.table_name, TT.table_type, TC.column_name FROM information_schema.columns AS TC JOIN information_schema.tables AS TT ON TC.table_schema = TT.table_schema and TC.table_name = TT.table_name WHERE TT.table_schema = 'MARKETING' ORDER BY TC.table_schema, TC.table_name . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/logical_schema_update/request_from_schema/request_from_schema.html",
    "relUrl": "/working_with_system/logical_schema_update/request_from_schema/request_from_schema.html"
  },"223": {
    "doc": "Проверка месторасположения логической сущности",
    "title": "Проверка месторасположения логической сущности",
    "content": "Проверка месторасположения логической сущности . Чтобы проверить, в каких СУБД хранилища размещены данные логической таблицы или материализованного представления, выполните запрос к системному представлению tables (вместо DB_NAME и ENTITY_NAME подставьте имя логической базы данных и имя таблицы или представления в верхнем регистре): . | запрос для логической таблицы: SELECT * FROM information_schema.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND (table_name = '&lt;ENTITY_NAME&gt;' AND table_type = 'BASE TABLE') . | запрос для материализованного представления: SELECT * FROM information_schema.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND (table_name = '&lt;ENTITY_NAME&gt;' AND table_type = 'MATERIALIZED VIEW') . | . В ответе система возвращает информацию о запрошенной логической сущности, где столбец table_datasource_type содержит список СУБД хранилища, в которых размещены данные логической сущности. На рисунке ниже показан фрагмент ответа на запрос по всем логическим сущностям логической БД marketing. Системное представление tables . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/other_features/datasource_check/datasource_check.html",
    "relUrl": "/working_with_system/other_features/datasource_check/datasource_check.html"
  },"224": {
    "doc": "Определение логической БД по умолчанию",
    "title": "Определение логической БД по умолчанию",
    "content": "Определение логической БД по умолчанию . Логическую базу данных можно определить как используемую по умолчанию. Если логическая база данных по умолчанию определена, система использует ее имя всякий раз, когда в запросах явно не указана логическая БД. Логическую базу данных по умолчанию необходимо определить перед выполнением запросов, предназначенных для управления дельтой и получения информации о ней. Это действие также можно выполнить перед другими запросами, что позволит не указывать имя логической БД перед именами логических сущностей в запросах к одной и той же логической базе данных. Чтобы определить логическую базу данных по умолчанию, используйте любой из способов: . | Укажите логическую базу данных в настройках JDBC-подключения к системе (см. рисунок ниже). Логическая база данных указывается последним параметром адресной строки (например, jdbc:prostore://10.92.3.3:9092/marketing, где marketing — имя логической базы данных). Логическая база, указанная таким образом, используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или изменение настроек JDBC-подключения. | Выполните запрос USE. Логическая база, указанная таким образом, используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или закрытие соединения с системой. | . На рисунке ниже показан пример настройки параметров JDBC-подключения в SQL-клиенте, где логическая БД marketing указана как используемая по умолчанию. Параметры JDBC-драйвера с указанной логической БД по умолчанию . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/other_features/default_db_set-up/default_db_set-up.html",
    "relUrl": "/working_with_system/other_features/default_db_set-up/default_db_set-up.html"
  },"225": {
    "doc": "Другие действия",
    "title": "Другие действия",
    "content": "Другие действия . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/other_features/other_features.html",
    "relUrl": "/working_with_system/other_features/other_features.html"
  },"226": {
    "doc": "Получение информации о SELECT-запросе",
    "title": "Получение информации о SELECT-запросе",
    "content": "Получение информации о SELECT-запросе . По SELECT-запросу можно получить информацию о его выполнении без фактического выполнения в СУБД хранилища. Доступна следующая информация: . | имя СУБД хранилища, в которой предполагается выполнение запроса; | план выполнения запроса (только для ADB и ADP); | обогащенный запрос, подготовленный системой на основе исходного запроса с учетом специфики СУБД хранилища. | . Чтобы получить информацию о SELECT-запросе, выполните его с ключевым словом ESTIMATE_ONLY (см. пример ниже). Подробнее о формате и содержимом ответа см. в секции Ключевое слово ESTIMATE_ONLY раздела SELECT, о возможных ключевых словах SELECT-запроса — в секции Поддерживаемые ключевые слова того же раздела. Пример . SELECT s.store_id, SUM(s.product_units) AS product_amount FROM marketing.sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC ESTIMATE_ONLY . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/other_features/query_estimation/query_estimation.html",
    "relUrl": "/working_with_system/other_features/query_estimation/query_estimation.html"
  },"227": {
    "doc": "Разбор ошибок загрузки и обновления данных",
    "title": "Разбор ошибок загрузки и обновления данных",
    "content": "Разбор ошибок загрузки и обновления данных . В случае возникновения ошибок во время загрузки или обновления данных система отменяет операции записи (далее — операции), которые не удалось успешно завершить, и возвращает данные в состояние, предшествовавшее загрузке или обновлению. Основные причины ошибок см. в секции ниже. При необходимости используйте запросы для управления процессами загрузки и обновления данных: . | GET_WRITE_OPERATIONS — возвращает информацию об операциях горячей дельты, находящихся в статусах «Выполняется» и «Отменяется»; | RESUME_WRITE_OPERATION — возобновляет обработку операций горячей дельты, находящихся в статусах «Выполняется» и «Отменяется»; | ROLLBACK CRASHED_WRITE_OPERATIONS — возобновляет обработку операций горячей дельты, находящихся в статусе «Отменяется»; | ROLLBACK DELTA — отменяет операции горячей дельты. | . Основные причины ошибок загрузки и обновления данных . Основные причины ошибок загрузки данных: . | некорректная схема или записи Avro в сообщениях топика Kafka; | несоответствие порядка, количества или типа полей между сообщениями Kafka, логической таблицей или внешней таблицей загрузки (кроме поля sys_op, которое должно присутствовать в сообщениях, но должно отсутствовать в таблицах); | некорректный путь к топику Kafka в настройках внешней таблицы загрузки; | недостаточная продолжительность одного или нескольких интервалов ожидания, заданных в конфигурации системы и используемых при работе с брокером сообщений Kafka; | некорректные настройки сервиса мониторинга статусов Kafka в конфигурации системы; | расхождения времени между серверами инсталляции; | некорректная установка коннектора, предназначенного для загрузки данных. | . Интервалы ожидания при работе с брокером сообщений Kafka настраиваются с помощью параметров конфигурации EDML_FIRST_OFFSET_TIMEOUT_MS и EDML_CHANGE_OFFSET_TIMEOUT_MS, а также параметра ADB_MPPW_FDW_TIMEOUT_MS, который используется только для ADB. Основные причины ошибок обновления данных: . | несоответствие порядка, количества или типов столбцов между логической таблицей-приемником данных и запросом на обновление данных; | отсутствие в запросе INSERT VALUES, INSERT SELECT или UPSERT VALUES значений обязательных столбцов логической таблицы; | указание в запросе INSERT SELECT тех СУБД хранилища, для которых недоступна вставка данных. | . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/other_features/troubleshooting/troubleshooting.html",
    "relUrl": "/working_with_system/other_features/troubleshooting/troubleshooting.html"
  },"228": {
    "doc": "Работа с системой",
    "title": "Работа с системой",
    "content": "Работа с системой . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/working_with_system/working_with_system.html",
    "relUrl": "/working_with_system/working_with_system.html"
  },"229": {
    "doc": "Temporary folder for processing SVG-files",
    "title": "Temporary folder for processing SVG-files",
    "content": "Temporary folder for processing SVG-files . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/TMP/DRAWIO/",
    "relUrl": "/TMP/DRAWIO/"
  },"230": {
    "doc": "Temporary folder for processing XML-files",
    "title": "Temporary folder for processing XML-files",
    "content": "Temporary folder for processing XML-files . ",
    "url": "https://datamarts.github.io/docs_prostore_archive/v5-4/TMP/SVG/",
    "relUrl": "/TMP/SVG/"
  }
}
