{"0": {
    "doc": "docs_prostore",
    "title": "docs_prostore",
    "content": "Prostore user guide . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/README.html",
    "relUrl": "/README.html"
  },"1": {
    "doc": "Сборка и развёртывание",
    "title": "Сборка и развёртывание",
    "content": "Содержание раздела . | Предустановленные программные средства | Сборка Prostore | Настройка СУБД Postgres | Сборка и установка коннектора Kafka-Postgres | Запуск сервисов Apache Zookeeper и Apache Kafka | Запуск коннектора Kafka-Postgres | Запуск службы dtm-status-monitor | Запуск Prostore | Подключение к Prostore с помощью SQL-клиента | Демонстрационный сценарий . | Создание необходимых логических сущностей | Создание топика Kafka для последующей загрузки данных | Создание бинарного avro-файла kafka_upload_sales.avro из avro-схемы и данных | Загрузка avro-файла kafka_upload_sales.avro | Загрузка данных | Вставка данных | Выборка данных | Выгрузка в топик Kafka | Удаление логических сущностей | . | . В данном разделе описаны шаги по развёртыванию среды в конфигурации, предполагающей единственное хранилище - СУБД PostgreSQL. Дополнительная информация приведена в разделе Схемы развёртывания. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html",
    "relUrl": "/getting_started/getting_started.html"
  },"2": {
    "doc": "Сборка и развёртывание",
    "title": "Предустановленные программные средства",
    "content": ". | OC Centos 7; | yum-utils; | curl; | git; | wget; | OpenJDK 8; | Apache Maven 3.6.3; | СУБД PostgreSQL 13; | Apache Zookeeper; | Apache Kafka (например, в каталоге /opt/kafka); | Apache Avro (например, в каталоге /opt/avro); | SQL-клиент, например DBeaver; | docker; | Браузер топиков Kafka с возможностью загрузки бинарных данных, например kafkacat. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#preinstalled_software",
    "relUrl": "/getting_started/getting_started.html#preinstalled_software"
  },"3": {
    "doc": "Сборка и развёртывание",
    "title": "Сборка Prostore",
    "content": "# клонирование репозитория Prostore git clone https://github.com/arenadata/prostore ~/ # запуск сборки Prostore средствами Apache Maven cd ~/prostore mvn clean install -DskipTests=true # создание символической ссылки на файл конфигурации sudo ln -s ~/prostore/dtm-query-execution-core/config/application.yml ~/prostore/dtm-query-execution-core/target/application.yml # приведение конфигурационного файла к виду, показанному ниже sudo nano ~/prostore/dtm-query-execution-core/config/application.yml . конфигурационный файл Prostore `application.yml` # # Copyright © 2021 ProStore # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # logging: level: io.arenadata.dtm.query.execution: ${DTM_LOGGING_LEVEL:TRACE} server: port: ${DTM_METRICS_PORT:8080} management: endpoints: enabled-by-default: ${DTM_METRICS_ENABLED:true} web: exposure: include: ${DTM_METRICS_SCOPE:info, health, requests} core: plugins: active: ${CORE_PLUGINS_ACTIVE:ADP} category: mapping: RELATIONAL: ${DTM_CORE_PLUGINS_RELATIONAL:ADP} ANALYTICAL: ${DTM_CORE_PLUGINS_ANALYTICAL:ADP} DICTIONARY: ${DTM_CORE_PLUGINS_DICTIONARY:ADP} UNDEFINED: ${DTM_CORE_PLUGINS_UNDEFINED:ADP} http: port: ${DTM_CORE_HTTP_PORT:9090} tcpNoDelay: ${DTM_CORE_HTTP_TCP_NO_DELAY:true} tcpFastOpen: ${DTM_CORE_HTTP_TCP_FAST_OPEN:true} tcpQuickAck: ${DTM_CORE_HTTP_TCP_QUICK_ACK:true} env: name: ${DTM_NAME:test} matviewsync: periodMs: ${MATERIALIZED_VIEWS_SYNC_PERIOD_MS:5000} retryCount: ${MATERIALIZED_VIEWS_RETRY_COUNT:10} maxConcurrent: ${MATERIALIZED_VIEWS_CONCURRENT:2} metrics: enabled: ${DTM_CORE_METRICS_ENABLED:true} datasource: edml: sourceType: ${EDML_DATASOURCE:ADP} defaultChunkSize: ${EDML_DEFAULT_CHUNK_SIZE:1000} pluginStatusCheckPeriodMs: ${EDML_STATUS_CHECK_PERIOD_MS:1000} firstOffsetTimeoutMs: ${EDML_FIRST_OFFSET_TIMEOUT_MS:15000} changeOffsetTimeoutMs: ${EDML_CHANGE_OFFSET_TIMEOUT_MS:10000} zookeeper: connection-string: ${ZOOKEEPER_DS_ADDRESS:localhost} connection-timeout-ms: ${ZOOKEEPER_DS_CONNECTION_TIMEOUT_MS:30000} session-timeout-ms: ${ZOOKEEPER_DS_SESSION_TIMEOUT_MS:86400000} chroot: ${ZOOKEEPER_DS_CHROOT:/adtm} kafka: producer: property: key.serializer: org.apache.kafka.common.serialization.StringSerializer value.serializer: org.apache.kafka.common.serialization.StringSerializer cluster: zookeeper: connection-string: ${ZOOKEEPER_KAFKA_ADDRESS:localhost} connection-timeout-ms: ${ZOOKEEPER_KAFKA_CONNECTION_TIMEOUT_MS:30000} session-timeout-ms: ${ZOOKEEPER_KAFKA_SESSION_TIMEOUT_MS:86400000} chroot: ${ZOOKEEPER_KAFKA_CHROOT:} admin: inputStreamTimeoutMs: ${KAFKA_INPUT_STREAM_TIMEOUT_MS:2000} status.event.publish: enabled: ${KAFKA_STATUS_EVENT_ENABLED:false} statusMonitor: statusUrl: ${STATUS_MONITOR_URL:http://localhost:9095/status} versionUrl: ${STATUS_MONITOR_VERSION_URL:http://localhost:9095/versions} vertx: blocking-stacktrace-time: ${DTM_VERTX_BLOCKING_STACKTRACE_TIME:1} pool: worker-pool: ${DTM_CORE_WORKER_POOL_SIZE:20} event-loop-pool: ${DTM_CORE_EVENT_LOOP_POOL_SIZE:20} task-pool: ${DTM_CORE_TASK_POOL_SIZE:20} task-timeout: ${DTM_CORE_TASK_TIMEOUT:86400000} cache: initialCapacity: ${CACHE_INITIAL_CAPACITY:100000} maximumSize: ${CACHE_MAXIMUM_SIZE:100000} expireAfterAccessMinutes: ${CACHE_EXPIRE_AFTER_ACCESS_MINUTES:99960} delta: rollback-status-calls-ms: ${DELTA_ROLLBACK_STATUS_CALLS_MS:2000} adp: datasource: user: ${ADP_USERNAME:dtm} password: ${ADP_PASS:dtm} host: ${ADP_HOST:localhost} port: ${ADP_PORT:5432} poolSize: ${ADP_MAX_POOL_SIZE:3} executorsCount: ${ADP_EXECUTORS_COUNT:3} fetchSize: ${ADP_FETCH_SIZE:1000} preparedStatementsCacheMaxSize: ${ADP_PREPARED_CACHE_MAX_SIZE:256} preparedStatementsCacheSqlLimit: ${ADP_PREPARED_CACHE_SQL_LIMIT:2048} preparedStatementsCache: ${ADP_PREPARED_CACHE:true} mppw: restStartLoadUrl: ${ADP_REST_START_LOAD_URL:http://localhost:8096/newdata/start} restStopLoadUrl: ${ADP_REST_STOP_LOAD_URL:http://localhost:8096/newdata/stop} restVersionUrl: ${ADP_MPPW_CONNECTOR_VERSION_URL:http://localhost:8096/versions} kafkaConsumerGroup: ${ADP_KAFKA_CONSUMER_GROUP:adp-load} mppr: restLoadUrl: ${ADP_MPPR_QUERY_URL:http://localhost:8094/query} restVersionUrl: ${ADP_MPPR_CONNECTOR_VERSION_URL:http://localhost:8094/versions} . Далее конфигурационный файл application.yml обозначается термином “конфигурация Prostore”. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#prostore_build",
    "relUrl": "/getting_started/getting_started.html#prostore_build"
  },"4": {
    "doc": "Сборка и развёртывание",
    "title": "Настройка СУБД Postgres",
    "content": "# создание в СУБД Postgres SUPERUSER-пользователя c именем и паролем, # указанными в конфигурации Prostore # (значения параметров (adp:datasource:user) и (adp:datasource:password) соответственно) cd / sudo -u postgres psql -c 'CREATE ROLE dtm WITH LOGIN SUPERUSER' sudo -u postgres psql -c \"ALTER ROLE dtm WITH PASSWORD 'dtm'\" # создание базы данных с именем test, указанным в конфигурации Prostore (env: name) sudo -u postgres psql -c 'CREATE DATABASE test' # перезапуск сервиса Postgresql sudo systemctl reload postgresql-13 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#postgres_setup",
    "relUrl": "/getting_started/getting_started.html#postgres_setup"
  },"5": {
    "doc": "Сборка и развёртывание",
    "title": "Сборка и установка коннектора Kafka-Postgres",
    "content": "# клонирование репозитория kafka-postgres-connector git clone https://github.com/arenadata/kafka-postgres-connector ~/ # запуск сборки коннектора kafka-postgres средствами Apache Maven cd ~/kafka-postgres-connector mvn clean install -DskipTests=true # приведение конфигурационных файлов kafka-postgres-writer и kafka-postgres-reader к виду, # показанному ниже, чтобы значения параметров совпадали со значениями соответствующих параметров конфигурации Prostore # datasource: postgres: database ~ env: name, # datasource: postgres: user ~ adp: datasource: user, # datasource: postgres: password ~ adp: datasource: password, # datasource: postgres: hosts ~ adp: datasource: host, adp: datasource: port sudo nano ~/kafka-postgres-connector/kafka-postgres-writer/src/main/resources/application.yml sudo nano ~/kafka-postgres-connector/kafka-postgres-reader/src/main/resources/application.yml # создание символических ссылок на файлы конфигурации sudo ln -s ~/kafka-postgres-connector/kafka-postrges-writer/src/main/resources/application.yml ~/kafka-postgres-connector/kafka-postrges-writer/target/application.yml sudo ln -s ~/kafka-postgres-connector/kafka-postrges-reader/src/main/resources/application.yml ~/kafka-postgres-connector/kafka-postrges-reader/target/application.yml . конфигурационный файл kafka-postgres-writer `application.yml` logging: level: io.arenadata.kafka: ${LOG_LEVEL:DEBUG} org.apache.kafka: ${KAFKA_LOG_LEVEL:INFO} http: port: ${SERVER_PORT:8096} vertx: pools: eventLoopPoolSize: ${VERTX_EVENT_LOOP_SIZE:12} workersPoolSize: ${VERTX_WORKERS_POOL_SIZE:32} verticle: query: instances: ${QUERY_VERTICLE_INSTANCES:12} insert: poolSize: ${INSERT_WORKER_POOL_SIZE:32} insertPeriodMs: ${INSERT_PERIOD_MS:1000} batchSize: ${INSERT_BATCH_SIZE:500} consumer: poolSize: ${KAFKA_CONSUMER_WORKER_POOL_SIZE:32} maxFetchSize: ${KAFKA_CONSUMER_MAX_FETCH_SIZE:10000} commit: poolSize: ${KAFKA_COMMIT_WORKER_POOL_SIZE:1} commitPeriodMs: ${KAFKA_COMMIT_WORKER_COMMIT_PERIOD_MS:1000} client: kafka: consumer: checkingTimeoutMs: ${KAFKA_CHECKING_TIMEOUT_MS:10000} responseTimeoutMs: ${KAFKA_RESPONSE_TIMEOUT_MS:10000} consumerSize: ${KAFKA_CONSUMER_SIZE:10} closeConsumersTimeout: ${KAFKA_CLOSE_CONSUMER_TIMEOUT:15000} property: bootstrap.servers: ${KAFKA_BOOTSTRAP_SERVERS:kafka.host:9092} group.id: ${KAFKA_CONSUMER_GROUP_ID:postgres-query-execution} auto.offset.reset: ${KAFKA_AUTO_OFFSET_RESET:earliest} enable.auto.commit: ${KAFKA_AUTO_COMMIT:false} auto.commit.interval.ms: ${KAFKA_AUTO_INTERVAL_MS:1000} datasource: postgres: database: ${POSTGRES_DB_NAME:test} user: ${POSTGRES_USERNAME:dtm} password: ${POSTGRES_PASS:dtm} hosts: ${POSTGRES_HOSTS:localhost:5432} poolSize: ${POSTGRES_POOLSIZE:10} preparedStatementsCacheMaxSize: ${POSTGRES_CACHE_MAX_SIZE:256} preparedStatementsCacheSqlLimit: ${POSTGRES_CACHE_SQL_LIMIT:2048} preparedStatementsCache: ${POSTGRES_CACHE:true} . конфигурационный файл kafka-postgres-reader `application.yml` logging: level: io.arenadata.kafka: ${LOG_LEVEL:DEBUG} org.apache.kafka: ${KAFKA_LOG_LEVEL:INFO} http: port: ${SERVER_PORT:8094} vertx: pools: eventLoopPoolSize: ${VERTX_EVENT_LOOP_SIZE:12} workersPoolSize: ${VERTX_WORKERS_POOL_SIZE:32} verticle: query: instances: ${QUERY_VERTICLE_INSTANCES:12} datasource: postgres: database: ${POSTGRES_DB_NAME:test} user: ${POSTGRES_USERNAME:dtm} password: ${POSTGRES_PASS:dtm} hosts: ${POSTGRES_HOSTS:localhost:5432} poolSize: ${POSTGRES_POOLSIZE:10} preparedStatementsCacheMaxSize: ${POSTGRES_CACHE_MAX_SIZE:256} preparedStatementsCacheSqlLimit: ${POSTGRES_CACHE_SQL_LIMIT:2048} preparedStatementsCache: ${POSTGRES_CACHE:true} fetchSize: ${POSTGRES_FETCH_SIZE:1000} kafka: client: property: key.serializer: org.apache.kafka.common.serialization.ByteArraySerializer value.serializer: org.apache.kafka.common.serialization.ByteArraySerializer . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#kafka_postgres_connector_build_deploy",
    "relUrl": "/getting_started/getting_started.html#kafka_postgres_connector_build_deploy"
  },"6": {
    "doc": "Сборка и развёртывание",
    "title": "Запуск сервисов Apache Zookeeper и Apache Kafka",
    "content": "# запуск одного экземпляра сервера ZooKeeper, если он еще не запущен sudo systemctl start zookeeper # запуск сервера Kafka и проверка его состояния sudo systemctl start kafka sudo systemctl status kafka . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#zookeeper_kafka_execution",
    "relUrl": "/getting_started/getting_started.html#zookeeper_kafka_execution"
  },"7": {
    "doc": "Сборка и развёртывание",
    "title": "Запуск коннектора Kafka-Postgres",
    "content": "# запуск kafka-postgres-writer в отдельном окне терминала cd ~/kafka-postgres-connector/kafka-postgres-writer/target java -jar kafka-postgres-writer-&lt;version&gt;.jar # запуск kafka-postgres-reader в отдельном окне терминала cd ~/kafka-postgres-connector/kafka-postgres-reader/target java -jar kafka-postgres-reader-&lt;version&gt;.jar . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#kafka_postgres_execution",
    "relUrl": "/getting_started/getting_started.html#kafka_postgres_execution"
  },"8": {
    "doc": "Сборка и развёртывание",
    "title": "Запуск службы dtm-status-monitor",
    "content": "# создание символической ссылки на файл конфигурации dtm-status-monitor sudo ln -s ~/prostore/dtm-status-monitor/src/main/resources/application.yml ~/prostore/dtm-status-monitor/target/application.yml # запуск dtm-status-monitor в отдельном окне терминала с указанием порта, заданного в конфигурации Prostore (core:kafka:statusMonitor) cd ~/prostore/dtm-status-monitor/target java -Dserver.port=9095 -jar dtm-status-monitor-&lt;version&gt;.jar . Примечание: Запуск службы dtm-status-monitor без указания порта -Dserver.port приведёт к конкуренции с сервисом Prostore за использование последним порта по умолчанию 8080. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#dtm_status_monitor_execution",
    "relUrl": "/getting_started/getting_started.html#dtm_status_monitor_execution"
  },"9": {
    "doc": "Сборка и развёртывание",
    "title": "Запуск Prostore",
    "content": "Запуск со значением по умолчанию (8080) для порта (server:port) в конфигурации Prostore: . # запуск файла dtm-query-execution-core-&lt;version&gt;.jar (например, dtm-query-execution-core-5.1.0.jar) cd ~/prostore/dtm-query-execution-core/target java -jar dtm-query-execution-core-&lt;version&gt;.jar . Запуск с иным заданным значением осуществляется путём изменения параметра (server:port) в конфигурации Prostore или задании переменной окружения . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#prostore_execution",
    "relUrl": "/getting_started/getting_started.html#prostore_execution"
  },"10": {
    "doc": "Сборка и развёртывание",
    "title": "Подключение к Prostore с помощью SQL-клиента",
    "content": "Порядок подключения описан в разделе Подключение с помощью SQL-клиента. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#sql_client_connection",
    "relUrl": "/getting_started/getting_started.html#sql_client_connection"
  },"11": {
    "doc": "Сборка и развёртывание",
    "title": "Демонстрационный сценарий",
    "content": "Создание необходимых логических сущностей . -- создание логической базы данных CREATE DATABASE sales; -- выбор логической БД по умолчанию USE sales; -- создание логической таблицы в БД sales CREATE TABLE sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id); -- создание внешней таблицы загрузки CREATE UPLOAD EXTERNAL TABLE sales_ext_upload ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://localhost:2181/salesTopic' FORMAT 'AVRO' MESSAGE_LIMIT 1000; -- создание логического представления stores_by_sold_products CREATE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales.sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 30; -- создание внешней таблицы выгрузки в топик Kafka \"salesTopicOut\" CREATE DOWNLOAD EXTERNAL TABLE sales.sales_ext_download ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://localhost:2181/salesTopicOut' FORMAT 'AVRO' CHUNK_SIZE 1000; . Создание топика Kafka для последующей загрузки данных . Создание топика Kafka “salesTopic” в терминале: . cd /opt/kafka/bin bash kafka-topics.sh --create --replication-factor 1 --partitions 1 --topic salesTopic --zookeeper localhost:2181 . Создание бинарного avro-файла kafka_upload_sales.avro из avro-схемы и данных . JSON-файл avro-схемы `kafka_upload_sales.avsc` { \"name\": \"sales\", \"namespace\": \"sales\", \"type\": \"record\", \"fields\": [ { \"name\": \"id\", \"type\": \"long\" }, { \"name\": \"transaction_date\", \"type\": { \"type\": \"long\", \"logicalType\": \"timestamp-micros\" } }, { \"name\": \"product_code\", \"type\": \"string\" }, { \"name\": \"product_units\", \"type\": \"long\" }, { \"name\": \"store_id\", \"type\": \"long\" }, { \"name\": \"description\", \"type\": \"string\" }, { \"name\": \"sys_op\", \"type\": \"int\" } ] } . JSON-файл данных `kafka_upload_sales.json` { \"id\": 1000111, \"transaction_date\": 1614269474000000, \"product_code\": \"ABC102101\", \"product_units\": 2, \"store_id\": 1000012345, \"description\": \"Покупка по акции 1+1\", \"sys_op\": 0 } { \"id\": 1000112, \"transaction_date\": 1614334214000000, \"product_code\": \"ABC102001\", \"product_units\": 1, \"store_id\": 1000000123, \"description\": \"Покупка без акций\", \"sys_op\": 0 } { \"id\": 1000020, \"transaction_date\": 1614636614000000, \"product_code\": \"ABC102010\", \"product_units\": 4, \"store_id\": 1000000123, \"description\": \"Покупка по акции 1+1\", \"sys_op\": 0 } . бинарный AVRO-файл `kafka_upload_sales.avro` сохранить бинарный файл . Загрузка avro-файла kafka_upload_sales.avro . Загрузка avro-файла kafka_upload_sales.avro в топик Kafka “salesTopic” через терминал с помощью kafkacat: . #получение docker-образа kafkacat sudo docker pull edenhill/kcat:1.7.0 #запуск docker-образа kafkacat для загрузки в топик salesTopic #avro-файла /opt/kafka/sales/kafka_upload_sales.avro sudo docker run -it --network host \\ --volume /opt/kafka/sales/kafka_upload_sales.avro:/data/kafka_upload_sales.avro \\ edenhill/kcat:1.7.0 -b localhost:9092 -t salesTopic -P /data/kafka_upload_sales.avro . Загрузка данных . -- открытие новой (горячей) дельты BEGIN DELTA; -- запуск загрузки данных в логическую таблицу sales INSERT INTO sales SELECT * FROM sales.sales_ext_upload; -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Вставка данных . -- открытие новой (горячей) дельты BEGIN DELTA; -- запуск вставки данных в логическую таблицу sales UPSERT INTO sales.sales (id, transaction_date, product_code, product_units, store_id, description) VALUES (2000111, '2020-05-01 13:14:16', 'ABC202010', 7, 1000000123, 'Покупка без акций'), (2000112, '2020-05-02 16:13:17', 'ABC202011', 11, 1000000456, 'Покупка без акций'), (2000113, '2020-05-03 21:15:17', 'ABC202012', 5, 1000000789, 'Покупка без акций'), (2000114, '2020-05-04 23:03:13', 'ABC202013', 7, 1000000123, 'Покупка без акций'), (2000115, '2020-05-05 14:10:21', 'ABC202014', 21, 1000000623, 'Покупка без акций'), (2000116, '2020-06-12 08:43:56', 'ABC202015', 32, 1000000987, 'Покупка без акций'); -- закрытие дельты (фиксация изменений) COMMIT DELTA; . Выборка данных . -- запрос с неявным указанием столбцов и ключевым словом WHERE SELECT * FROM sales.sales WHERE store_id = 1000000123; -- запрос с агрегацией, группировкой и сортировкой данных, а также выбором первых 5 строк SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales.sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC LIMIT 5; -- запрос к логическому представлению stores_by_sold_products SELECT * from stores_by_sold_products; . Выгрузка в топик Kafka . -- запуск выгрузки данных из логической таблицы sales INSERT INTO sales_ext_download SELECT * FROM sales WHERE product_units &gt; 2; . Удаление логических сущностей . -- удаление внешней таблицы загрузки DROP UPLOAD EXTERNAL TABLE sales_ext_upload; -- удаление внешней таблицы выгрузки DROP DOWNLOAD EXTERNAL TABLE sales_ext_download; . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/getting_started/getting_started.html#demo_scenario",
    "relUrl": "/getting_started/getting_started.html#demo_scenario"
  },"12": {
    "doc": "Обзор понятий, компонентов и связей",
    "title": "Обзор понятий, компонентов и связей",
    "content": " ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/overview.html",
    "relUrl": "/overview/overview.html"
  },"13": {
    "doc": "Введение",
    "title": "Введение",
    "content": "Введение . DTM (далее — система) — система для построения витрин данных, позволяющая работать как с актуальными, так и архивными данными. Система выполняет роль интеграционного сервиса, объединяющего различные СУБД хранилища, и предоставляет следующие возможности: . | работа с данными с использованием единой логической схемы данных, не зависящей от типа СУБД хранилища; | параллельная загрузка и выгрузка больших объемов данных; | запрос и выгрузка данных, актуальных на указанный момент времени; | частичное или полное удаление истории изменений данных. | . Работа с системой возможна с помощью любых программных инструментов, которые предоставляют подключение через JDBC-интерфейс. Для запросов к системе используется декларативный язык запросов на основе SQL, в некоторых случаях совпадающий с SQL-стандартом (см. Запросы SQL+). ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/introduction/introduction.html",
    "relUrl": "/introduction/introduction.html"
  },"14": {
    "doc": "Поддерживаемые СУБД хранилища",
    "title": "Поддерживаемые СУБД хранилища",
    "content": "Поддерживаемые СУБД хранилища . Система поддерживает работу со следующими СУБД хранилища: . | Arenadata DB (ADB) — СУБД с массивно-параллельной архитектурой (Massive parallel processing, MPP), построенная на основе Greenplum; | Arenadata QuickMarts (ADQM) — кластерная колоночная СУБД на основе Yandex ClickHouse; | Arenadata Grid (ADG) — система распределенных вычислений в оперативной памяти, построенная на основе Tarantool; | PostgreSQL (ADP) — свободная объектно-реляционная СУБД на основе PostgreSQL. | . Система позволяет работать с перечисленными СУБД одинаковым образом, используя единый синтаксис запросов SQL+ и единую логическую схему данных. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/introduction/supported_DBMS/supported_DBMS.html",
    "relUrl": "/introduction/supported_DBMS/supported_DBMS.html"
  },"15": {
    "doc": "Термины и определения",
    "title": "Термины и определения",
    "content": "Термины и определения . Система — система DTM, описываемая в данном документе. Внешняя информационная система — внешняя система, которая является источником загружаемых данных и (или) получателем выгружаемых данных. СУБД — СУБД из числа поддерживаемых системой. СУБД выгрузки данных — СУБД, из которой выгружаются данные системы. СУБД выгрузки данных определяется в конфигурации системы. Фиксация изменений в данных — процесс сохранения состояния витрины данных, запускаемый соответствующей командой после загрузки данных в систему. Горячая запись — запись, которая загружена в систему, но еще не зафиксирована. После фиксации изменений горячая запись переходит в категорию актуальных. Актуальная запись — зафиксированная запись, которая является актуальной на данный момент. Архивная запись — зафиксированная запись, которая больше не является актуальной. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/introduction/terms/terms.html",
    "relUrl": "/introduction/terms/terms.html"
  },"16": {
    "doc": "Конфигурация",
    "title": "Конфигурация",
    "content": "Конфигурация . Содержание раздела . | Конфигурация сервиса исполнения запросов . | Настройки журналирования | Настройки управления DTM | Настройки сервиса исполнения запросов | Настройки СУБД ADB | Настройки СУБД ADG | Настройки СУБД ADQM | Настройки СУБД ADP | . | Конфигурация сервиса мониторинга статусов Kafka | . Конфигурация системы задается в текстовом файле YAML-формата. Параметры конфигурации организованы в иерархическую структуру типа дерево. В разделе представлены примеры актуальных файлов конфигурации системы: конфигурации сервиса исполнения запросов и конфигурации сервиса мониторинга статусов Kafka. Перед каждым параметром указан комментарий, поясняющий назначение этого параметра. Для наглядности конфигурация сервиса исполнения запросов разделена на отдельные секции. Конфигурация сервиса исполнения запросов . Настройки журналирования . # раздел настроек журналирования logging: # задание уровня важности сообщений, журналируемых в лог-файле level: io.arenadata.dtm.query.execution: ${DTM_LOGGING_LEVEL:TRACE} . Настройки управления DTM . # раздел настроек управления DTM management: # номер порта сервиса метрик server: port: ${DTM_METRICS_PORT:8080} # настройки конечных точек ADTM endpoints: # настройка генерации метрик со стороны ADTM enabled-by-default: ${DTM_METRICS_ENABLED:true} # настройка видимости метрик через веб-соединения web: exposure: # состав метрик, видимых через веб-соединения include: ${DTM_METRICS_SCOPE:info, health, requests} . Настройки сервиса исполнения запросов . # раздел настроек сервиса исполнения запросов core: # настройки плагинов plugins: # список работающих плагинов к соответствующим СУБД active: ${CORE_PLUGINS_ACTIVE:ADG, ADB, ADP, ADQM} # настройки профилей приоритетности СУБД по категориям SQL-запросов category: mapping: # профиль для общих реляционных запросов RELATIONAL: ${DTM_CORE_PLUGINS_RELATIONAL:ADB, ADP, ADQM, ADG} # профиль для запросов аналитики ANALYTICAL: ${DTM_CORE_PLUGINS_ANALYTICAL:ADQM, ADB, ADP, ADG} # профиль для запросов ключ-значение DICTIONARY: ${DTM_CORE_PLUGINS_DICTIONARY:ADG, ADB, ADP, ADQM} # профиль для других категорий запросов UNDEFINED: ${DTM_CORE_PLUGINS_UNDEFINED:ADB, ADP, ADQM, ADG} # настройки сетевых подключений через HTTP-протокол http: # номер порта сервиса исполнения запросов port: ${DTM_CORE_HTTP_PORT:9090} # настройка режима оптимизации работы сокета TCP_NODELAY tcpNoDelay: ${DTM_CORE_HTTP_TCP_NO_DELAY:true} # настройка режима TCP FAST_OPEN tcpFastOpen: ${DTM_CORE_HTTP_TCP_FAST_OPEN:true} # настройка режима оптимизации работы сокета TCP_QUICKACK tcpQuickAck: ${DTM_CORE_HTTP_TCP_QUICK_ACK:true} # настройки окружения env: # имя окружения для формирования полных имен логических БД name: ${DTM_NAME:test} # настройки временной зоны settings: timeZone: ${CORE_TIME_ZONE:UTC} # настройки синхронизации материализованных представлений matviewsync: # периодичность запуска синхронизации в миллисекундах periodMs: ${MATERIALIZED_VIEWS_SYNC_PERIOD_MS:5000} # максимальное количество попыток синхронизации представления, после рестарта системы счетчик обнуляется retryCount: ${MATERIALIZED_VIEWS_RETRY_COUNT:10} # максимальное количество представлений, синхронизируемых одновременно maxConcurrent: ${MATERIALIZED_VIEWS_CONCURRENT:2} # настройки генерации метрики сервиса исполнения запросов metrics: isEnabled: ${DTM_CORE_METRICS_ENABLED:true} # настройки источника данных datasource: # настройки для EDML-операторов edml: # тип СУБД-источника (ADB, ADQM, ADG) sourceType: ${EDML_DATASOURCE:ADB} # количество записей, по умолчанию выгружаемых в одном сообщении топика Каfka defaultChunkSize: ${EDML_DEFAULT_CHUNK_SIZE:1000} # период проверки статуса плагина в миллисекундах pluginStatusCheckPeriodMs: ${EDML_STATUS_CHECK_PERIOD_MS:1000} # интервал времени ожидания (в миллисекундах) до тайм-аута при работе с первым смещением в топике Kafka firstOffsetTimeoutMs: ${EDML_FIRST_OFFSET_TIMEOUT_MS:15000} # интервал времени ожидания (в миллисекундах) до тайм-аута при ожидании смены смещения в топике Kafka changeOffsetTimeoutMs: ${EDML_CHANGE_OFFSET_TIMEOUT_MS:10000} # настройки Zookeeper zookeeper: # сетевой адрес хоста Zookeeper для служебной БД connection-string: ${ZOOKEEPER_DS_ADDRESS:localhost} # интервал времени ожидания (в миллисекундах) соединения с хостом Zookeeper для служебной БД до достижения тайм-аута connection-timeout-ms: ${ZOOKEEPER_DS_CONNECTION_TIMEOUT_MS:30000} # интервал времени бездействия (в миллисекундах) в сессии хоста Zookeeper для служебной БД до достижения тайм-аута session-timeout-ms: ${ZOOKEEPER_DS_SESSION_TIMEOUT_MS:86400000} # корневой путь к хосту Zookeeper для служебной БД chroot: ${ZOOKEEPER_DS_CHROOT:/adtm} # настройки взаимодействия сервиса исполнения запросов с брокером сообщений Kafka kafka: producer: property: # указание сериализатора строковых ключей key.serializer: org.apache.kafka.common.serialization.StringSerializer # указание сериализатора строковых значений value.serializer: org.apache.kafka.common.serialization.StringSerializer # настройка кластера Zookeeper для взаимодействия с брокером сообщений Kafka cluster: zookeeper: # сетевой адрес хоста Zookeeper для брокера сообщений Kafka connection-string: ${ZOOKEEPER_KAFKA_ADDRESS:localhost} # интервал времени ожидания (в миллисекундах) соединения с хостом Zookeeper для брокера сообщений Kafka до достижения тайм-аута connection-timeout-ms: ${ZOOKEEPER_KAFKA_CONNECTION_TIMEOUT_MS:30000} # интервал времени бездействия (в миллисекундах) в сессии хоста Zookeeper для брокера сообщений Kafka до достижения тайм-аута session-timeout-ms: ${ZOOKEEPER_KAFKA_SESSION_TIMEOUT_MS:86400000} # корневой путь к хосту Zookeeper для брокера сообщений Kafka chroot: ${ZOOKEEPER_KAFKA_CHROOT:} # настройки администратора Kafka admin: # интервал времени ожидания (в миллисекундах) входного потока данных для брокера сообщений Kafka до достижения тайм-аута inputStreamTimeoutMs: ${KAFKA_INPUT_STREAM_TIMEOUT_MS:2000} # настройки статусов публикации событий брокером сообщений Kafka status.event.publish: # разрешение на публикацию событий enabled: ${KAFKA_STATUS_EVENT_ENABLED:false} # наименование топика Kafka, в который публикуются события topic: ${KAFKA_STATUS_EVENT_TOPIC:status.event} # настройки подключения к сервису мониторинга статусов Kafka statusMonitor: # сетевой адрес и путь для получения информации о статусе сервиса statusUrl: ${STATUS_MONITOR_URL:http://localhost:9095/status} # сетевой адрес и путь для получения информации о версии сервиса versionUrl: ${STATUS_MONITOR_VERSION_URL:http://localhost:9095/versions} # настройки при использовании фреймворка vertx vertx: # время в (секундах), после которого заблокированный поток пишет stacktrace blocking-stacktrace-time: ${DTM_VERTX_BLOCKING_STACKTRACE_TIME:1} pool: # максимальный размер пула потоков, выполняющих долгие операции worker-pool: ${DTM_CORE_WORKER_POOL_SIZE:20} # максимальный размер пула потоков, обрабатывающих события vertx event-loop-pool: ${DTM_CORE_EVENT_LOOP_POOL_SIZE:20} # максимальный объем пула задач в сервисе исполнения запросов task-pool: ${DTM_CORE_TASK_POOL_SIZE:20} # интервал времени завершения задачи, выполняемой в сервисе исполнения запросов task-timeout: ${DTM_CORE_TASK_TIMEOUT:86400000} # настройки кэширования запросов cache: # начальная емкость кэша initialCapacity: ${CACHE_INITIAL_CAPACITY:100000} # максимальный размер кэша maximumSize: ${CACHE_MAXIMUM_SIZE:100000} # время (в минутах) устаревания кэша после последнего момента обращения к нему expireAfterAccessMinutes: ${CACHE_EXPIRE_AFTER_ACCESS_MINUTES:99960} # настройки отката дельты delta: # периодичность проверки операций записи, требующих остановки, в миллисекундах rollback-status-calls-ms: ${DELTA_ROLLBACK_STATUS_CALLS_MS:2000} . Настройки СУБД ADB . # настройки ADB adb: # настройки источника данных ADB datasource: # имя пользователя/логин для авторизации в ADB user: ${ADB_USERNAME:dtm} # пароль для авторизации в ADB password: ${ADB_PASS:dtm} # сетевой адрес хоста с ADB host: ${ADB_HOST:localhost} # сетевой адрес порта на хосте с ADB port: ${ADB_PORT:5432} # максимальное количество подключений к ADB в одном потоке; # максимальное количество подключений к ADB в целом по всем потокам равно произведению poolSize и executorsCount poolSize: ${ADB_MAX_POOL_SIZE:3} # количество одновременных потоков, исполняющих запросы к ADB executorsCount: ${ADB_EXECUTORS_COUNT:3} # максимальный размер результата, возвращаемого по FETCH-запросу к ADB fetchSize: ${ADB_FETCH_SIZE:1000} # максимальный размер кэша запроса prepared statement preparedStatementsCacheMaxSize: ${ADB_PREPARED_CACHE_MAX_SIZE:256} # максимальный размер запроса prepared statement, который может быть закэширован preparedStatementsCacheSqlLimit: ${ADB_PREPARED_CACHE_SQL_LIMIT:2048} # признак кэширования запросов prepared statement preparedStatementsCache: ${ADB_PREPARED_CACHE:true} # настройки механизма загрузки данных в ADB mppw: # наименование консьюмер-группы ADB для взаимодействия с брокером сообщений Kafka consumerGroup: ${ADB_LOAD_GROUP:adb-emulator-load-adb} # максимальный размер пула подключений к ADB для операций загрузки poolSize: ${ADB_MPPW_POOL_SIZE:2} # значение тайм-аута ожидания (в миллисекундах) для остановки загрузки stopTimeoutMs: ${ADB_MPPW_STOP_TIMEOUT_MS:86400000} # предельное количество сообщений для операции загрузки в ADB defaultMessageLimit: ${ADB_MPPW_DEFAULT_MESSAGE_LIMIT:100} # значение тайм-аута ожидания (в миллисекундах) для FDW-коннектора ADB fdwTimeoutMs: ${ADB_MPPW_FDW_TIMEOUT_MS:1000} # признак использования исторических таблиц with-history-table: ${ADB_WITH_HISTORY_TABLE:false} . Настройки СУБД ADG . # настройки ADG adg: tarantool: db: # сетевой адрес хоста с ADG host: ${TARANTOOL_DB_HOST:localhost} # сетевой адрес порта на хосте с ADG port: ${TARANTOOL_DB_PORT:3306} # имя пользователя/логин для авторизации в ADG user: ${TARANTOOL_DB_USER:admin} # пароль для авторизации в ADG password: ${TARANTOOL_DB_PASS:memstorage-cluster-cookie} # максимальный интервал времени ожидания выполнения операции ADG до тайм-аута operationTimeout: ${TARANTOOL_DB_OPER_TIMEOUT:60000} # максимальное количество повторных попыток выполнения операции retryCount: ${TARANTOOL_DB_RETRY_COUNT:0} # движок ADG engine: ${TARANTOOL_DEFAULT_ENGINE:MEMTX} # настройки картриджа Tatantool cartridge: # сетевой путь и порт к картриджу Tarantool url: ${TARANTOOL_CATRIDGE_URL:http://localhost:8086} # настройки механизма загрузки данных mppw: # наименование консьюмер-группы ADG для взаимодействия с брокером сообщений Kafka consumerGroup: ${ADG_CONSUMER_GROUP:tarantool-group-csv} kafka: # максимальное количество сообщений в топике Kafka на раздел ADG maxNumberOfMessagesPerPartition: ${ADG_MAX_MSG_PER_PARTITION:200} # время простоя (в секундах) callback-функции callbackFunctionSecIdle: ${ADG_CB_FUNC_IDLE:100} # настройки отката операции rollback: # размер пакета операций при откате eraseOperationBatchSize: ${ADG_ROLLBACK_OPERATION_BATCH_SIZE:300} # настройки отказоустойчивости ADG по паттерну circuitbreaker circuitbreaker: # максимальное количество отказов ADG maxFailures: ${ADG_CIRCUIT_BREAKER_MAX_FAILURES:5} # интервал времени фиксации отказа при пропадании отклика ADG timeout: ${ADG_CIRCUIT_BREAKER_TIMEOUT:30000} # использование паттерна fallback при отказе fallbackOnFailure: ${ADG_CIRCUIT_BREAKER_FALLBACK_ON_FAILURE:false} # интервал времени до сброса по паттерну timeout resetTimeout: ${ADG_CIRCUIT_BREAKER_RESET_TIMEOUT:10000} # настройки для подключений веб-клиентов web-client: # максимальный размер пула подключений веб-клиентов к ADG max-pool-size: ${ADG_WEB_CLIENT_MAX_POOL_SIZE:100} . Настройки СУБД ADQM . # настройки ADQM adqm: # настройка источника данных ADQM datasource: # наименование ADQM database: ${ADQM_DB_NAME:upload} # имя пользователя/логин для авторизации в ADQM user: ${ADQM_USERNAME:} # пароль для авторизации в ADQM password: ${ADQM_PASS:} # сетевой адрес хоста с ADQM и номер порта на хосте hosts: ${ADQM_HOSTS:localhost:8123} # интервал времени ожидания отклика соединения с ADQM до тайм-аута socketTimeout: ${ADQM_SOCKET_TIMEOUT:30000} # интервал времени ожидания завершения обмена данными с ADQM до тайм-аута dataTransferTimeout: ${ADQM_DATA_TRANSFER_TIMEOUT:10000} # настройки DDL-операторов ddl: # наименование кластера ADQM cluster: ${ADQM_CLUSTER:test_arenadata} # настройки механизма выгрузки данных из ADQM mppr: # сетевой адрес и путь для запросов на выгрузку данных loadingUrl: ${ADQM_MPPR_CONNECTOR_URL:http://localhost:8086/query} # сетевой адрес и путь для получения информации о версии коннектора versionUrl: ${ADQM_MPPR_CONNECTOR_VERSION_URL:http://localhost:8086/versions} # настройки механизма загрузки данных ADQM mppw: # наименование консьюмер-группы ADQM для загрузки данных в ADQM # не используется consumerGroup: ${ADQM_CONSUMER_GROUP:adqm} # сетевой адрес брокера сообщений Kafka kafkaBrokers: ${ADQM_BROKERS:localhost:9092} # тип интерфейса для загрузки данных в ADQM loadType: ${ADQM_MPPW_LOAD_TYPE:REST} # сетевой адрес и путь к REST-интерфейсу для загрузки новых данных в ADQM restStartLoadUrl: ${ADQM_REST_START_LOAD_URL:http://localhost:8090/newdata/start} # сетевой адрес и путь к REST-интерфейсу для остановки загрузки данных в ADQM restStopLoadUrl: ${ADQM_REST_STOP_LOAD_URL:http://localhost:8090/newdata/stop} # сетевой адрес и путь для получения информации о версии коннектора versionUrl: ${ADQM_MPPW_CONNECTOR_VERSION_URL:http://localhost:8090/versions} # наименование коньсюмер-группы для загрузки данных в ADQM через REST API restLoadConsumerGroup: ${ADQM_REST_LOAD_GROUP:adb-emulator-load-adqm} # настройки для подключений веб-клиентов web-client: # максимальный размер пула подключений веб-клиентов к ADQM max-pool-size: ${ADQM_WEB_CLIENT_MAX_POOL_SIZE:100} . Настройки СУБД ADP . # настройки ADP adp: # настройка источника данных ADP datasource: # имя пользователя/логин для авторизации в ADP user: ${ADP_USERNAME:dtm} # пароль для авторизации в ADP password: ${ADP_PASS:dtm} # сетевой адрес хоста с ADP host: ${ADP_HOST:localhost} # сетевой адрес порта на хосте с ADP port: ${ADP_PORT:5432} # максимальное количество подключений к ADP в одном потоке; # максимальное количество подключений к ADP в целом по всем потокам равно произведению poolSize и executorsCount poolSize: ${ADP_MAX_POOL_SIZE:3} # количество одновременных потоков, исполняющих запросы к ADP executorsCount: ${ADP_EXECUTORS_COUNT:3} # максимальный размер результата, возвращаемого по FETCH-запросу к ADP fetchSize: ${ADP_FETCH_SIZE:1000} # максимальный размер кэша запроса prepared statement preparedStatementsCacheMaxSize: ${ADP_PREPARED_CACHE_MAX_SIZE:256} # максимальный размер запроса prepared statement, который может быть закэширован preparedStatementsCacheSqlLimit: ${ADP_PREPARED_CACHE_SQL_LIMIT:2048} # признак кэширования запросов prepared statement preparedStatementsCache: ${ADP_PREPARED_CACHE:true} # настройки механизма загрузки данных в ADP mppw: # сетевой адрес и путь к REST-интерфейсу для загрузки данных в ADP restStartLoadUrl: ${ADP_REST_START_LOAD_URL:http://localhost:8096/newdata/start} # сетевой адрес и путь к REST-интерфейсу для остановки загрузки данных в ADP restStopLoadUrl: ${ADP_REST_STOP_LOAD_URL:http://localhost:8096/newdata/stop} # сетевой адрес и путь для получения информации о версии коннектора restVersionUrl: ${ADP_MPPW_CONNECTOR_VERSION_URL:http://localhost:8096/versions} # наименование коньсюмер-группы для загрузки данных в ADP через REST API kafkaConsumerGroup: ${ADP_KAFKA_CONSUMER_GROUP:adp-load} # настройки механизма выгрузки данных из ADP mppr: # сетевой адрес и путь для запросов на выгрузку данных restLoadUrl: ${ADP_MPPR_QUERY_URL:http://localhost:8094/query} # сетевой адрес и путь для получения информации о версии коннектора restVersionUrl: ${ADP_MPPR_CONNECTOR_VERSION_URL:http://localhost:8094/versions} . Конфигурация сервиса мониторинга статусов Kafka . # настройки cервиса мониторинга статусов Kafka monitor: # список адресов брокеров сообщений Kafka brokersList: ${STATUS_MONITOR_BROKERS:localhost:9092} # количество потребителей (консьюмеров) cервиса мониторинга Kafka consumersCount: ${STATUS_MONITOR_CONSUMERS:8} . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/maintenance/configuration/configuration.html",
    "relUrl": "/maintenance/configuration/configuration.html"
  },"17": {
    "doc": "Схемы развертывания",
    "title": "Схемы развертывания",
    "content": "Схемы развертывания . Систему можно разворачивать различными способами, устанавливая различные наборы связанных компонентов, — в зависимости от целей проекта. Однако есть основные схемы развертывания системы: . | с кластерами каждой из следующих СУБД хранилища: ADB, ADQM и ADG; | с сервером одной СУБД хранилища — ADP. | . На рисунке ниже показана схема развертывания системы с ADB, ADQM и ADG. Стрелки направлены от вызывающих компонентов к вызываемым. Схема развертывания с ADB, ADQM и ADG . На рисунке ниже показана схема развертывания системы с ADP. Стрелки направлены от вызывающих компонентов к вызываемым. Схема развертывания с ADP . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/maintenance/deployment_diagrams/deployment_diagrams.html",
    "relUrl": "/maintenance/deployment_diagrams/deployment_diagrams.html"
  },"18": {
    "doc": "Настройка JSON-логов",
    "title": "Настройка JSON-логов",
    "content": "Настройка JSON-логов . Система поддерживает конфигурацию и отображение JSON-логов проекта Logback. Помимо стандартных параметров, таких как время сообщения, уровень логирования и т.д., система позволяет отображать в логах уникальные идентификаторы запросов. Если отображение идентификаторов настроено, для каждого запроса SQL+ отображается уникальный идентификатор, для внутреннего запроса системы — значение no_id. Чтобы настроить отображение идентификаторов запросов в логах, отредактируйте файл logback.xml (полный пример файла см. ниже): . | Перед объявлением appender добавьте строки: . &lt;conversionRule conversionWord=\"vcl\" converterClass=\"io.reactiverse.contextual.logging.LogbackConverter\"/&gt; . | В секцию appender.providers.pattern добавьте строку: . \"requestId\": \"%vcl{requestId:-no_id}\" . | . Ниже показан пример файла logback.xml с включенным отображением идентификаторов запросов: . &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;configuration&gt; &lt;conversionRule conversionWord=\"vcl\" converterClass=\"io.reactiverse.contextual.logging.LogbackConverter\"/&gt; &lt;appender name=\"rollingFile\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;logs/application.log&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;!-- daily rollover --&gt; &lt;fileNamePattern&gt;logs/application.%d{yyyy-MM-dd}.log.gz&lt;/fileNamePattern&gt; &lt;!-- keep 30 days' worth of history capped at 3GB total size --&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;totalSizeCap&gt;3GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder\"&gt; &lt;providers&gt; &lt;pattern&gt; &lt;omitEmptyFields&gt;true&lt;/omitEmptyFields&gt; &lt;pattern&gt; { \"timestamp\": \"%date{ISO8601}\", \"logger\": \"%logger\", \"level\": \"%level\", \"thread\": \"%thread\", \"requestId\": \"%vcl{requestId:-no_id}\", \"message\": \"%message\" } &lt;/pattern&gt; &lt;/pattern&gt; &lt;stackTrace&gt; &lt;throwableConverter class=\"net.logstash.logback.stacktrace.ShortenedThrowableConverter\"&gt; &lt;maxDepthPerThrowable&gt;30&lt;/maxDepthPerThrowable&gt; &lt;maxLength&gt;2048&lt;/maxLength&gt; &lt;shortenedClassNameLength&gt;20&lt;/shortenedClassNameLength&gt; &lt;exclude&gt;^sun\\.reflect\\..*\\.invoke&lt;/exclude&gt; &lt;exclude&gt;^net\\.sf\\.cglib\\.proxy\\.MethodProxy\\.invoke&lt;/exclude&gt; &lt;rootCauseFirst&gt;true&lt;/rootCauseFirst&gt; &lt;/throwableConverter&gt; &lt;/stackTrace&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"rollingFile\" /&gt; &lt;/root&gt; &lt;/configuration&gt; . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/maintenance/json_logs_configuration/json_logs_configuration.html",
    "relUrl": "/maintenance/json_logs_configuration/json_logs_configuration.html"
  },"19": {
    "doc": "Эксплуатация",
    "title": "Эксплуатация",
    "content": "Эксплуатация . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/maintenance/maintenance.html",
    "relUrl": "/maintenance/maintenance.html"
  },"20": {
    "doc": "Минимальные системные требования",
    "title": "Минимальные системные требования",
    "content": "Минимальные системные требования . Система предъявляет следующие минимальные требования: . | аппаратные требования: . | ядро системы: 4 CPU, 16 RAM, 20 HDD; | сервис мониторинга статусов Kafka: 2 CPU, 8 RAM, 20 HDD; | . | программные требования: . | ADB версии 6.15.0; | ADQM версии 20.4.4.18; | ADG версии 2.7.2; | PostgreSQL версии 13.3; | ADS: . | ADS версии 1.5; | Kafka версии 2.4; | Zookeeper версии 3.5.6. | . | . | . Компоненты, с которыми работает система, предъявляют минимальные требования, перечисленные в таблице ниже. | Компонент | Системные требования | . | ADB | https://docs.arenadata.io/adb/requirements/online.html#id2 | . | ADQM | https://docs.arenadata.io/adqm/requirements/index.html#clickhouse | . | ADG (Tarantool) | https://www.tarantool.io/en/sizing_calculator/ | . | PostgreSQL | https://postgrespro.ru/docs/postgresql/13/install-requirements | . | Kafka | https://docs.arenadata.io/ads/Requirements/min.html | . | Zookeeper | https://docs.arenadata.io/ads/Requirements/min.html | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/maintenance/system_requirements/system_requirements.html",
    "relUrl": "/maintenance/system_requirements/system_requirements.html"
  },"21": {
    "doc": "Часовые пояса системы и компонентов",
    "title": "Часовые пояса системы и компонентов",
    "content": "Часовые пояса системы и компонентов . | Значения времени должны лежать в диапазоне от 00:00:00.000000 до 23:59:59.999999 включительно. | Все значения типа TIMESTAMP, загружаемые в систему и выгружаемые из нее, не содержат данных о часовых поясах и рассматриваются системой как время UTC. | Часовой пояс системы должен быть задан в конфигурации как UTC (см. параметр CORE_TIME_ZONE). | Часовой пояс хранилища данных должен быть задан как UTC. | JDBC-функции getDate, getTime и getTimestamp системы возвращают дату и время SQL без указания часового пояса (значение java.sql.date, нормализованное относительно GMT+0). | . Загружаемое и возвращаемое значения типа TIMESTAMP . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/maintenance/time_zones/time_zones.html",
    "relUrl": "/maintenance/time_zones/time_zones.html"
  },"22": {
    "doc": "Компоненты системы",
    "title": "Компоненты системы",
    "content": "Компоненты системы . Система состоит из следующих компонентов (см. рисунок ниже): . | JDBC-драйвер — размещается на стороне внешней информационной системы; предоставляет JDBC-интерфейс подключения к DTM и взаимодействует с сервисом исполнения запросов по REST API; | сервис исполнения запросов (DTM Core) — анализирует и исполняет SQL-запросы; предоставляет REST API для JDBC-драйвера и взаимодействует с сервисом мониторинга статусов Kafka по REST API; | сервис мониторинга статусов Kafka (DTM Status Monitor) — отслеживает состояние топиков брокера сообщений Kafka; предоставляет REST API для сервиса исполнения запросов. | . Версии используемых компонентов системы можно проверить с помощью запроса CHECK_VERSIONS. На рисунке ниже показана схема компонентов системы. Компоненты системы . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/components/components.html",
    "relUrl": "/overview/components/components.html"
  },"23": {
    "doc": "Порядок обработки запросов на обновление логической схемы",
    "title": "Порядок обработки запросов на обновление логической схемы",
    "content": "Порядок обработки запросов на обновление логической схемы . Запрос на обновление логической схемы данных обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос на обновление логической схемы данных, используя JDBC-драйвер DTM. | Запрос поступает в сервис исполнения запросов DTM. | Сервис исполнения запросов определяет, для каких СУБД хранилища предназначен запрос, модифицирует (обогащает) запрос нужным образом и отправляет в соответствующие СУБД команду на обновление физической схемы данных. | Сервис исполнения запросов сохраняет изменения логической схемы данных в сервисной базе данных. | Сервис исполнения запросов публикует сообщение об обновлении логической схемы данных в топике Kafka, указанном в конфигурации системы (см. параметр KAFKA_STATUS_EVENT_TOPIC). | После успешного обновления логической и физической схем данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/interactions/ddl_processing/ddl_processing.html",
    "relUrl": "/overview/interactions/ddl_processing/ddl_processing.html"
  },"24": {
    "doc": "Порядок обработки запросов на выгрузку данных",
    "title": "Порядок обработки запросов на выгрузку данных",
    "content": "Порядок обработки запросов на выгрузку данных . Запрос на выгрузку данных обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос INSERT INTO download_external_table, используя JDBC-драйвер DTM. | Запрос поступает в сервис исполнения запросов DTM. | Сервис исполнения запросов анализирует запрос и запрашивает актуальную информацию о логической схеме данных в сервисной базе данных. | Сервис исполнения запросов на основании конфигурации определяет, для какой СУБД хранилища данных предназначен запрос, и отправляет в соответствующий коннектор команду на выгрузку данных из этой СУБД. | Коннектор выгружает данные в топик Kafka, который определен в свойствах внешней таблицы выгрузки, указанной в запросе. | После успешного выполнения выгрузки данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/interactions/download_processing/download_processing.html",
    "relUrl": "/overview/interactions/download_processing/download_processing.html"
  },"25": {
    "doc": "Связи с другими системами и компонентами",
    "title": "Связи с другими системами и компонентами",
    "content": "Связи с другими системами и компонентами . Система взаимодействует со следующими внешними системами и компонентами (см. рисунок ниже): . | внешней информационной системой-клиентом (по JDBC-интерфейсу), | сервисной базой данных (по API ZooKeeper), | СУБД хранилища данных (по интерфейсу JDBC или REST API — в зависимости от типа СУБД), | коннекторами (по API коннекторов); | брокером сообщений Kafka (по API Kafka). | . На рисунке ниже показаны взаимодействия системы с внешними системами и компонентами. Состав внешних компонентов, с которыми работает система, может меняться в зависимости от требований проекта (см. раздел Схемы развертывания). Внешние взаимодействия системы . Взаимодействия системы с внешними системами и компонентами при выполнении основных действий описаны в разделах: . | Порядок обработки запросов на обновление логической схемы, | Порядок обработки запросов на загрузку данных, | Порядок обработки запросов на выгрузку данных, | Порядок обработки запросов на чтение данных. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/interactions/interactions.html",
    "relUrl": "/overview/interactions/interactions.html"
  },"26": {
    "doc": "Порядок обработки запросов на чтение данных",
    "title": "Порядок обработки запросов на чтение данных",
    "content": "Порядок обработки запросов на чтение данных . Запросы на чтение данных обрабатываются в следующем порядке: . | Внешняя информационная система формирует запрос, используя JDBC-драйвер DTM. | Запрос поступает в сервис исполнения запросов DTM. | Сервис исполнения запросов анализирует запрос и запрашивает актуальную информацию о логической схеме данных в сервисной базе данных. | Сервис исполнения запросов определяет, для какой СУБД хранилища данных предназначен запрос, модифицирует (обогащает) запрос нужным образом и отправляет в эту СУБД команду на исполнение обогащенного запроса. | После успешного выполнения чтения данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/interactions/llr_processing/llr_processing.html",
    "relUrl": "/overview/interactions/llr_processing/llr_processing.html"
  },"27": {
    "doc": "Порядок обработки запросов на загрузку данных",
    "title": "Порядок обработки запросов на загрузку данных",
    "content": "Порядок обработки запросов на загрузку данных . Запрос на загрузку данных в логическую таблицу обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос INSERT INTO logical_table, используя JDBC-драйвер DTM. | Запрос поступает в сервис исполнения запросов DTM. | Сервис исполнения запросов анализирует запрос и сохраняет информацию о процессе загрузки данных в сервисной базе данных. | Сервис исполнения запросов отправляет в коннектор каждой из целевых СУБД хранилища команду на загрузку данных и отслеживает состояние загрузки с помощью сервиса мониторинга статусов Kafka. Под целевыми подразумеваются СУБД, в которых размещаются данные логической таблицы (см. CREATE TABLE). | Коннектор загружает данные из топика Kafka, который определен в свойствах внешней таблицы загрузки, указанной в запросе. | По завершении загрузки всех или каждого пакета данных (в зависимости от типа СУБД) сервис исполнения запросов отправляет в целевые СУБД команду на выполнение задач по версионированию данных. | После успешного выполнения загрузки данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/interactions/upload_processing/upload_processing.html",
    "relUrl": "/overview/interactions/upload_processing/upload_processing.html"
  },"28": {
    "doc": "Хранилище данных",
    "title": "Хранилище данных",
    "content": "Хранилище данных . Физическое хранилище данных (далее — хранилище) — совокупность СУБД различного типа, в которых хранятся данные логических таблиц. Данные в хранилище хранятся в соответствии с физической схемой данных. Система предоставляет единый интерфейс взаимодействия с хранилищем в виде логической базы данных. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/data_storage/data_storage.html",
    "relUrl": "/overview/main_concepts/data_storage/data_storage.html"
  },"29": {
    "doc": "Дельта",
    "title": "Дельта",
    "content": "Дельта . Дельта — целостная совокупность изменений в логической базе данных. Дельта включает все операции записи, выполненные между открытием и закрытием этой дельты, и имеет порядковый номер, уникальный в рамках логической базы данных. Нумерация дельт начинается с 0. Дельты упорядочены в порядке возрастания их номеров и формируют историю состояний данных логической БД. На рисунке ниже показана последовательность операций записи, выполненных в рамках дельт с номерами 0 и 1. В рамках дельты 0 выполнены операции записи с номерами 0-2, в рамках дельты 1 — операции записи с номерами 3-6. Операции записи двух дельт . Дельту можно открыть, закрыть и отменить (откатить). Дельта, которая была открыта и еще не была закрыта, содержит горячие записи и называется открытой или горячей. Для каждой логической базы одновременно может быть открыто не более одной дельты. Дельта, которая была закрыта (зафиксирована) содержит актуальные записи и называется закрытой. На рисунке ниже показана последовательность дельт, где дельта с номером 3 является открытой, а все предыдущие — закрытыми. Открытая и закрытые дельты . Для загрузки данных в логическую БД нужно открыть дельту, загрузить данные в требуемые логические таблицы, после чего сохранить изменения (закрыть дельту). В рамках открытой дельты можно выполнить любое число операций записи. Примечание: не допускается загрузка различных состояний одного и того же объекта в рамках одной дельты. Для загрузки обновленных данных объекта нужно закрыть открытую дельту, открыть новую дельту и загрузить необходимые изменения (см. пример на рисунке ниже). На рисунке ниже показан пример обновления данных клиента, сменившего фамилию. Первоначальные данные клиента загружены в рамках дельты 0, а обновленные данные — в рамках дельты 1. Обновление данных клиента, сменившего фамилию . Если нужно вернуть состояние данных, которое предшествовало изменениям, выполненным в рамках открытой дельты, следует откатить дельту. Откатить можно только открытую дельту, после закрытия дельты возврат к предыдущему состоянию данных невозможен. При запросе и выгрузке данных номер дельты можно использовать, чтобы указать момент или период, по состоянию на который запрашивается информация (см. секцию FOR SYSTEM_TIME в разделе SELECT). ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/delta/delta.html",
    "relUrl": "/overview/main_concepts/delta/delta.html"
  },"30": {
    "doc": "Окружение",
    "title": "Окружение",
    "content": "Окружение . Окружение — совокупность логических баз данных, доступных при работе с системой. Инсталляция системы работает с окружением, заданным в конфигурации. Допустимо создавать несколько окружений для одного набора кластеров СУБД и при необходимости перенастраивать инсталляцию системы на другое окружение. Попеременное использование независимых окружений может быть полезно, например, в случае разделения различных тестовых сред. На рисунке ниже показан пример инсталляции системы с тремя окружениями, где в настоящий момент внешняя информационная система работает с окружением test2. Инсталляция системы с тремя окружениями . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/environment/environment.html",
    "relUrl": "/overview/main_concepts/environment/environment.html"
  },"31": {
    "doc": "Внешняя таблица",
    "title": "Внешняя таблица",
    "content": "Внешняя таблица . Внешняя таблица задает набор параметров внешнего приемника данных (например, топика Kafka), используемого для параллельной загрузки или выгрузки данных. Набор включает следующие параметры: . | список передаваемых полей, | путь к внешнему приемнику данных, | формат обмена данными. | . Внешняя таблица представляет собой декларацию источника/приемника данных и формата загрузки/выгрузки данных и не хранит сами данные. Внешние таблицы разделяются по назначению: . | внешние таблицы загрузки используются для загрузки данных в систему, | внешние таблицы выгрузки используются для выгрузки данных из системы. | . Внешние таблицы можно создавать и удалять: . | создание внешней таблицы загрузки, | создание внешней таблицы выгрузки, | удаление внешней таблицы загрузки, | удаление внешней таблицы выгрузки. | . В зависимости от требований проекта созданная внешняя таблица может использоваться однократно или многократно. Следует учитывать, что потоки обмена данными с системой должны быть разделены по приемникам данных в следующих разрезах: . | по логическим таблицам, | по направлениям передачи данных (загрузка/выгрузка), | (опционально) на основе каких-либо дополнительных критериев (например, по целевым информационным системам). | . Например, если для логической таблицы транзакций нужно поддержать и загрузку, и выгрузку данных, следует создать две (или более) внешние таблицы: хотя бы одну таблицу загрузки транзакций и хотя бы одну — выгрузки. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/external_table/external_table.html",
    "relUrl": "/overview/main_concepts/external_table/external_table.html"
  },"32": {
    "doc": "Логическая база данных",
    "title": "Логическая база данных",
    "content": "Логическая база данных . Логическая база данных (логическая БД) — совокупность логических сущностей (логических таблиц, логических представлений, материализованных представлений и внешних таблиц), сгруппированных по какому-либо принципу, например по направлению анализа. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/logical_db/logical_db.html",
    "relUrl": "/overview/main_concepts/logical_db/logical_db.html"
  },"33": {
    "doc": "Логическая схема данных",
    "title": "Логическая схема данных",
    "content": "Логическая схема данных . Логическая схема данных — внешнее представление структуры данных окружения, единое для всех поддерживаемых СУБД хранилища. Логическая схема данных представляет собой иерархию следующих объектов: . | логических баз данных, | логических таблиц, | логических представлений, | материализованных представлений, | внешних таблиц. | . Логическая схема данных хранится в сервисной базе данных системы. На рисунке ниже показана иерархия объектов логической схемы данных. Объекты логической схемы и их связи с объектами физической схемы . Внешняя информационная система (пользователь) отправляет системе запросы к данным, сформулированные в терминах логической схемы. Система разбирает полученные запросы, модифицирует (обогащает) их нужным образом и перенаправляет к физическим таблицам хранилища данных. В зависимости от момента времени, указанного в запросе, система обращается к горячим, актуальным или архивным данным. Такая модель взаимодействия позволяет работать с различными версиями данных, которые хранятся в различных СУБД хранилища, в едином формате. Связанные разделы: . | Управление схемой данных. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/logical_schema/logical_schema.html",
    "relUrl": "/overview/main_concepts/logical_schema/logical_schema.html"
  },"34": {
    "doc": "Логическая таблица",
    "title": "Логическая таблица",
    "content": "Логическая таблица . Логическая таблица — структурированная совокупность записей о состояниях объектов одного типа, например счетов или контрагентов. Логическая таблица не хранит сами данные, а предоставляет доступ к данным соответствующих физических таблиц хранилища. В отличие от реляционной таблицы, объекты которой обычно хранятся в актуальном (текущем) состоянии, логическая таблица предоставляет информацию обо всех исторических состояниях объектов: новых, актуальных и архивных. Например, данные одного клиента могут иметь нескольких версий в логической таблице clients: . | архивная запись с номером телефона +7(342)205-90-59 и адресом Пермь, | актуальная запись с номером телефона +7(495)777-77-77 и адресом Пермь (клиент сменил номер телефона), | горячая (новая) запись с номером телефона +7(495)777-77-77 и адресом Москва (клиент сменил адрес; запись загружена, но еще не зафиксирована). | . На рисунке ниже показана схема связей логической таблицы с ее физическими представлениями — физическими таблицами хранилища данных. Связи логической таблицы с физическими таблицами . Работа с логическими таблицами напоминает работу с реляционными таблицами. Логические таблицы можно создавать и удалять. Данные логической таблицы можно загружать, запрашивать и выгружать. При обращении к данным логической таблицы можно указать момент времени, по состоянию на который запрашиваются данные. Если момент времени не указан, система возвращает данные, актуальные на момент обработки запроса. Таким образом, можно получать данные из логической таблицы по состоянию на любой момент времени — независимо от того, являются они горячими (новыми), актуальными или архивными. При создании логической таблицы система автоматически создает и далее поддерживает набор физических таблиц для хранения данных. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/logical_table/logical_table.html",
    "relUrl": "/overview/main_concepts/logical_table/logical_table.html"
  },"35": {
    "doc": "Логическое представление",
    "title": "Логическое представление",
    "content": "Логическое представление . Логическое представление — сохраненный запрос к данным одной или нескольких логических таблиц, который имеет имя и может использоваться как источник данных в других запросах. Примером логического представления является список контрагентов, объединенный с информацией о благонадежности контрагентов и их контактами. Работа с логическими представлениями напоминает работу с реляционными представлениями. Логические представления можно создавать, изменять и удалять. Данные логического представления можно запрашивать и выгружать. Логическое представление проецирует данные связанных логических таблиц и не отражается в хранилище. Загрузка данных в логические представления невозможна. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/logical_view/logical_view.html",
    "relUrl": "/overview/main_concepts/logical_view/logical_view.html"
  },"36": {
    "doc": "Основные понятия",
    "title": "Основные понятия",
    "content": "Основные понятия . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/main_concepts.html",
    "relUrl": "/overview/main_concepts/main_concepts.html"
  },"37": {
    "doc": "Материализованное представление",
    "title": "Материализованное представление",
    "content": "Материализованное представление . Содержание раздела . | Синхронизация материализованных представлений . | Пример синхронизации материализованного представления | . | . Материализованное представление — структурированная совокупность записей, содержащих результаты выполнения запроса к одной или нескольким логическим таблицам. Материализованное представление позволяет предварительно вычислить результат запроса и сохранить его для будущего использования. Материализованное представление строится на основе данных одной СУБД хранилища (далее — СУБД-источник), а его данные размещаются в другой СУБД. Это позволяет создавать инсталляции, где одна СУБД служит полноценным хранилищем исходных данных, а остальные СУБД отвечают за быструю выдачу данных по запросам чтения. В текущей версии системы доступно создание материализованных представлений в ADG на основе данных из ADB. Материализованное представление помогает ускорить запросы к данным в следующих случаях: . | если представление содержит результаты сложного запроса, который на исходных данных выполняется дольше; | если запросы к представлению возвращают значительно меньше данных, чем запросы к исходным данным; | если запросы относятся к категории, которую та СУБД хранилища, где размещены данные представления, выполняет более эффективно, чем СУБД-источник (например, ADG быстрее всех из поддерживаемых СУБД обрабатывает чтение по ключу). | . Материализованное представление дает доступ к актуальным и архивным состояниях объектов. Чтение горячих данных из представления недоступно: это позволяет избежать чтения изменений, частично загруженных из СУБД-источника. Данные материализованного представления хранятся аналогично данным логических таблиц — в физических таблицах хранилища, которые автоматически создаются при создании представления. Связи материализованного представления с физическими таблицами . Система поддерживает целостность данных материализованных представлений, периодически синхронизируя их с данными СУБД-источника (см. ниже). Синхронизация материализованного представления . Материализованные представления можно создавать и удалять. Из материализованного представления можно запрашивать данные — так же, как из логических таблиц и логических представлений. Загрузка и выгрузка данных материализованных представлений не поддерживается. При запросе данных из материализованного представления можно указать момент времени, по состоянию на который запрашиваются данные. Если момент времени не указан, система возвращает данные, актуальные на момент последней синхронизации представления, иначе — данные, актуальные на запрашиваемый момент времени. При запросе данных на указанный момент времени может оказаться, что материализованное представление отстало от СУБД-источника и не содержит запрошенные данные. В этом случае система перенаправляет запрос к исходным таблицам СУБД-источника (см. раздел Маршрутизация запросов к данным материализованных представлений). Перенаправленный запрос может выполняться дольше, однако это позволяет получить данные, полностью актуальные на указанный момент времени. Синхронизация материализованных представлений . Система периодически проверяет, нужно ли синхронизировать материализованные представления окружения с СУБД-источником. Периодичность проверки настраивается в конфигурации системы (см. параметр MATERIALIZED_VIEWS_SYNC_PERIOD_MS); по умолчанию проверка запускается раз в 5 секунд. Проверка материализованных представлений запускается только по таймеру и не запускается по другим событиям, таким как создание материализованного представления или загрузка данных в СУБД-источник. При срабатывании таймера система проверяет, появились ли в СУБД-источнике дельты, закрытые после последней синхронизации и, если такие дельты появились, система синхронизирует материализованные представления с СУБД-источником. Количество одновременно синхронизируемых представлений задается в конфигурации с помощью параметра MATERIALIZED_VIEWS_CONCURRENT. По умолчанию одновременно синхронизируется максимум два представления, а остальные, если они есть, ожидают следующего цикла проверки. Данные представления синхронизируются отдельно по каждой закрытой дельте — с полным сохранением изменений, выполненных в этих дельтах. В каждой дельте для материализованного представления рассчитывается и сохраняется результат запроса, указанного при создании этого представления. Таким образом, материализованное представление имеет такой же уровень историчности данных, как и исходные логические таблицы, на которых построено представление. Если системе не удалось синхронизировать материализованное представление, она делает несколько повторных попыток. Максимальное количество попыток синхронизации представления задается в конфигурации (см. параметр MATERIALIZED_VIEWS_RETRY_COUNT), по умолчанию система делает до 10 попыток. Если количество попыток исчерпано, но материализованное представление так и не удалось синхронизировать, система прекращает попытки синхронизировать это представление (до перезапуска). После перезапуска системы счетчики попыток по всем представлениям обнуляются, и, если какие-либо представления остались несинхронизированными, система возобновляет попытки их синхронизировать. Пример синхронизации материализованного представления . Рассмотрим пример со следующими условиями: . | логическая БД sales содержит логическую таблицу sales и материализованное представление sales_by_stores; | логическая БД содержит две дельты: . | дельта 0: в таблицу sales загружено две записи; | дельта 1: в таблицу sales загружено еще две записи с другими первичными ключами (новые записи); | . | материализованное представление sales_by_stores содержит результат агрегации и группировки данных таблицы sales и построено на основе запроса: CREATE MATERIALIZED VIEW sales.sales_by_stores ( store_id INT NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, PRIMARY KEY (store_id, product_code) ) DISTRIBUTED BY (store_id) DATASOURCE_TYPE (adg) AS SELECT store_id, product_code, SUM(product_units) as product_units FROM sales.sales WHERE product_code &lt;&gt; 'ABC0001' GROUP BY store_id, product_code DATASOURCE_TYPE = 'adb' . | . На рисунке ниже показан порядок синхронизации материализованного представления sales_by_stores. В каждой дельте рассчитывается и сохраняется сумма по столбцу product_units таблицы sales с группировкой по столбцам store_id и product_code. При этом неважно, когда было создано материализованное представление: до дельты 0, после дельты 1 или в какой-то момент между этими дельтами. Пример синхронизации материализованного представления . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/materialized_view/materialized_view.html",
    "relUrl": "/overview/main_concepts/materialized_view/materialized_view.html"
  },"38": {
    "doc": "Физическая схема данных",
    "title": "Физическая схема данных",
    "content": "Физическая схема данных . Физическая схема данных — структура хранения данных в хранилище, создаваемая и поддерживаемая системой. Для каждой логической таблицы и каждого материализованного представления система создает и поддерживает набор физических таблиц, перечисленных в таблице ниже. Состав набора физических таблиц зависит от типа СУБД хранилища. | Физическая таблица | ADB | ADG | ADQM | ADP | . | &lt;table&gt;_staging | +Горячие записи | +Горячие записи | − | +Горячие записи | . | tbl_buffer | − | − | +Идентификаторы горячих записей | − | . | &lt;table&gt;_actual | +Актуальные и архивные записи | +Актуальные записи | +Горячие, актуальные и архивные записи всех узлов кластера | +Актуальные и архивные записи | . | &lt;table&gt;_history | − | +Архивные записи | − | − | . | &lt;table&gt;_actual_shard | − | − | +Горячие, актуальные и архивные записи узла кластера | − | . | tbl_buffer_shard | − | − | +Идентификаторы горячих записей узла кластера | − | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/physical_schema/physical_schema.html",
    "relUrl": "/overview/main_concepts/physical_schema/physical_schema.html"
  },"39": {
    "doc": "Физическая таблица",
    "title": "Физическая таблица",
    "content": "Физическая таблица . Физическая таблица — таблица СУБД хранилища, каждая запись которой описывает состояние объекта логической таблицы или материализованного представления в определенный период времени. В зависимости от типа физической таблицы состояние объектов, хранящееся в ней, может быть новым (“горячим”), актуальным или архивным. Все данные, загруженные в систему, до фиксации изменений считаются новым состоянием объектов и хранятся в виде горячих записей. При фиксации изменений система одномоментно обновляет состояние объектов, исключая возможность чтения грязных данных. Обновление происходит в следующем порядке: . | Сравниваются новое и актуальное состояния объектов. | Определяется, какие записи нужно добавить (если таких объектов нет среди актуальных данных), а какие — заменить новыми (если объекты уже есть в системе, и нужно обновить их состояние). | Состояние новых объектов фиксируется в виде актуальных записей. | Для существующих объектов записи, которые считались актуальными до момента фиксации изменений, перемещаются в категорию архивных, а новое состояние объектов фиксируется в виде актуальных записей. | Все горячие записи удаляются. | В историю изменений состояния системы добавляется новая дельта с номером, увеличенным на 1 относительно предыдущей зафиксированной дельты. | . На рисунке ниже показан пример обновления состояния объекта логической таблицы clients — набора данных одного клиента. В примере рассматривается следующая ситуация: номер телефона клиента был ранее изменен со значения phone_1 на phone_2, это изменение было зафиксировано, и теперь загружаются данные того же клиента с новым адресом (address_2). Обновление данных клиента . В условиях, рассмотренных в примере, данные клиента обновляются в следующем порядке: . | Загрузка данных: запись с новым адресом (address_2) сохраняется в качестве горячей записи. | Фиксация изменений данных: запись с предыдущим адресом (address_1) переносится в категорию архивных, запись с новым адресом (address_2) — в категорию актуальных, и горячая запись удаляется. Обновление записей происходит одномоментно. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/physical_table/physical_table.html",
    "relUrl": "/overview/main_concepts/physical_table/physical_table.html"
  },"40": {
    "doc": "Сервисная база данных",
    "title": "Сервисная база данных",
    "content": "Сервисная база данных . Сервисная база данных — сервис, используемый ядром системы для хранения метаданных, в частности логической схемы данных и информации о дельтах. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/service_db/service_db.html",
    "relUrl": "/overview/main_concepts/service_db/service_db.html"
  },"41": {
    "doc": "Операция записи",
    "title": "Операция записи",
    "content": "Операция записи . Операция записи — операция загрузки нового состояния объектов из внешнего источника в логическую таблицу. В рамках дельты можно выполнить произвольное количество операций записи. Каждая операция записи имеет порядковый номер, уникальный среди всех операций записи в логической базе данных. Нумерация начинается с 0. Номера операций записи используются в физических таблицах для обозначения границ периода [sys_from, sys_to], в котором запись была актуальна. На рисунке ниже показан пример с тремя операциями записи (0, 1, 2) в двух логических таблицах: clients и sales. В этом примере операции 0 и 2 выполнены по отдельности, однако их изменения могли быть загружены в таблицу clients в рамках одной операции записи. Операции записи в двух логических таблицах . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/overview/main_concepts/write_operation/write_operation.html",
    "relUrl": "/overview/main_concepts/write_operation/write_operation.html"
  },"42": {
    "doc": "Формат выгрузки данных",
    "title": "Формат выгрузки данных",
    "content": "Формат выгрузки данных . Содержание раздела . | Структура сообщений | Формат данных | Примеры . | Пример выгружаемой схемы данных Avro | Пример выгружаемых записей Avro | . | . Структура сообщений . Данные выгружаются из системы в виде сообщений топиков Kafka. Каждое сообщение имеет структуру, показанную на рисунке ниже. Структура выгружаемых сообщений . Формат данных . Данные выгружаются из системы в следующем формате: . | Выгрузка данных выполняется в топик Kafka, указанный в настройках внешней таблицы выгрузки. | Каждое сообщение топика Kafka состоит из ключа и тела. | Тело сообщения представляет собой файл Avro (Object Container File), который состоит из заголовка и блоков данных. | Заголовок файла содержит схему данных Avro. | Схема данных тела сообщения содержит следующие элементы: имя, тип “record” и перечень полей. Для каждого поля указано имя, а также тип данных из числа перечисленных в разделе Выгружаемые типы данных (см. пример ниже). | Каждый блок данных содержит запись, представленную в бинарной кодировке. Запись соответствует схеме данных из заголовка файла Avro. | Каждая запись содержит перечень полей и их значений. Имена и порядок перечисления полей, а также типы данных их значений соответствуют схеме данных (см. пример ниже). | Состав и порядок полей совпадают в следующих объектах: . | во внешней таблице выгрузки, | в схеме данных тела сообщения, | в наборе выгружаемых записей. | . | . Типы данных Avro, доступные к выгрузке из системы, описаны в разделе Выгружаемые типы данных. Подробнее о формате Avro см. в официальной документации на сайте https://avro.apache.org. Примеры . Пример выгружаемой схемы данных Avro . Пример ниже содержит схему данных Avro, выгружаемую с данными о продажах из СУБД ADB. Для наглядности примера бинарные данные представлены в JSON-формате. { \"name\": \"row\", \"type\": \"record\", \"fields\": [ { \"name\": \"id\", \"type\": \"long\" }, { \"name\": \"transaction_date\", \"type\": \"long\" }, { \"name\": \"product_code\", \"type\": \"string\" }, { \"name\": \"product_units\", \"type\": \"long\" }, { \"name\": \"store_id\", \"type\": \"long\" }, { \"name\": \"description\", \"type\": \"string\" } ] } . Пример выгружаемых записей Avro . В примере ниже показан набор записей Avro о продажах, выгруженных из СУБД ADB и соответствующих схеме из предыдущего примера. Для наглядности примера бинарные данные представлены в JSON-формате. [ { \"id\": 1000111, \"transaction_date\": 1614269474000000, \"product_code\": \"ABC102101\", \"product_units\": 2, \"store_id\": 1000012345, \"description\": \"Покупка по акции 1+1\" }, { \"id\": 1000112, \"transaction_date\": 1614334214000000, \"product_code\": \"ABC102001\", \"product_units\": 1, \"store_id\": 1000000123, \"description\": \"Покупка без акций\" } ] . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/download_format/download_format.html",
    "relUrl": "/reference/download_format/download_format.html"
  },"43": {
    "doc": "Формат пути к внешнему приемнику данных",
    "title": "Формат пути к внешнему приемнику данных",
    "content": "Формат пути к внешнему приемнику данных . При создании внешних таблиц загрузки и выгрузки данных необходимо указать путь (URI-строку) к внешнему приемнику данных, из которого извлекаются или в который помещаются данные. Для обоих типов внешних таблиц используется одинаковый формат URI-строки. Доступны следующие способы указания пути к топику Kafka, расположенному на узлах кластера Zookeeper: . | полный путь к топику, | путь к топику с использованием переменной, определенной в конфигурации системы. | . Указание полного пути к топику . Чтобы указать полный путь к топику Kafka, задайте URI-строку в следующем формате: . kafka://zkhost_1:port_1,zkhost_2:port_2,zkhost_3:port_3/chroot/path/topic_name . Где: . | zkhost_N (обязательный) — имя хоста или IP-адрес хоста Zookeeper, к которому подключен брокер сообщений Kafka; | port_N (обязательный) — порт хоста Zookeeper, к которому подключен брокер сообщений Kafka. Должен соответствовать порту, заданному в конфигурации Zookeeper для подключения клиентов (по умолчанию — 2181); | chroot/path — путь chroot к метаданным кластера Kafka. Следует использовать при наличии нескольких узлов Kafka в одном кластере Zookeeper; | topic_name (обязательный) — имя топика Kafka. | . Примеры . Имена нескольких хостов с непустым путем chroot (chroot_kafka): . kafka://zk1:2181,zk2:2181,zk3:2181/chroot_kafka/sales . IP-адрес одного хоста: . kafka://192.168.60.97:2181/chroot_kafka/sales . Указание пути к топику с использованием переменной . Чтобы указать путь к топику Kafka с использованием переменной конфигурации, задайте URI-строку в следующем формате: . kafka://$kafka/topic_name . Пример . Пример пути к топику sales: . kafka://$kafka/sales . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/path_to_kafka_topic/path_to_kafka_topic.html",
    "relUrl": "/reference/path_to_kafka_topic/path_to_kafka_topic.html"
  },"44": {
    "doc": "Справочная информация",
    "title": "Справочная информация",
    "content": "Справочная информация . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/reference.html",
    "relUrl": "/reference/reference.html"
  },"45": {
    "doc": "ALTER VIEW",
    "title": "ALTER VIEW",
    "content": "ALTER VIEW . Запрос позволяет изменить вид логического представления в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Примечание: логическое представление можно также изменить с помощью запроса CREATE OR REPLACE VIEW (см. CREATE VIEW). Синтаксис . ALTER VIEW [db_name.]view_name AS SELECT query . Параметры . | db_name — имя логической базы данных, в которой находится логическое представление. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя изменяемого логического представления; | query — SELECT-подзапрос, на основе которого строится новый вид логического представления. | . Ограничения . В подзапросе query не допускается использование: . | логических представлений, | системных представлений INFORMATION_SCHEMA, | ключевого слова FOR SYSTEM_TIME, | ключевого слова DATASOURCE_TYPE. | . Пример . ALTER VIEW sales.stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales.sales GROUP BY store_id ORDER BY product_amount ASC LIMIT 20 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/ALTER_VIEW/ALTER_VIEW.html"
  },"46": {
    "doc": "BEGIN DELTA",
    "title": "BEGIN DELTA",
    "content": "BEGIN DELTA . Запрос позволяет открыть новую горячую дельту для последующей загрузки данных. Номер открываемой дельты может быть указан в запросе или установлен системой. Примечание: перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о номере открытой дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса открывается новая дельта. Дельта получает номер, указанный в запросе (если номер указан и корректен) или определенный системой (если номер не указан). Дельта всегда открывается с номером, следующим по порядку за номером последней закрытой дельты. После успешного выполнения запроса можно выполнять запросы INSERT INTO logical_table на загрузку данных. Подробнее о порядке выполнения запросов для загрузки данных см. в разделе Загрузка данных. Если нужно отменить все изменения данных, загруженные в рамках открытой дельты, выполните запрос ROLLBACK DELTA. Синтаксис . Открытие новой дельты: . BEGIN DELTA . Открытие новой дельты с указанным номером: . BEGIN DELTA SET delta_number . Параметры . | delta_number — целочисленный номер открываемой дельты, равный номеру последней закрытой дельты + 1. Номер последней закрытой дельты можно узнать с помощью запроса GET_DELTA_OK. | . Ограничения . Если в запросе указан номер открываемой дельты, он должен быть равен номеру последней закрытой дельты + 1. Пример . BEGIN DELTA SET 10 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/BEGIN_DELTA/BEGIN_DELTA.html",
    "relUrl": "/reference/sql_plus_requests/BEGIN_DELTA/BEGIN_DELTA.html"
  },"47": {
    "doc": "CHECK_DATA",
    "title": "CHECK_DATA",
    "content": "CHECK_DATA . Содержание раздела . | Синтаксис | Ограничения | Примеры . | Запрос без перечисления столбцов | Запрос с перечислением столбцов | Запрос с коэффициентом нормализации | . | Порядок проверки данных | Порядок расчета контрольной суммы . | Пример расчета контрольной суммы | . | . Запрос позволяет проверить идентичность данных логической таблицы во всех СУБД хранилища. Данные проверяются по дельтам в обратном порядке: с последней закрытой дельты до указанной в запросе (обе дельты включительно). При первом найденном расхождении система останавливает проверку и возвращает сообщение о расхождении в данных. В проверке участвуют все СУБД хранилища, в которых есть данные логической таблицы, указанной в запросе. Если такая СУБД одна, проверка все равно проходит и считается успешной. В ответе возвращается: . | объект ResultSet с одной записью, содержащей результат проверки, при успешном выполнении запроса. Результат включает список проверенных дельт, где для каждой указано сообщение об успешной проверке или найденном расхождении; | исключение при неуспешном выполнении запроса. | . Порядок проверки зависит от параметров запроса: . | если указаны столбцы к проверке, система сверяет контрольные суммы загруженных записей в каждой дельте; | иначе — система сверяет количество загруженных записей в каждой дельте. | . Подробнее о порядке проверки см. в секции Порядок проверки данных, о расчете контрольной суммы — в секции Порядок расчета контрольной суммы. Синтаксис . CHECK_DATA([db_name.]table_name, delta_number[, normalization][, square-bracketed_column_list]) . Параметры: . | db_name (опциональный) — имя логической базы данных, в которой находится проверяемая логическая таблица. Параметр опционален, если выбрана логическая БД, используемая по умолчанию; | table_name — имя проверяемой логической таблицы; | delta_number — номер дельты, с которой начинается проверка. Должен быть меньше или равен номеру последней закрытой дельты. Номер последней закрытой дельты можно узнать с помощью запроса GET_DELTA_OK; | normalization (опциональный) — коэффициент, который повышает максимально допустимое количество записей в дельте, но снижает уникальность контрольных сумм. Может принимать любое положительное целочисленное значение, начиная с 1. Значение по умолчанию — 1. Если коэффициент не указан или равен 1, каждая из проверяемых дельт может содержать до 4'294'967'298 записей; при увеличении коэффициента допустимое количество записей увеличивается пропорционально. Если количество записей в какой-либо из дельт больше допустимого, в ответе возвращается исключение; | square_bracketed_column_list (опциональный) — список проверяемых столбцов таблицы. Элементы списка должны быть указаны в квадратных скобках через запятую, например [id, transaction_date]. Если столбцы указаны, проверяется контрольная сумма загруженных записей в каждой дельте, иначе — количество таких записей. | . Ограничения . | Существует математическая вероятность получения одинаковых контрольных сумм для разных наборов записей, поэтому возможен ложноположительный результат проверки. | Максимальное количество записей в дельте, для которых контрольная сумма рассчитывается корректно, пропорционально коэффициенту нормализации. Если коэффициент не указан или равен 1, проверяемая дельта может содержать до 4'294'967'298 записей; при увеличении коэффициента допустимое количество записей также увеличивается. | . Примеры . Запрос без перечисления столбцов . Проверка целостности данных логической таблицы stores75 в диапазоне [дельта 0, последняя закрытая дельта]: . CHECK_DATA(sales.stores75, 0) . На рисунке ниже показан пример ответа CHECK_DATA при успешной проверке логической таблицы stores75, данные которой размещены только в ADB. Ответ CHECK_DATA с проверкой только в ADB . Запрос с перечислением столбцов . Проверка целостности данных столбцов id, transaction_date и product_code таблицы sales: . CHECK_DATA(sales.sales, 10, [id, transaction_date, product_code]) . На рисунке ниже показан пример ответа на запрос CHECK_DATA по столбцам таблицы при наличии расхождений: контрольная сумма дельты 10 в ADB отличается от контрольной суммы в ADG и ADQM. Ответ CHECK_DATA с найденными расхождениями . Запрос с коэффициентом нормализации . Проверка целостности данных некоторых столбцов таблицы sales с коэффициентом нормализации 100: . CHECK_DATA(sales.sales, 12, 100, [id, transaction_date, product_code]) . На рисунке ниже показан пример ответа на такой запрос. Запрос CHECK_DATA с коэффициентом нормализации . Порядок проверки данных . Идентичность данных проверяется в следующем порядке: . | В каждой из целевых СУБД: . | Выбираются проверяемые дельты: от указанной в запросе до последней закрытой (обе включительно). | По каждой дельте выбираются все записи, загруженные в логическую таблицу, которая указана в запросе. | По каждой дельте — в зависимости от наличия/отсутствия столбцов в запросе — рассчитывается контрольная сумма или количество загруженных записей. Порядок расчета контрольной суммы см. ниже. | . | Значения по каждой дельте сравниваются в целевых СУБД. | Если значение по одной из дельт отсутствует или не соответствует другим, для нее в ответе возвращается сообщение о расхождении в данных. Иначе по всем дельтам возвращаются сообщения об успешной проверке. | . Порядок расчета контрольной суммы . Контрольная сумма логической таблицы в дельте рассчитывается в следующем порядке: . | По каждой записи, загруженной в логическую таблицу в этой дельте: . | Формируется текстовая строка: значения столбцов конвертируются в зависимости от типа данных (см. таблицу ниже) и записываются через точку с запятой. Значение NULL записывается как пустая строка. | Для полученной строки вычисляется MD5-хеш в виде байтовой последовательности в шестнадцатеричном формате. | Хеш интерпретируется как ASCII-строка в нижнем регистре. | Выбираются первые 4 символа строки, выстраиваются в порядке от младшего к старшему (little endian) и конвертируются в целое 32-битное число. | Полученное число делится на коэффициент нормализации, дробная часть результата отбрасывается — получается контрольная сумма записи. | . | Контрольные суммы всех записей в дельте суммируются — получается 64-битная контрольная сумма таблицы в дельте. | . В таблице ниже показано, как значения столбцов (column_value), указанных в запросе, конвертируются в зависимости от их типа данных. | Тип данных | Порядок конвертации | Пример | . | BOOLEAN | (column_value)::int | true -&gt; 1 | . | DATE | column_value - make_date(1970, 01, 01) | 2021-03-15 -&gt; 18701 | . | TIME | (extract(epoch from column_value)*1000000)::bigint | 13:01:44 -&gt; 46904000000 | . | TIMESTAMP | (extract(epoch from column_value)*1000000)::bigint | 2020-11-17 21:11:12 -&gt; 1605647472000000 | . | Другие типы данных | column_value | Иванов -&gt; Иванов | . Пример расчета контрольной суммы . Рассмотрим пример расчета контрольной суммы таблицы sales в дельте, в которой была загружена одна запись со следующими значениями: . | id = 10021, | transaction_date = 2020-11-17 21:11:12, | product_code = ABC1830. | . В качестве коэффициента нормализации возьмем число 10. Контрольная сумма таблицы рассчитывается в следующем порядке: . | Формируется строка для хеш-функции: 10021;1605647472000000;ABC1830. | Вычисляется MD5-хеш: bedbead6aea8ca373d8f0a15713639c1. | Выбираются первые 4 символа хеша: bedb. | Символы интерпретируются как ASCII-строка в нижнем регистре: 98 101 100 98. | Строка конвертируется в целое 32-битное число: 98*20 + 101*28 + 100*216 + 98*224 = 1650746722. | Полученное значение делится на коэффициент нормализации, остаток отбрасывается: 1650746722 : 10 = 165074672. | . Так как запись в дельте одна, контрольная сумма таблицы в этой дельте равна полученной контрольной сумме записи (165074672). ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CHECK_DATA/CHECK_DATA.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_DATA/CHECK_DATA.html"
  },"48": {
    "doc": "CHECK_DATABASE",
    "title": "CHECK_DATABASE",
    "content": "CHECK_DATABASE . Содержание раздела . | Синтаксис | Параметры | Примеры | . Запрос позволяет проверить соответствие логических таблиц логической базы данных и их физических представлений — физических таблиц в хранилище данных. В проверке участвуют логические таблицы логической базы данных и все связанные с ними физические таблицы. Если СУБД хранилища не хранит данные логической таблицы, и, следовательно, не содержит связанные физические таблицы, она пропускается при проверке логической таблицы. Проверяется соответствие следующих элементов: . | имен и порядка следования столбцов, | типов данных столбцов, | первичного ключа. | . Имена и порядок следования проверяются для всех столбцов логических и физических таблиц, включая служебные столбцы, имеющиеся только у физических таблиц. Например, если служебный столбец sys_to удален из физической таблицы, в ответе вернется сообщение о расхождении. В ответе возвращается: . | объект ResultSet с одной записью, содержащей результаты проверки, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает сообщение об успешной проверке или найденных расхождениях, а также список проверенных СУБД хранилища. Примеры запросов и ответов см. в секции Примеры. Синтаксис . Проверка логической базы данных, выбранной по умолчанию: . CHECK_DATABASE() . Проверка указанной логической базы данных: . CHECK_DATABASE(db_name) . Параметры . | db_name — имя логической базы данных, для таблиц которой выполняется проверка. | . Примеры . Проверка логической базы данных sales: . CHECK_DATABASE(sales) . На рисунках ниже показаны примеры ответов: на первом — ответ при отсутствии расхождений, на втором — при наличии расхождений. Расхождения вызваны тем, что в целях иллюстрации между первым и вторым запросом столбец description одной из таблиц был переименован в ADB. Ответ CHECK_DATABASE при успешной проверке . Ответ CHECK_DATABASE с найденными расхождениями . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CHECK_DATABASE/CHECK_DATABASE.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_DATABASE/CHECK_DATABASE.html"
  },"49": {
    "doc": "CHECK_SUM",
    "title": "CHECK_SUM",
    "content": "CHECK_SUM . Содержание раздела . | Синтаксис | Ограничения | Примеры . | Запрос по некоторым столбцам логической таблицы | Запрос по всем столбцам логической таблицы | Запрос по всем столбцам материализованного представления | Запрос по логической базе данных | Запрос по логической базе данных с коэффициентом нормализации | . | Порядок расчета контрольных сумм . | Расчет контрольной суммы по логической таблице (материализованному представлению) | Расчет контрольной суммы по логической базе данных | Пример расчета контрольной суммы по таблице | . | . Запрос позволяет рассчитать контрольную сумму данных в указанной дельте. Дельта может быть любой: как закрытой, так и открытой (горячей). Расчет контрольной суммы возможен по следующим данным: . | отдельным столбцам логической таблицы или материализованного представления, | всем столбцам логической таблицы или материализованного представления, | всем логическим таблицам логической базы данных. | . Контрольная сумма рассчитывается по каждой СУБД хранилища, в которой размещаются данные проверяемой логической сущности. Расчет выполняется в порядке, описанном ниже. Если контрольные суммы логической сущности различаются между СУБД хранилища, в ответе возвращается исключение Consistency breach detected for &lt;entity_name&gt; с перечислением контрольных сумм сущности во всех проверенных СУБД. При расчете контрольной суммы по логической БД система останавливает расчет и возвращает исключение при первом найденном расхождении. В ответе возвращается: . | объект ResultSet с одной записью, содержащей контрольную сумму данных, при успешном выполнении запроса и отсутствии расхождений между СУБД хранилища; | исключение при наличии расхождений или неуспешном выполнении запроса. | . Синтаксис . CHECK_SUM(delta_num[, normalization][, [db_name.]entity_name[, square-bracketed_column_list]]) . Параметры: . | delta_num — номер открытой (горячей) или закрытой дельты, в которой рассчитывается контрольная сумма таблицы, представления или логической БД. Если других аргументов в запросе нет, контрольная сумма рассчитывается по всем логическим таблицам логической БД; | normalization (опциональный) — коэффициент, который повышает максимально допустимое количество записей таблицы (или представления) в дельте, но снижает уникальность контрольных сумм. Может принимать любое положительное целочисленное значение, начиная с 1. Значение по умолчанию — 1. Если коэффициент не указан или равен 1, проверяемая таблица (представление) может содержать до 4'294'967'298 записей в дельте; при увеличении коэффициента допустимое количество записей увеличивается пропорционально. Если количество записей какой-либо таблицы (или представления) в дельте больше допустимого, в ответе возвращается исключение; | entity_name (опциональный) — имя логической таблицы или материализованного представления, по которым рассчитывается контрольная сумма; | square-bracketed_column_list (опциональный) — список имен столбцов указанной таблицы или представления, по которым рассчитывается контрольная сумма. Элементы списка перечисляются внутри квадратных скобок через запятую. Если список столбцов не указан, контрольная сумма рассчитывается по всем столбцам логической таблицы или материализованного представления. | . Ограничения . | Контрольная сумма логической базы данных рассчитывается только по данным логических таблиц и не учитывает данные материализованных представлений. | Существует математическая вероятность получения одинаковых контрольных сумм для разных наборов данных. | Максимально допустимое количество записей таблицы (или представления) в дельте, для которых контрольная сумма рассчитывается корректно, пропорционально коэффициенту нормализации. Если коэффициент не указан или равен 1, каждая из проверяемых таблиц или представлений может содержать до 4'294'967'298 записей в дельте; при увеличении коэффициента допустимое количество записей также увеличивается. | . Примеры . Запрос по некоторым столбцам логической таблицы . Расчет контрольной суммы по трем столбцам таблицы sales в десятой дельте: . CHECK_SUM(10,sales.sales,[id, transaction_date, product_code]) . На рисунках ниже показаны примеры ответов на запрос CHECK_SUM с перечислением столбцов: на первом — ответ при отсутствии расхождений в данных между СУБД хранилища, на втором — ответ при наличии расхождений. Ответ CHECK_SUM по указанным столбцам таблицы при отсутствии расхождений . Ответ CHECK_SUM при наличии расхождений . Запрос по всем столбцам логической таблицы . Расчет контрольной суммы по всей таблице sales в десятой дельте: . CHECK_SUM(10,sales.sales) . На рисунке ниже показан пример ответа на запрос CHECK_SUM по логической таблице. Ответ CHECK_SUM по логической таблице . Запрос по всем столбцам материализованного представления . Расчет контрольной суммы по всему материализованному представлению sales_by_stores в десятой дельте: . CHECK_SUM(10,sales.sales_by_stores) . Запрос по логической базе данных . Расчет контрольной суммы по всей логической базе данных sales в десятой дельте: . USE sales CHECK_SUM(10) . На рисунке ниже показан пример ответа на запрос CHECK_SUM по логической базе данных. Ответ CHECK_SUM по логической базе данных . Запрос по логической базе данных с коэффициентом нормализации . Расчет контрольной суммы по логической базе данных sales с коэффициентом нормализации, равным 100: . USE sales CHECK_SUM(7, 100) . На рисунке ниже показан пример ответа на такой запрос. Запрос CHECK_SUM с коэффициентом нормализации . Порядок расчета контрольных сумм . Расчет контрольной суммы по логической таблице (материализованному представлению) . Контрольная сумма логической таблицы или материализованного представления рассчитывается, как описано в разделе CHECK_DATA. Расчет контрольной суммы по логической базе данных . Контрольная сумма логической базы данных рассчитывается в следующем порядке: . | По каждой логической таблице логической БД рассчитывается контрольная сумма, как описано в разделе CHECK_DATA. | Контрольные суммы всех логических таблиц суммируются — получается 64-битная контрольная сумма логической базы данных. | . Пример расчета контрольной суммы по таблице . Рассмотрим пример расчета контрольной суммы по таблице sales в дельте, содержащей две операции записи. Для простоты примера по каждой из записей возьмем заранее рассчитанную 32-битную контрольную сумму: 165074672 (см. пример расчета в разделе CHECK_DATA) и 87891666. Контрольная сумма таблицы равна 165074672 + 87891666 = 252966338. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CHECK_SUM/CHECK_SUM.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_SUM/CHECK_SUM.html"
  },"50": {
    "doc": "CHECK_TABLE",
    "title": "CHECK_TABLE",
    "content": "CHECK_TABLE . Содержание раздела . | Синтаксис | Параметры | Примеры . | Ответ при успешной проверке | Ответ при наличии расхождений | . | . Запрос позволяет проверить соответствие логической таблицы и ее физических представлений — физических таблиц в хранилище данных. В проверке участвуют указанная логическая таблица и все связанные с ней физические таблицы. Если СУБД хранилища не хранит данные логической таблицы, и, следовательно, не содержит связанные физические таблицы, она пропускается при проверке. Проверяется соответствие следующих элементов: . | имен и порядка следования столбцов, | типов данных столбцов, | первичного ключа. | . Имена и порядок следования проверяются для всех столбцов логической и физических таблиц, включая служебные столбцы, имеющиеся только у физических таблиц. Например, если служебный столбец sys_to удален из физической таблицы, в ответе вернется сообщение о расхождении. В ответе возвращается: . | объект ResultSet с одной записью, содержащей результаты проверки, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает сообщение об успешной проверке или найденных расхождениях, а также список проверенных СУБД хранилища. Примеры запросов и ответов см. в секции Примеры. Синтаксис . CHECK_TABLE([db_name.]table_name) . Параметры . | db_name — имя логической базы данных, которой принадлежит проверяемая логическая таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя проверяемой логической таблицы. | . Примеры . Проверка логической таблицы sales.sales: . CHECK_TABLE(sales.sales) . Ответ при успешной проверке . На рисунках ниже показаны примеры ответов в случае успешной проверки: на первом рисунке — по таблице, данные которой размещены во всех СУБД хранилища, на втором — по таблице, данные которой размещены только в ADB. Ответ CHECK_TABLE при успешной проверке . Ответ CHECK_TABLE с проверкой только в ADB . Ответ при наличии расхождений . На рисунке ниже показан пример ответа при наличии расхождений, которые вызваны тем, что в физической таблице ADB отсутствует столбец description. Ответ CHECK_TABLE с найденными расхождениями . На рисунке ниже показан пример ответа при наличии расхождений, которые вызваны тем, что логическая таблица, размещаемая в ADB, была логически пересоздана для ADB, ADP и ADQM. Подробнее о пересоздании логической таблицы только на логическом уровне см. в секции LOGICAL_ONLY раздела CREATE TABLE. Ответ CHECK_TABLE с найденными расхождениями . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CHECK_TABLE/CHECK_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_TABLE/CHECK_TABLE.html"
  },"51": {
    "doc": "CHECK_VERSIONS",
    "title": "CHECK_VERSIONS",
    "content": "CHECK_VERSIONS . Запрос позволяет получить информацию о версиях следующих программных компонентов: . | компонентов системы, | компонентов, с которыми работает система. | . В ответе возвращается: . | объект ResultSet с записями, содержащими информацию об именах и версиях компонентах, при успешном выполнении запроса (см. рисунок ниже); | исключение при неуспешном выполнении запроса. | . Ответ CHECK_VERSIONS . Синтаксис . CHECK_VERSIONS() . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CHECK_VERSIONS/CHECK_VERSIONS.html",
    "relUrl": "/reference/sql_plus_requests/CHECK_VERSIONS/CHECK_VERSIONS.html"
  },"52": {
    "doc": "COMMIT DELTA",
    "title": "COMMIT DELTA",
    "content": "COMMIT DELTA . Запрос позволяет закрыть открытую (горячую) дельту. Дата и время закрытия дельты могут быть указаны в запросе или установлены системой. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дате и времени закрытия дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса горячие записи дельты перемещаются в категорию актуальных, а зафиксированные ранее записи, которые больше не являются актуальными, — в категорию архивных. Дельта закрывается и становится недоступна для загрузки данных. Подробнее о порядке обновления записей см. в разделе Физическая таблица. В качестве даты и времени закрытия дельты устанавливаются дата и время, указанные в запросе (если они указаны и корректны) или определенные системой (если дата и время не указаны). Синтаксис . Закрытие открытой дельты: . COMMIT DELTA . Закрытие открытой дельты с указанными датой и временем закрытия: . COMMIT DELTA SET date_time_expression . Параметры . | date_time_expression — метка даты и времени вида 'YYYY-MM-DD hh:mm:ss'. Возможные форматы см. в разделе Форматы даты и времени. | . Ограничения . Если в запросе указаны дата и время закрытия дельты, они должны быть больше, чем дата и время последней закрытой дельты. Дату и время последней закрытой дельты можно узнать, выполнив запрос GET_DELTA_OK. Пример . COMMIT DELTA SET '2021-03-21 09:29:54' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/COMMIT_DELTA/COMMIT_DELTA.html",
    "relUrl": "/reference/sql_plus_requests/COMMIT_DELTA/COMMIT_DELTA.html"
  },"53": {
    "doc": "CONFIG_STORAGE_ADD",
    "title": "CONFIG_STORAGE_ADD",
    "content": "CONFIG_STORAGE_ADD . Запрос позволяет подключить к системе источник данных — СУБД указанного типа. После успешного выполнения запроса можно создавать логические таблицы с размещением данных в этой СУБД и загружать данные в нее. Примечание: перед выполнением запроса необходимо добавить параметры СУБД в конфигурацию системы. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса все логические базы данных окружения активируются для указанной СУБД хранилища. При этом копирование логических таблиц и их данных из других СУБД хранилища не происходит и не может быть выполнено средствами системы. Синтаксис . CONFIG_STORAGE_ADD('datasource_alias') . Параметры . | datasource_alias — псевдоним СУБД хранилища. Возможные значения: adb, adqm, adg, adp. | . Пример . Подключение ADB к хранилищу: . CONFIG_STORAGE_ADD('adb') . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CONFIG_STORAGE_ADD/CONFIG_STORAGE_ADD.html",
    "relUrl": "/reference/sql_plus_requests/CONFIG_STORAGE_ADD/CONFIG_STORAGE_ADD.html"
  },"54": {
    "doc": "CREATE DATABASE",
    "title": "CREATE DATABASE",
    "content": "CREATE DATABASE . Запрос позволяет создать логическую базу данных в текущем окружении. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Совет: перед работой с логической базой данных выберите ее в качестве используемой по умолчанию — это позволит обращаться к логическим сущностям без имени логической БД. Синтаксис . Создание логической БД: . CREATE DATABASE db_name . Создание логической БД только на логическом уровне: . CREATE DATABASE db_name LOGICAL_ONLY . Где: . | db_name — имя создаваемой логической базы данных. Может содержать латинские буквы, цифры и символы подчеркивания (“_”). | . Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет создать логическую базу данных только на логическом уровне (в логической схеме данных), без пересоздания связанной физической базы данных в хранилище данных. Если ключевое слово не указано, создается как логическая, так и связанная с ней физическая база данных. Примеры . Создание логической БД . CREATE DATABASE sales . Создание логической БД только на логическом уровне . CREATE DATABASE sales1 LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CREATE_DATABASE/CREATE_DATABASE.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_DATABASE/CREATE_DATABASE.html"
  },"55": {
    "doc": "CREATE DOWNLOAD EXTERNAL TABLE",
    "title": "CREATE DOWNLOAD EXTERNAL TABLE",
    "content": "CREATE DOWNLOAD EXTERNAL TABLE . Содержание раздела . | Синтаксис | Параметры | Пример | . Запрос позволяет создать внешнюю таблицу выгрузки в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . После успешного выполнения запроса можно выполнять запросы INSERT INTO download_external_table на выгрузку данных. Подробнее о порядке выполнения действий для выгрузки данных см. в разделе Выгрузка данных. Примечание: изменение внешней таблицы недоступно. Для замены внешней таблицы необходимо удалить ее и создать новую. Синтаксис . CREATE DOWNLOAD EXTERNAL TABLE [db_name.]ext_table_name( column_name_1 datatype_1, column_name_2 datatype_2, column_name_3 datatype_3 ) LOCATION receiver_URI FORMAT 'AVRO' [CHUNK_SIZE records_per_message] . Параметры . | db_name — имя логической базы данных, в которой создается внешняя таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя создаваемой внешней таблицы выгрузки. Для удобства различения таблиц выгрузки и таблиц загрузки рекомендуется задавать имя таблицы, указывающее на ее тип, например sales_ext_download; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | receiver_URI — путь к топику Kafka (см. Формат пути к внешнему приемнику данных); | records_per_message — максимальное количество записей, выгружаемых из хранилища в одном сообщении топика Каfka. | . Пример . CREATE DOWNLOAD EXTERNAL TABLE sales.sales_ext_download ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CREATE_DOWNLOAD_EXTERNAL_TABLE/CREATE_DOWNLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_DOWNLOAD_EXTERNAL_TABLE/CREATE_DOWNLOAD_EXTERNAL_TABLE.html"
  },"56": {
    "doc": "CREATE MATERIALIZED VIEW",
    "title": "CREATE MATERIALIZED VIEW",
    "content": "CREATE MATERIALIZED VIEW . Содержание раздела . | Синтаксис . | Ключевое слово DATASOURCE_TYPE | Ключевое слово LOGICAL_ONLY | . | Ограничения | Примеры . | Создание представления на основе одной таблицы с условием | Создание представления на основе одной таблицы с условием, агрегацией и группировкой | Создание представления на основе двух таблиц | Создание представления только на логическом уровне | . | . Запрос позволяет создать материализованное представление в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Для размещения данных материализованного представления только в некоторых СУБД хранилища можно указать ключевое слово DATASOURCE_TYPE (см. секцию Ключевое слово DATASOURCE_TYPE). Примечание: создание материализованных представлений возможно на основе данных ADB с размещением в ADG. Примечание: изменение материализованного представления недоступно. Для замены материализованного представления необходимо удалить его и создать новое. Синтаксис . CREATE MATERIALIZED VIEW [db_name.]materialized_view_name ( column_name_1 datatype_1 NOT NULL, column_name_2 datatype_2 DEFAULT default_value_2, column_name_3 datatype_3, PRIMARY KEY (column_list_1) ) DISTRIBUTED BY (column_list_2) DATASOURCE_TYPE (datasource_aliases) AS SELECT query DATASOURCE_TYPE = origin_datasource_alias [LOGICAL_ONLY] . Где: . | db_name — имя логической базы данных, в которой создается материализованное представление. Параметр опционален, если выбрана логическая БД, используемая по умолчанию; | materialized_view_name — имя создаваемого логического представления, уникальное среди логических сущностей логической БД; | column_name_N — имя столбца представления; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | default_value_N — значение столбца column_name_N по умолчанию; | column_list_1 — список столбцов, входящих в первичный ключ представления; | column_list_2 — список столбцов, входящих в ключ шардирования представления. Столбцы должны быть из числа столбцов column_list_1; | datasource_aliases — список псевдонимов СУБД хранилища, в которых нужно разместить данные представления. Элементы списка перечисляются через запятую. Возможные значения: adg. Значения можно указывать без кавычек (например, adg) или двойных кавычках (например, \"adg\"); | query — SELECT-подзапрос, на основе которого строится представление; | origin_datasource_alias — псевдоним СУБД, которая служит источником данных. Возможные значения: 'adb'. Значение указывается в одинарных кавычках. | . Ключевое слово DATASOURCE_TYPE . Ключевое слово DATASOURCE_TYPE позволяет указать СУБД хранилища, в которых необходимо размещать данные материализованного представления. В текущей версии данные представления могут размещаться только в ADG. Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет создать материализованное представление только на логическом уровне (в логической схеме данных), без пересоздания связанных физических таблиц в хранилище данных. Если ключевое слово не указано, создается как материализованное представление, так и связанные с ним физические таблицы. Ограничения . | Имена столбцов должны быть уникальны в рамках представления. | Столбцы не могут иметь имена, зарезервированные для служебного использования: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Имена, порядок и типы данных столбцов должны совпадать в SELECT-подзапросе и представлении. | Первичный ключ должен включать все столбцы ключа шардирования. | Подзапрос может обращаться только к логическим таблицам и только той логической базы данных, которой принадлежит материализованное представление. | Подзапрос не может содержать следующие элементы: . | ключевое слово FOR SYSTEM_TIME, | ключевое слово ORDER BY. | . | . Примеры . Создание представления на основе одной таблицы с условием . CREATE MATERIALIZED VIEW sales.sales_december_2020 ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adg) AS SELECT * FROM sales.sales WHERE transaction_date BETWEEN '2020-12-01' AND '2020-12-31' DATASOURCE_TYPE = 'adb' . Создание представления на основе одной таблицы с условием, агрегацией и группировкой . CREATE MATERIALIZED VIEW sales.sales_by_stores ( store_id INT NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, PRIMARY KEY (store_id, product_code) ) DISTRIBUTED BY (store_id) DATASOURCE_TYPE (adg) AS SELECT store_id, product_code, SUM(product_units) as product_units FROM sales.sales WHERE product_code &lt;&gt; 'ABC0001' GROUP BY store_id, product_code DATASOURCE_TYPE = 'adb' . Создание представления на основе двух таблиц . CREATE MATERIALIZED VIEW sales.sales_and_stores ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, description VARCHAR(256), store_id INT NOT NULL, store_category VARCHAR(256) NOT NULL, region VARCHAR(256) NOT NULL, PRIMARY KEY (id, region) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adg) AS SELECT s.id, s.transaction_date, s.product_code, s.product_units, s.description, st.id AS store_id, st.category as store_category, st.region FROM sales.sales AS s JOIN sales.stores AS st ON s.store_id = st.id DATASOURCE_TYPE = 'adb' . Создание представления только на логическом уровне . CREATE MATERIALIZED VIEW sales.stores_by_sold_products_matview ( store_id INT NOT NULL, product_amount INT NOT NULL, PRIMARY KEY (store_id) ) DISTRIBUTED BY (store_id) DATASOURCE_TYPE (adg) AS SELECT store_id, SUM(product_units) AS product_amount FROM sales.sales GROUP BY store_id DATASOURCE_TYPE = 'adb' LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_MATERIALIZED_VIEW/CREATE_MATERIALIZED_VIEW.html"
  },"57": {
    "doc": "CREATE TABLE",
    "title": "CREATE TABLE",
    "content": "CREATE TABLE . Содержание раздела . | Синтаксис . | Ключевое слово DATASOURCE_TYPE | Ключевое слово LOGICAL_ONLY | . | Ограничения | Примеры . | Создание таблицы с размещением данных во всех СУБД хранилища | Создание таблицы с составным первичным ключом | Создание таблицы с размещением данных в ADQM и ADG | Создание таблицы только на логическом уровне | . | . Запрос позволяет создать логическую таблицу в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Для размещения данных логической таблицы только в некоторых СУБД хранилища можно указать ключевое слово DATASOURCE_TYPE (см. секцию Ключевое слово DATASOURCE_TYPE). Совет: рекомендуется создавать логическую таблицу с размещением данных, как минимум, в СУБД хранилища, из которой планируется выгрузка данных. Иначе выгрузка данных из таблицы будет недоступна. Подробнее о СУБД, из которых можно выгружать данные, см. в разделе INSERT INTO download_external_table. Примечание: изменение логической таблицы недоступно. Для замены таблицы необходимо удалить ее и создать новую. Синтаксис . CREATE TABLE [db_name.]table_name ( column_name_1 datatype_1 NOT NULL, column_name_2 datatype_2 DEFAULT default_value_2, column_name_3 datatype_3, PRIMARY KEY (column_list_1) ) DISTRIBUTED BY (column_list_2) [DATASOURCE_TYPE (datasource_aliases)] [LOGICAL_ONLY] . Где: . | db_name — имя логической базы данных, в которой создается логическая таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя создаваемой логической таблицы, уникальное среди логических сущностей логической БД; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | default_value_N — значение столбца column_name_N по умолчанию; | column_list_1 — список столбцов, входящих в первичный ключ таблицы; | column_list_2 — список столбцов целочисленного типа, входящих в ключ шардирования таблицы. Столбцы должны быть из числа столбцов column_list_1; | datasource_aliases — список псевдонимов СУБД хранилища, в которых нужно разместить данные таблицы. Элементы списка перечисляются через запятую. Возможные значения: adb, adqm, adg. Значения можно указывать без кавычек (например, adb) или двойных кавычках (например, \"adb\"). | . Ключевое слово DATASOURCE_TYPE . Ключевое слово DATASOURCE_TYPE позволяет указать СУБД хранилища, в которых необходимо размещать данные логической таблицы. Если ключевое слово не указано, данные таблицы размещаются во всех доступных СУБД хранилища. Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет создать логическую таблицу только на логическом уровне (в логической схеме данных), без пересоздания связанных физических таблиц в хранилище данных. Если ключевое слово не указано, создается как логическая, так и связанные с ней физические таблицы. Ограничения . | Имена столбцов должны быть уникальны в рамках логической таблицы. | Недопустимо использование зарезервированных имен столбцов: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Первичный ключ должен включать все столбцы ключа шардирования. | Ключ шардирования может содержать только целочисленные столбцы. | . Примеры . Создание таблицы с размещением данных во всех СУБД хранилища . CREATE TABLE sales.sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) . Создание таблицы с составным первичным ключом . CREATE TABLE sales.stores ( id INT NOT NULL, category VARCHAR(256) NOT NULL, region VARCHAR(256) NOT NULL, address VARCHAR(256) NOT NULL, description VARCHAR(256), PRIMARY KEY (id, region) ) DISTRIBUTED BY (id) . Создание таблицы с размещением данных в ADQM и ADG . CREATE TABLE sales.clients ( id INT NOT NULL, first_name VARCHAR(256) NOT NULL, last_name VARCHAR(256) NOT NULL, patronymic_name VARCHAR(256), birth_date DATE, PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adqm,adg) . Создание таблицы только на логическом уровне . CREATE TABLE sales.sales1 ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CREATE_TABLE/CREATE_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_TABLE/CREATE_TABLE.html"
  },"58": {
    "doc": "CREATE UPLOAD EXTERNAL TABLE",
    "title": "CREATE UPLOAD EXTERNAL TABLE",
    "content": "CREATE UPLOAD EXTERNAL TABLE . Содержание раздела . | Синтаксис | Параметры | Пример | . Запрос позволяет создать внешнюю таблицу загрузки в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . После успешного выполнения запроса можно выполнять запросы INSERT INTO logical_table на загрузку данных. Подробнее о порядке выполнения действий для загрузки данных см. в разделе Загрузка данных. Примечание: изменение внешней таблицы недоступно. Для замены внешней таблицы необходимо удалить ее и создать новую. Синтаксис . CREATE UPLOAD EXTERNAL TABLE [db_name.]ext_table_name ( column_name_1 datatype_1, column_name_2 datatype_2, column_name_3 datatype_3 ) LOCATION source_URI FORMAT 'AVRO' [MESSAGE_LIMIT messages_per_segment] . Параметры . | db_name — имя логической базы данных, в которой создается внешняя таблица. Указание опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя создаваемой внешней таблицы загрузки. Для удобства различения таблиц выгрузки и таблиц загрузки рекомендуется задавать имя таблицы, указывающее на ее тип, например sales_ext_upload; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | source_URI — путь к топику Kafka (см. Формат пути к внешнему приемнику данных); | messages_per_segment — максимальное количество сообщений, загружаемых в хранилище в составе одного блока на один поток загрузки. Значение подбирается в зависимости от параметров производительности инфраструктуры. | . Пример . CREATE UPLOAD EXTERNAL TABLE sales.sales_ext_upload ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CREATE_UPLOAD_EXTERNAL_TABLE/CREATE_UPLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_UPLOAD_EXTERNAL_TABLE/CREATE_UPLOAD_EXTERNAL_TABLE.html"
  },"59": {
    "doc": "CREATE VIEW",
    "title": "CREATE VIEW",
    "content": "CREATE VIEW . Запрос позволяет создать или заменить логическое представление в логической базе данных. Логическое представление можно создать на основе данных одной или нескольких логических таблиц. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . Создание логического представления: . CREATE VIEW [db_name.]view_name AS SELECT query . Создание логического представления с заменой существующего представления, если такое будет найдено: . CREATE OR REPLACE VIEW [db_name.]view_name AS SELECT query . Параметры . | db_name — имя логической базы данных, в которой создается или заменяется логическое представление. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя создаваемого или заменяемого логического представления. В запросе на создание представления имя должно быть уникально среди логических сущностей логической БД; | query — SELECT-подзапрос, на основе которого строится логическое представление. | . Ограничения . В подзапросе query не допускается использование: . | логических представлений, | системных представлений INFORMATION_SCHEMA, | ключевого слова FOR SYSTEM_TIME, | ключевого слова DATASOURCE_TYPE. | . Пример . CREATE VIEW sales.stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales.sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 20 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/CREATE_VIEW/CREATE_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/CREATE_VIEW/CREATE_VIEW.html"
  },"60": {
    "doc": "DROP DATABASE",
    "title": "DROP DATABASE",
    "content": "DROP DATABASE . Запрос позволяет удалить логическую базу данных и все ее данные. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Внимание: при удалении логической базы данных без ключевого слова LOGICAL_ONLY удаляются все ее данные и вся история изменений данных этой логической БД. Удаленные данные не подлежат восстановлению средствами системы. Синтаксис . Удаление логической БД: . DROP DATABASE db_name . Удаление логической БД только на логическом уровне: . DROP DATABASE db_name LOGICAL_ONLY . Где: . | db_name — имя удаляемой логической базы данных. | . Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет удалить логическую базу данных и все ее дочерние логические сущности только на логическом уровне (из логической схемы данных), без удаления связанной физической базы данных и размещенных в ней данных из хранилища данных. Если ключевое слово не указано, удаляется как логическая, так и связанная с ней физическая база данных. Ограничения . Не допускается удаление системной базы данных с именем INFORMATION_SCHEMA. Примеры . Удаление логической БД . DROP DATABASE sales . Удаление логической БД только на логическом уровне . DROP DATABASE sales1 LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/DROP_DATABASE/DROP_DATABASE.html",
    "relUrl": "/reference/sql_plus_requests/DROP_DATABASE/DROP_DATABASE.html"
  },"61": {
    "doc": "DROP DOWNLOAD EXTERNAL TABLE",
    "title": "DROP DOWNLOAD EXTERNAL TABLE",
    "content": "DROP DOWNLOAD EXTERNAL TABLE . Запрос позволяет удалить внешнюю таблицу выгрузки из логической базы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . DROP DOWNLOAD EXTERNAL TABLE [db_name.]ext_table_name . Параметры . | db_name — имя логической базы данных, из которой удаляется внешняя таблица выгрузки. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя удаляемой внешней таблицы выгрузки. | . Пример . DROP DOWNLOAD EXTERNAL TABLE sales.sales_ext_download . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/DROP_DOWNLOAD_EXTERNAL_TABLE/DROP_DOWNLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/DROP_DOWNLOAD_EXTERNAL_TABLE/DROP_DOWNLOAD_EXTERNAL_TABLE.html"
  },"62": {
    "doc": "DROP MATERIALIZED VIEW",
    "title": "DROP MATERIALIZED VIEW",
    "content": "DROP MATERIALIZED VIEW . Содержание раздела . | Синтаксис . | Ключевое слово IF EXISTS | Ключевое слово DATASOURCE_TYPE | Ключевое слово LOGICAL_ONLY | . | Примеры . | Удаление представления с удалением данных из всех СУБД | Удаление представления с проверкой его наличия | Удаление представления с удалением данных из ADG | Удаление представления только на логическом уровне | . | . Запрос позволяет удалить материализованное представление и его данные. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . DROP MATERIALIZED VIEW [IF EXISTS] [db_name.]materialized_view_name [DATASOURCE_TYPE = datasource_alias] [LOGICAL_ONLY] . Где: . | db_name — имя логической базы данных, из которой удаляется материализованное представление. Параметр опционален, если выбрана логическая БД, используемая по умолчанию; | table_name — имя удаляемого материализованного представления; | datasource_alias — псевдоним СУБД хранилища, из которой удаляются данные материализованного представления. Возможные значения: adg. Значение можно указывать без кавычек, в одинарных кавычках (например, 'adg') или двойных кавычках (например, \"adg\"). Если ключевое слово DATASOURCE_TYPE с псевдонимом не указано, данные удаляются из всех СУБД хранилища. | . Ключевое слово IF EXISTS . Ключевое слово IF EXISTS включает проверку наличия материализованного представления до попытки его удаления. Если ключевое слово указано в запросе, система возвращает успешный ответ как по успешно удаленному, так и несуществующему представлению; иначе — только по успешно удаленному представлению. Ключевое слово DATASOURCE_TYPE . Ключевое слово DATASOURCE_TYPE позволяет указать СУБД хранилища, из которых необходимо удалить данные материализованного представления. В текущей версии данные представления могут размещаться только в ADG. Само материализованное представление удаляется из логической схемы данных при удалении его данных из последней СУБД хранилища. Если ключевое слово не указано, данные представления удаляются из всех СУБД хранилища. Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет удалить материализованное представление только на логическом уровне (из логической схемы данных), без удаления связанных физических таблиц и размещенных в них данных из хранилища данных. Если ключевое слово не указано, удаляется как материализованное представление, так и связанные с ним физические таблицы. Примеры . Удаление представления с удалением данных из всех СУБД . DROP MATERIALIZED VIEW sales.sales_and_stores . Удаление представления с проверкой его наличия . DROP MATERIALIZED VIEW IF EXISTS sales.mat_view_with_unknown_existence . Удаление представления с удалением данных из ADG . DROP MATERIALIZED VIEW sales.sales_and_stores DATASOURCE_TYPE = 'adg' . Удаление представления только на логическом уровне . DROP MATERIALIZED VIEW sales.stores_by_sold_products_matview LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/DROP_MATERIALIZED_VIEW/DROP_MATERIALIZED_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/DROP_MATERIALIZED_VIEW/DROP_MATERIALIZED_VIEW.html"
  },"63": {
    "doc": "DROP TABLE",
    "title": "DROP TABLE",
    "content": "DROP TABLE . Содержание раздела . | Синтаксис . | Ключевое слово IF EXISTS | Ключевое слово DATASOURCE_TYPE | Ключевое слово LOGICAL_ONLY | . | Примеры . | Удаление таблицы с удалением данных из всех СУБД | Удаление таблицы и ее данных с проверкой наличия таблицы | Удаление таблицы с удалением данных из ADB и ADG | Удаление таблицы только на логическом уровне | . | . Запрос позволяет удалить логическую таблицу и ее данные. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Для удаления данных логической таблицы только из некоторых СУБД хранилища можно указать ключевое слово DATASOURCE_TYPE (см. секцию Ключевое слово DATASOURCE_TYPE). Внимание: удаленные данные невозможно восстановить средствами системы. Удаление данных из СУБД хранилища, используемых для выгрузки данных, приведет к невозможности выгрузки этих данных. Подробнее о СУБД, из которых можно выгружать данные, см. в разделе INSERT INTO download_external_table. Синтаксис . DROP TABLE [IF EXISTS] [db_name.]table_name [DATASOURCE_TYPE = datasource_alias] [LOGICAL_ONLY] . Где: . | db_name — имя логической базы данных, из которой удаляется логическая таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя удаляемой логической таблицы; | datasource_alias — псевдоним СУБД хранилища, из которой удаляются данные логической таблицы. Возможные значения: adb, adqm, adg, adp. Значение можно указывать без кавычек, в одинарных кавычках (например, 'adb') или двойных кавычках (например, \"adb\"). Если ключевое слово DATASOURCE_TYPE с псевдонимом не указано, данные удаляются из всех СУБД хранилища. | . Ключевое слово IF EXISTS . Ключевое слово IF EXISTS включает проверку наличия логической таблицы до попытки ее удаления. Если ключевое слово указано в запросе, система возвращает успешный ответ как по успешно удаленной, так и несуществующей таблице; иначе — только по успешно удаленной таблице. Ключевое слово DATASOURCE_TYPE . Ключевое слово DATASOURCE_TYPE позволяет указать СУБД хранилища, из которых необходимо удалить данные логической таблицы. Сама логическая таблица удаляется из логической схемы данных при удалении данных таблицы из последней СУБД хранилища. Если ключевое слово не указано, данные таблицы удаляются из всех СУБД хранилища. Ключевое слово LOGICAL_ONLY . Ключевое слово LOGICAL_ONLY позволяет удалить логическую таблицу только на логическом уровне (из логической схемы данных), без удаления связанных физических таблиц и размещенных в них данных из хранилища данных. Если ключевое слово не указано, удаляется как логическая, так и связанные с ней физические таблицы. Примеры . Удаление таблицы с удалением данных из всех СУБД . DROP TABLE sales.sales . Удаление таблицы и ее данных с проверкой наличия таблицы . DROP TABLE IF EXISTS sales.sales_unknown_existence . Удаление таблицы с удалением данных из ADB и ADG . DROP TABLE sales.stores DATASOURCE_TYPE = adb DROP TABLE sales.stores DATASOURCE_TYPE = adg . Удаление таблицы только на логическом уровне . DROP TABLE sales.sales1 LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/DROP_TABLE/DROP_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/DROP_TABLE/DROP_TABLE.html"
  },"64": {
    "doc": "DROP UPLOAD EXTERNAL TABLE",
    "title": "DROP UPLOAD EXTERNAL TABLE",
    "content": "DROP UPLOAD EXTERNAL TABLE . Запрос позволяет удалить внешнюю таблицу загрузки из логической базы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . DROP UPLOAD EXTERNAL TABLE [db_name.]ext_table_name . Параметры . | db_name — имя логической базы данных, из которой удаляется внешняя таблица загрузки. Опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя удаляемой внешней таблицы загрузки. | . Пример . DROP UPLOAD EXTERNAL TABLE sales.sales_ext_upload . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/DROP_UPLOAD_EXTERNAL_TABLE/DROP_UPLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/reference/sql_plus_requests/DROP_UPLOAD_EXTERNAL_TABLE/DROP_UPLOAD_EXTERNAL_TABLE.html"
  },"65": {
    "doc": "DROP VIEW",
    "title": "DROP VIEW",
    "content": "DROP VIEW . Запрос позволяет удалить логическое представление из логической базы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса логическое представление удаляется из логической схемы данных. Синтаксис . DROP VIEW [db_name.]view_name . Параметры . | db_name — имя логической базы данных, из которой удаляется логическое представление. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя удаляемого логического представления. | . Пример . DROP VIEW sales.stores_by_sold_products . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/DROP_VIEW/DROP_VIEW.html",
    "relUrl": "/reference/sql_plus_requests/DROP_VIEW/DROP_VIEW.html"
  },"66": {
    "doc": "GET_DELTA_BY_DATETIME",
    "title": "GET_DELTA_BY_DATETIME",
    "content": "GET_DELTA_BY_DATETIME . Запрос позволяет получить информацию о последней закрытой дельте на указанные дату и время. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дельте, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия дельты, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_BY_DATETIME(date_time_expression) . Параметры . | date_time_expression — момент даты-времени вида 'YYYY-MM-DD hh:mm:ss'. Возможные форматы см. в разделе Форматы даты и времени. | . Пример . GET_DELTA_BY_DATETIME('2021-03-25 07:30:32') . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/GET_DELTA_BY_DATETIME/GET_DELTA_BY_DATETIME.html",
    "relUrl": "/reference/sql_plus_requests/GET_DELTA_BY_DATETIME/GET_DELTA_BY_DATETIME.html"
  },"67": {
    "doc": "GET_DELTA_BY_NUM",
    "title": "GET_DELTA_BY_NUM",
    "content": "GET_DELTA_BY_NUM . Запрос позволяет получить информацию о закрытой дельте по ее номеру. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дельте, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия дельты, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_BY_NUM(delta_num) . Параметры . | delta_num — целый неотрицательный номер дельты. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/GET_DELTA_BY_NUM/GET_DELTA_BY_NUM.html",
    "relUrl": "/reference/sql_plus_requests/GET_DELTA_BY_NUM/GET_DELTA_BY_NUM.html"
  },"68": {
    "doc": "GET_DELTA_HOT",
    "title": "GET_DELTA_HOT",
    "content": "GET_DELTA_HOT . Запрос позволяет получить информацию о горячей дельте. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью при успешном выполнении запроса. Если дельта присутствует, запись содержит информацию о дельте, иначе — возвращается пустая запись; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты; | [cn_from, cn_to] — диапазон порядковых номеров непрерывной последовательности операций записи, выполненных в рамках дельты; | cn_max — максимальный номер операции среди операций записи, выполненных в рамках дельты. До успешного завершения операций записи возвращается максимальный номер операции записи в последней закрытой дельте; | is_rolling_back — флаг отката; | write_op_finished — массив операций записей, выполненных в рамках дельты. | . В связи с многопоточной обработкой операций значения cn_to и cn_max горячей дельты могут отличаться. Например, если в рамках горячей дельты завершены операции записи с номерами 1, 2, 3 и 7, то значение cn_to этой дельты равно 3, а значение cn_max равно 7. Синтаксис . GET_DELTA_HOT() . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/GET_DELTA_HOT/GET_DELTA_HOT.html",
    "relUrl": "/reference/sql_plus_requests/GET_DELTA_HOT/GET_DELTA_HOT.html"
  },"69": {
    "doc": "GET_DELTA_OK",
    "title": "GET_DELTA_OK",
    "content": "GET_DELTA_OK . Запрос позволяет получить информацию о последней закрытой дельте. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью при успешном выполнении запроса. Если дельта присутствует, запись содержит информацию о дельте, иначе — возвращается пустая запись; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_OK() . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/GET_DELTA_OK/GET_DELTA_OK.html",
    "relUrl": "/reference/sql_plus_requests/GET_DELTA_OK/GET_DELTA_OK.html"
  },"70": {
    "doc": "INSERT INTO download_external_table",
    "title": "INSERT INTO download_external_table",
    "content": "INSERT INTO download_external_table . Запрос позволяет выгрузить данные, выбранные SELECT-подзапросом к логической базе данных, во внешний приемник данных. Данные можно выгружать из логических таблиц и логических представлений. Выгрузка данных из материализованных представлений недоступна. Данные можно выгрузить из СУБД хранилища, выбранной для выгрузки данных в конфигурации (см. параметр EDML_DATASOURCE), или любой указанной СУБД хранилища. Если в запросе не указана СУБД для выгрузки, данные выгружаются из СУБД, заданной в конфигурации. Чтобы выгрузить данные из другой СУБД, нужно добавить в запрос ключевое слово DATASOURCE_TYPE с псевдонимом СУБД. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на выгрузку данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса данные выгружаются в том формате и в тот приемник данных, которые были указаны при создании внешней таблицы выгрузки. Формат данных соответствует описанному в разделе Формат выгрузки данных. Примечания: . | Перед выполнением запроса необходимо создать внешнюю таблицу с указанием пути к топику Kafka. Подробнее о порядке выполнения действий для выгрузки данных см. в разделе Выгрузка данных. | Имена и порядок следования столбцов должны совпадать в SELECT-подзапросе на выгрузку данных и внешней таблице выгрузки. | . Синтаксис . INSERT INTO [db_name.]ext_table_name SELECT query . Параметры . | db_name — имя логической базы данных, из которой выгружаются данные. Параметр опционален, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя внешней таблицы выгрузки; | query — SELECT-подзапрос для выбора выгружаемых данных. Если в подзапросе указано ключевое слово DATASOURCE_TYPE с псевдонимом СУБД хранилища, данные выгружаются из этой СУБД, иначе — из СУБД, выбранной для выгрузки в конфигурации системы. | . Ограничения . | Выгружаемые данные должны быть доступны в СУБД хранилища, выбранной для выгрузки. | . Пример . Выгрузка из СУБД, заданной в конфигурации . INSERT INTO sales.sales_ext_download SELECT * FROM sales.sales WHERE sales.product_units &gt; 2 . Выгрузка из указанной СУБД . INSERT INTO sales.stores_ext_download SELECT * FROM sales.stores WHERE region = 'Москва' DATASOURCE_TYPE = 'adqm' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html",
    "relUrl": "/reference/sql_plus_requests/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html"
  },"71": {
    "doc": "INSERT INTO logical_table",
    "title": "INSERT INTO logical_table",
    "content": "INSERT INTO logical_table . Содержание раздела . | Синтаксис | Параметры | Ограничения | Пример | . Запрос позволяет загрузить данные в логическую таблицу логической базы данных из внешнего источника данных. Загружаемые данные должны соответствовать формату, указанному при создании внешней таблицы загрузки и описанному в разделе Формат загрузки данных. Примечание: загрузка данных возможна только в логическую таблицу. Загрузка данных в логические и материализованные представления недоступна. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на загрузку данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса данные загружаются в СУБД хранилища, выбранные для размещения данных таблицы. Месторасположение данных таблицы можно задавать запросами CREATE TABLE и DROP TABLE. Примечания . | Перед выполнением запроса необходимо создать внешнюю таблицу, загрузить данные в топик Kafka и открыть дельту. Подробнее о порядке выполнения действий для загрузки данных см. в разделе Загрузка данных. | Имена и порядок следования столбцов должны совпадать в топике Kafka, внешней таблице загрузке и запросе на загрузку данных. Исключением является служебное поле sys_op, которое обязательно для топика и опционально для внешней таблицы, но должно отсутствовать в запросе на загрузку данных при явном перечислении столбцов. Подробнее о требованиях к загружаемым данным см. в разделе Формат загрузки данных. | . Синтаксис . Запрос с явным перечислением столбцов внешней таблицы: . INSERT INTO [db_name.]table_name SELECT column_list FROM [db_name.]ext_table_name . Запрос с использованием символа *: . INSERT INTO [db_name.]table_name SELECT * FROM [db_name.]ext_table_name . Параметры . | db_name — имя логической базы данных. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя логической таблицы, в которую загружаются данные; | column_list — список имен столбцов внешней таблицы загрузки. Должен включать все имена столбцов логической таблицы. Если внешняя таблица содержит служебное поле sys_op, оно не указывается; | ext_table_name — имя внешней таблицы загрузки. | . Ограничения . Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). Пример . Пример загрузки данных с открытием и закрытием дельты: . -- открытие новой (горячей) дельты BEGIN DELTA -- запуск загрузки данных в логическую таблицу sales INSERT INTO sales.sales SELECT * FROM sales.sales_ext_upload -- закрытие дельты (фиксация изменений) COMMIT DELTA . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/INSERT_INTO_logical_table/INSERT_INTO_logical_table.html",
    "relUrl": "/reference/sql_plus_requests/INSERT_INTO_logical_table/INSERT_INTO_logical_table.html"
  },"72": {
    "doc": "ROLLBACK CRASHED_WRITE_OPERATIONS",
    "title": "ROLLBACK CRASHED_WRITE_OPERATIONS",
    "content": "ROLLBACK CRASHED_WRITE_OPERATIONS . Запрос позволяет перезапустить отмену неуспешных операций записи. При ошибке загрузки данных система автоматически отменяет неуспешную операцию записи и возвращает данные СУБД хранилища в состояние, которое предшествовало загрузке. Однако, если при откате неуспешной операции записи произошла ошибка (например, из-за неполадок в сети или СУБД), система возвращает исключение и запись не отменяется. В этом случае необходимо устранить причины ошибки и вручную перезапустить отмену неуспешных операций записей. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. После выполнения запроса необходимо вызвать ROLLBACK DELTA. В ответе возвращается: . | объект ResultSet с пустой записью, если неуспешные операции записи отсутствуют; | объект ResultSet c записями, каждая из которых содержит имя логической таблицы в столбце table_name и номер отмененной операции записи в столбце sys_cn_operations. | . Синтаксис . ROLLBACK CRASHED_WRITE_OPERATIONS . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/ROLLBACK_CRASHED_WRITE_OPERATIONS/ROLLBACK_CRASHED_WRITE_OPERATIONS.html",
    "relUrl": "/reference/sql_plus_requests/ROLLBACK_CRASHED_WRITE_OPERATIONS/ROLLBACK_CRASHED_WRITE_OPERATIONS.html"
  },"73": {
    "doc": "ROLLBACK DELTA",
    "title": "ROLLBACK DELTA",
    "content": "ROLLBACK DELTA . Запрос позволяет откатить горячую (открытую) дельту — отменить все изменения горячей дельты и вернуть логическую базу данных в состояние, актуальное на момент последней закрытой дельты. При откате отменяются все операции записи горячей дельты: как завершенные, так и еще выполняемые. Внимание: после запуска запроса невозможно закрыть горячую дельту и зафиксировать ее изменения, даже если система не смогла откатить дельту и вернула исключение. При наличии множества параллельных операций записи система не всегда может отменить все операции за один проход. Если запрос вернул исключение Can't rollback delta by datamart &lt;db_name&gt;, это означает, что системе не удалось отменить все операции записи горячей дельты. В этом случае необходимо повторить запрос один или несколько раз: до получения в ответе номера последней закрытой дельты вместо исключения. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. Примечание: откат закрытой дельты невозможен. Откат горячей дельты выполняется в следующем порядке: . | Останавливаются все выполняемые операции записи. Операции останавливаются асинхронно, и система периодически проверяет, остались ли выполняемые операции записи. Проверка запускается раз в интервал, заданный в конфигурации с помощью параметра DELTA_ROLLBACK_STATUS_CALLS_MS. | Отменяются все операции записи горячей дельты: остановленные, завершенные успешно и завершенные с ошибкой. При этом отменяются все связанные изменения данных. | Горячая дельта удаляется из сервисной базы данных, и зарезервированный ранее номер горячей дельты освобождается. | . В ответе возвращается: . | объект ResultSet c одной записью, содержащей номер последней закрытой дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . ROLLBACK DELTA . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/ROLLBACK_DELTA/ROLLBACK_DELTA.html",
    "relUrl": "/reference/sql_plus_requests/ROLLBACK_DELTA/ROLLBACK_DELTA.html"
  },"74": {
    "doc": "SELECT",
    "title": "SELECT",
    "content": "SELECT . Содержание раздела . | Синтаксис . | Поддерживаемые ключевые слова | Ключевое слово FOR SYSTEM_TIME | Поддерживаемые типы соединений (префиксы JOIN) | Ключевое слово OFFSET | Ключевое слово ESTIMATE_ONLY | . | Ограничения | Примеры . | Звездочка и WHERE | DATASOURCE_TYPE | GROUP BY, ORDER BY и LIMIT | ESTIMATE_ONLY | OFFSET | ORDER BY, LIMIT и OFFSET | FOR SYSTEM_TIME AS OF DELTA_NUM | Соединение таблиц из разных логических БД | Соединение изменений из разных дельт | . | . Запрос позволяет выбрать данные из логических таблиц, логических представлений и (или) материализованных представлений или получить информацию о запросе к данным. Возможен запрос к срезу данных на указанный момент времени. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на чтение данных. В ответе возвращается: . | объект ResultSet c выбранными записями или информацией о запросе при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Запрос также можно использовать как подзапрос в следующих запросах: . | на выгрузку данных, | на создание или обновление логического представления, | на создание материализованного представления. | . Синтаксис . SELECT column_list FROM [db_name.]entity_name [FOR SYSTEM_TIME time_expression [AS alias_name]] [DATASOURCE_TYPE = datasource_alias] [ESTIMATE_ONLY] . Где: . | column_list — список выбираемых столбцов таблицы или представления. Можно указывать символ * для выбора всех столбцов; | db_name — имя логической базы данных, из которой выбираются данные. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | entity_name — имя таблицы или представления, из которого выбираются данные; | time_expression — выражение, задающее момент или период времени, за который выбираются данные или изменения данных. Синтаксис выражения см. ниже; | alias_name — псевдоним таблицы или представления. Может включать латинские буквы, цифры и символы подчеркивания; | datasource_alias — системный псевдоним СУБД хранилища, из которой выбираются данные. Возможные значения: 'adb', 'adqm', 'adg', 'adp'. | . В запросах можно указывать: . | ключевые слова, перечисленные в секции Поддерживаемые ключевые слова, | функции, перечисленные в разделе Поддержка SQL, | псевдонимы для имен таблиц, представлений и столбцов. | . Примечание: некоторые агрегатные функции и типы соединений недоступны для исполнения в определенных СУБД хранилища. Список доступных возможностей см. в разделе Поддержка SQL. Поддерживаемые ключевые слова . В запросе можно использовать следующие ключевые слова, которые должны быть указаны в порядке их перечисления: . | FOR SYSTEM_TIME — для указания момента времени или периода, за который выбираются данные или изменения данных. Если ключевое слово не указано, из логической таблицы и логического представления выбираются данные, актуальные на момент обработки запроса, из материализованного представления — данные, актуальные на момент последней синхронизации представления. Описание синтаксиса см. в секции Ключевое слово FOR SYSTEM_TIME; | JOIN ON — для соединения данных нескольких логических таблиц и (или) представлений из одной или нескольких логических БД. Возможные префиксы см. в секции Возможные типы соединений (префиксы JOIN); | WHERE — для указания условий выбора данных; | GROUP BY — для группировки данных; | HAVING — для указания условий выбора сгруппированных данных; | ORDER BY — для сортировки данных; | LIMIT или FETCH NEXT &lt;N&gt; ROWS ONLY— для ограничения количества возвращаемых строк; | OFFSET — для пропуска указанного количества строк в результате запроса. Описание синтаксиса см. в секции Ключевое слово OFFSET; | DATASOURCE_TYPE — для указания СУБД хранилища, из которой выбираются данные; | ESTIMATE_ONLY — для получения информации о запросе, а не самих данных. Описание см. в секции Ключевое слово ESTIMATE_ONLY. | . Ключевое слово FOR SYSTEM_TIME . Ключевое слово FOR SYSTEM_TIME позволяет указать момент, по состоянию на который запрашиваются данные, или период (диапазон дельт), за который запрашиваются изменения. Ключевое слово относится к логической таблице, логическому представлению или материализованному представлению, после имени которого оно следует. Если в запросе соединяется несколько логических таблиц и представлений, для каждой логической сущности можно указать свое ключевое слово FOR SYSTEM_TIME, при этом значения этих ключевых слов могут различаться (см. пример ниже). Примечание: наличие и значение ключевого слова FOR SYSTEM_TIME для материализованного представления влияют на порядок маршрутизации запроса (см. раздел Маршрутизация запросов к данным материализованных представлений). Ключевое слово указывается в формате FOR SYSTEM_TIME time_expression, где выражение time_expression принимает одно из следующих значений: . | AS OF 'YYYY-MM-DD hh:mm:ss' — запрос данных, актуальных на указанную дату и время. Возможные форматы даты и времени см. в разделе Форматы даты и времени в запросах; | AS OF DELTA_NUM delta_num — запрос данных, актуальных на дату и время закрытия дельты с номером delta_num; | AS OF LATEST_UNCOMMITTED_DELTA — запрос данных на текущий момент, включая данные, загруженные в рамках открытой (горячей) дельты. По горячей дельте возвращаются записи, загруженные в рамках непрерывного диапазона завершенных операций записи (см. параметры cn_from и cn_to в разделе GET_DELTA_HOT); | STARTED IN (delta_num1, delta_num2) — запрос данных, добавленных или измененных в период между дельтой delta_num1 и дельтой delta_num2 (включительно); | FINISHED IN (delta_num1, delta_num2) — запрос данных, удаленных в период между дельтой delta_num1 и дельтой delta_num2 (включительно). | . Следующие значения ключевого слова не поддерживаются в запросах к материализованным представлениям: . | FOR SYSTEM_TIME AS OF LATEST_UNCOMMITTED_DELTA; | FOR SYSTEM_TIME AS OF STARTED IN (delta_num1, delta_num2), если хотя бы одна дельта из диапазона отсутствует в материализованном представлении; | FOR SYSTEM_TIME AS OF FINISHED IN (delta_num1, delta_num2), если хотя бы одна дельта из диапазона отсутствует в материализованном представлении. | . Поддерживаемые типы соединений (префиксы JOIN) . Поддерживаются следующие типы соединений: . | [INNER] — внутреннее соединение, | NATURAL — внутреннее соединение по всем столбцам с одинаковыми именами, ключи соединения не указываются, | LEFT [OUTER] — левое внешнее соединение, | RIGHT [OUTER] — правое внешнее соединение, | FULL [OUTER] — полное внешнее соединение, | CROSS — декартово произведение таблиц или представлений, ключи соединения не указываются. | . Ключевое слово OFFSET . Ключевое слово OFFSET позволяет пропустить первые несколько строк результата и выбрать только последующие строки. В качестве значения ключевого слова можно указать любое неотрицательное целое число, начиная с нуля, или переменную. Если для OFFSET указано значение 0, то пропускается 0 строк, что равносильно запросу без OFFSET. Запросы с OFFSET без ограничения количества строк не поддерживаются. То есть, если ключевое слово OFFSET указано в запросе, то перед ним должно быть ключевое слово LIMIT &lt;N&gt; или FETCH NEXT &lt;N&gt; ROWS ONLY. Обратного ограничения нет: ключевые слова LIMIT &lt;N&gt; и FETCH NEXT &lt;N&gt; ROWS ONLY можно использовать без OFFSET. Рекомендуется сочетать OFFSET с ключевым словом ORDER BY для получения упорядоченного набора строк. Ключевое слово ORDER BY необязательно, однако без него запрос с OFFSET возвращает неупорядоченный и потому непредсказуемый набор строк. Примеры запросов см. ниже. Таким образом, для ключевого слова OFFSET поддерживается следующий синтаксис: . [ ORDER BY &lt;column_name&gt; ] { LIMIT &lt;value_1&gt; | FETCH NEXT &lt;value_1&gt; ROWS ONLY } OFFSET &lt;value_2&gt; [ ROW | ROWS ] . Ключевое слово ESTIMATE_ONLY . Ключевое слово ESTIMATE_ONLY позволяет запросить информацию о выполнении запроса к данным, а не сами данные. То есть вместо выборки данных из таблицы или представления запрос возвращает следующую информацию: . | имя СУБД хранилища, в которой предполагается выполнение запроса; | план выполнения запроса (только для ADB и ADP) — результат выполнения команды EXPLAIN в СУБД хранилища. Подробнее о команде EXPLAIN в ADB см. в документации Greenplum, о команде в ADP — в документации PostgreSQL; | обогащенный запрос — запрос, подготовленный системой на основе исходного запроса с учетом специфики СУБД хранилища. | . В ответе возвращается объект ResultSet с одной строкой, содержащей JSON-строку в следующем формате: . { \"plugin\": \"&lt;имя_СУБД&gt;\", \"estimation\": &lt;план_выполнения_запроса&gt;, \"query\": &lt;обогащенный_запрос&gt; } . Ниже показан пример JSON-строки, полученной по запросу к ADB. Для наглядности пример представлен в виде дерева, а не плоской строки. { \"plugin\": \"ADB\", \"estimation\": [ { \"Plan\": { \"Node Type\": \"Gather Motion\", \"Senders\": 4, \"Receivers\": 1, \"Slice\": 1, \"Segments\": 4, \"Gang Type\": \"primary reader\", \"Startup Cost\": 0.00, \"Total Cost\": 433.70, \"Plan Rows\": 50000, \"Plan Width\": 8, \"Plans\": [ { \"Node Type\": \"Seq Scan\", \"Parent Relationship\": \"Outer\", \"Slice\": 1, \"Segments\": 4, \"Gang Type\": \"primary reader\", \"Relation Name\": \"sales_actual\", \"Alias\": \"sales_actual\", \"Startup Cost\": 0.00, \"Total Cost\": 432.18, \"Plan Rows\": 50000, \"Plan Width\": 8 } ] }, \"Settings\": { \"Optimizer\": \"Pivotal Optimizer (GPORCA)\" } } ], \"query\": \"SELECT * FROM (SELECT id FROM sales.sales_actual WHERE sys_from &lt;= 98 AND COALESCE(sys_to, 9223372036854775807) &gt;= 98)\" } . Ниже показан пример JSON-строки, полученной по запросу к ADP. Для наглядности пример представлен в виде дерева, а не плоской строки. { \"plugin\": \"ADP\", \"estimation\": [ { \"Plan\": { \"Node Type\": \"Seq Scan\", \"Parallel Aware\": false, \"Relation Name\": \"sales_actual\", \"Alias\": \"sales_actual\", \"Startup Cost\": 0.00, \"Total Cost\": 18.80, \"Plan Rows\": 880, \"Plan Width\": 64 } } ], \"query\": \"SELECT * FROM (SELECT id FROM sales.sales_actual WHERE sys_from &lt;= 98 AND COALESCE(sys_to, 9223372036854775807) &gt;= 98)\" } . Ограничения . | Запрос может обращаться либо к логической БД, либо к сервисной БД (см. SELECT FROM INFORMATION_SCHEMA), но не к обеим одновременно. | Если ключами соединения в запросе выступают поля типа Nullable, то строки, где хотя бы один из ключей имеет значение NULL, не соединяются. | Ключевое слово ORDER BY не поддерживается для SELECT-подзапроса в составе запроса CREATE MATERIALIZED VIEW. | . Примеры . Звездочка и WHERE . Запрос с неявным указанием столбцов и ключевым словом WHERE: . SELECT * FROM sales.sales WHERE store_id = 1234 . DATASOURCE_TYPE . Запрос с явным указанием столбцов и выбором данных из определенной СУБД хранилища (ADQM): . SELECT sold.store_id, sold.product_amount FROM sales.stores_by_sold_products AS sold DATASOURCE_TYPE = 'adqm' . GROUP BY, ORDER BY и LIMIT . Запрос с агрегацией, группировкой и сортировкой данных, а также выбором первых 20 строк: . SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales.sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC LIMIT 20 . ESTIMATE_ONLY . Запрос на получение информации о запросе: . SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales.sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC ESTIMATE_ONLY . OFFSET . Запрос 20 строк, начиная с десятой: . SELECT * from sales.sales FETCH NEXT 20 ROWS ONLY OFFSET 9 . ORDER BY, LIMIT и OFFSET . Запрос 20 строк, упорядоченных по значению id и выбираемых начиная с десятой строки результата: . SELECT * from sales.sales ORDER BY id LIMIT 20 OFFSET 9 . Такое сочетание ключевых слов позволяет выбирать данные порциями с сохранением их порядка. FOR SYSTEM_TIME AS OF DELTA_NUM . Запрос записей, актуальных на момент закрытия дельты с номером 9, из материализованного представления: . SELECT * FROM sales.sales_and_stores FOR SYSTEM_TIME AS OF DELTA_NUM 9 . Соединение таблиц из разных логических БД . Запрос с соединением данных двух логических таблиц из двух различных логических БД: . SELECT st.id, st.category, s.product_code FROM sales.stores FOR SYSTEM_TIME AS OF LATEST_UNCOMMITTED_DELTA AS st INNER JOIN sales2.sales FOR SYSTEM_TIME AS OF LATEST_UNCOMMITTED_DELTA AS s ON st.id = s.store_id . Соединение изменений из разных дельт . Запрос с соединением записей логической таблицы, добавленных и измененных в двух различных диапазонах дельт: . -- выбор логической базы данных sales в качестве базы данных по умолчанию use sales -- запрос данных из логической таблицы prices SELECT p1.product_code, p1.price as feb_price, p2.price as march_price, (p2.price - p1.price) as diff FROM (SELECT product_code, price from sales.prices FOR SYSTEM_TIME STARTED IN(3,6)) AS p1 FULL JOIN (select product_code, price from sales.prices FOR SYSTEM_TIME STARTED IN(7,10)) AS p2 ON p1.product_code = p2.product_code WHERE p1.product_code is NOT NULL ORDER BY diff DESC LIMIT 50 DATASOURCE_TYPE = 'adb' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/SELECT/SELECT.html",
    "relUrl": "/reference/sql_plus_requests/SELECT/SELECT.html"
  },"75": {
    "doc": "SELECT FROM INFORMATION_SCHEMA",
    "title": "SELECT FROM INFORMATION_SCHEMA",
    "content": "SELECT FROM INFORMATION_SCHEMA . Содержание раздела . | Синтаксис | Параметры | Ограничения | Примеры . | Запрос списка всех логических БД окружения | Запрос информации о сущностях логической БД | Запрос имен, типов и столбцов логических сущностей | . | . Запрос позволяет получить метаданные объектов логической схемы, описанные в разделе Системные представления (INFORMATION_SCHEMA). Возможности запроса отличаются от возможностей SELECT-запроса к логическим базам данных. В ответе возвращается: . | объект ResultSet c выбранными записями при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . SELECT column_list FROM [INFORMATION_SCHEMA.]system_view_name [AS alias_name] . Описание параметров запроса см. ниже. Префикс INFORMATION_SCHEMA перед именем системного представления опционален, если до этого был выполнен запрос USE INFORMATION_SCHEMA. Для имен системных представлений и столбцов можно использовать псевдонимы. В запросе поддерживаются следующие ключевые слова, которые должны быть указаны в порядке их перечисления: . | JOIN ON — для соединения данных нескольких системных представлений; | WHERE — для указания условий выбора данных; | GROUP BY — для группировки данных; | ORDER BY — для сортировки данных; | LIMIT — для ограничения количества возвращаемых строк. | . Внимание: строковые значения столбцов для ключевого слова WHERE необходимо указывать в верхнем регистре (например, WHERE table_schema = 'SALES'). Поддерживаются следующие типы соединений системных представлений: . | [INNER] — внутреннее соединение, | LEFT [OUTER] — левое внешнее соединение, | RIGHT [OUTER] — правое внешнее соединение, | FULL [OUTER] — полное внешнее соединение, | CROSS — декартово произведение, ключи соединения не указываются. | . Параметры . | column_list — список выбираемых столбцов. Допустимо указывать символ * для выбора всех столбцов; | system_view_name — имя системного представления, из которого запрашивается информация. Возможные значения см. в разделе Системные представления (INFORMATION_SCHEMA); | alias_name — псевдоним системного представления. | . Ограничения . Не допускается комбинирование подзапросов к INFORMATION_SCHEMA с подзапросами к логическим базам данных. Примеры . Запрос списка всех логических БД окружения . Запрос списка всех логических БД окружения с лексической сортировкой по возрастанию: . SELECT schema_name FROM INFORMATION_SCHEMA.schemata ORDER BY schema_name . Запрос информации о сущностях логической БД . Запрос информации о логических сущностях логической БД SALES: . SELECT * FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' . Запрос имен, типов и столбцов логических сущностей . Запрос списка имен, типов и столбцов логических сущностей окружения: . SELECT TC.table_schema, TC.table_name, TT.table_type, TC.column_name FROM information_schema.columns AS TC JOIN information_schema.tables AS TT ON TC.table_schema = TT.table_schema and TC.table_name = TT.table_name ORDER BY TC.table_schema, TC.table_name . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/SELECT_FROM_INFORMATION_SCHEMA/SELECT_FROM_INFORMATION_SCHEMA.html",
    "relUrl": "/reference/sql_plus_requests/SELECT_FROM_INFORMATION_SCHEMA/SELECT_FROM_INFORMATION_SCHEMA.html"
  },"76": {
    "doc": "TRUNCATE HISTORY",
    "title": "TRUNCATE HISTORY",
    "content": "TRUNCATE HISTORY . Содержание раздела . | Синтаксис | Параметры | Пример | . Запрос позволяет удалить записи логической таблицы согласно заданным условиям. В зависимости от параметров запроса удаляются записи одной из категорий: . | записи таблицы, которые были перенесены в архив до указанного момента времени (включительно) и соответствуют условию, заданному в запросе; . | все архивные и актуальные записи таблицы, которые соответствуют условию, заданному в запросе. | . Если в запросе указан момент времени, система определяет дельту, которая являлась последней закрытой дельтой на тот момент, и удаляет все записи логической таблицы, которые стали архивными в эту дельту или ранее и соответствуют заданному условию. Иначе, если задано ключевое слово infinite, удаляются все записи таблицы, соответствующие условию. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; . | исключение при неуспешном выполнении запроса. | . В результате успешного выполнения запроса записи, удовлетворяющие его параметрам, удаляются из логической таблицы. Внимание: удаленные данные не подлежат восстановлению средствами системы. На рисунке ниже показан пример работы запроса с указанным моментом времени. В примере логическая таблица содержит три записи об одном клиенте, загруженные в рамках трех разных дельт (дельта 0, дельта 1, дельта 2) в течение одного дня (2021-03-03). В результате исполнения запроса удаляется запись 0: на момент времени 18:00:00 дельта 1 была последней закрытой дельтой, и только запись 0 была архивной в эту дельту (запись 1 была актуальной). Удаление архивной записи по запросу с меткой времени . Синтаксис . TRUNCATE HISTORY [db_name.]table_name FOR SYSTEM_TIME AS OF date_time_expression [WHERE filter_expression] . Параметры . | db_name — имя логической базы данных. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; . | table_name — имя логической таблицы, из которой удаляются записи; . | date_time_expression — выражение, определяющее категорию удаляемых записей. Может принимать следующие значения: . | 'YYYY-MM-DD hh:mm:ss' — удаление архивных записей по указанный момент времени. Возможные форматы см. в разделе Форматы даты и времени; . | 'infinite' — удаление всех актуальных и архивных записей; . | . | filter_expression — условие выбора записей, подлежащих удалению. | . Пример . Удаление архивных записей таблицы sales, в которых значение столбца product_units меньше 10, по момент времени '2019-12-23 15:15:14': . TRUNCATE HISTORY sales.sales FOR SYSTEM_TIME AS OF '2019-12-23 15:15:14' WHERE product_units &lt; 10 . Удаление всех актуальных и архивных записей таблицы stores, в которых значение столбца id равно 123456: . TRUNCATE HISTORY sales.stores FOR SYSTEM_TIME AS OF 'infinite' WHERE id = 123456 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/TRUNCATE_HISTORY/TRUNCATE_HISTORY.html",
    "relUrl": "/reference/sql_plus_requests/TRUNCATE_HISTORY/TRUNCATE_HISTORY.html"
  },"77": {
    "doc": "USE",
    "title": "USE",
    "content": "USE . Запрос позволяет изменить логическую базу данных по умолчанию на указанную логическую базу данных. Логическую базу данных по умолчанию необходимо определить перед выполнением запросов, предназначенных для управления дельтой и получения информации о ней. Это действие также можно выполнить перед другими запросами, что позволит не указывать имя логической БД перед именами логических сущностей в запросах к одной и той же логической базе данных. В ответе возвращается: . | объект ResultSet c одной записью, содержащей имя выбранной логической базы данных, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса указанная логическая база данных выбирается и используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или закрытие соединения с системой. Примечание: альтернативно можно определить логическую базу данных по умолчанию в настройках JDBC-подключения (см. Определение логической БД по умолчанию). Синтаксис . USE db_name . Параметры . | db_name — имя логической базы данных, подлежащей установке по умолчанию. | . Пример . USE sales . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/USE/USE.html",
    "relUrl": "/reference/sql_plus_requests/USE/USE.html"
  },"78": {
    "doc": "USE INFORMATION_SCHEMA",
    "title": "USE INFORMATION_SCHEMA",
    "content": "USE INFORMATION_SCHEMA . Запрос позволяет изменить логическую базу данных по умолчанию на сервисную базу данных. Совет: запрос можно выполнить перед запросами SELECT FROM INFORMATION_SCHEMA — это даст возможность не указывать префикс INFORMATION_SCHEMA перед именами системных представлений в запросах к сервисной базе данных. В ответе возвращается: . | объект ResultSet c одной записью, содержащей имя сервисной базы данных (information_schema), при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . USE INFORMATION_SCHEMA . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/USE_INFORMATION_SCHEMA/USE_INFORMATION_SCHEMA.html",
    "relUrl": "/reference/sql_plus_requests/USE_INFORMATION_SCHEMA/USE_INFORMATION_SCHEMA.html"
  },"79": {
    "doc": "Запросы SQL+",
    "title": "Запросы SQL+",
    "content": "Запросы SQL+ . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_plus_requests/sql_plus_requests.html",
    "relUrl": "/reference/sql_plus_requests/sql_plus_requests.html"
  },"80": {
    "doc": "Поддержка SQL",
    "title": "Поддержка SQL",
    "content": "Поддержка SQL . Содержание раздела . | Примеры неподдерживаемых запросов . | AVG | CROSS JOIN | FULL JOIN | JOIN для трех таблиц | JOIN с подзапросом | RIGHT JOIN | . | . В SELECT-запросах к данным можно использовать функции, описанные в таблице ниже. СУБД хранилища имеют ограничения на использование некоторых функций в запросах, вызванные особенностями этих СУБД. Наиболее полный синтаксис запросов доступен в ADB и ADP. | Функция | Доступна в ADB | Доступна в ADQM | Доступна в ADG | Доступна в ADP | . | ABS | + | + | + | + | . | ACOS | + | + | − | + | . | ASIN | + | + | − | + | . | ATAN | + | + | − | + | . | ATAN2 | + | − | − | + | . | AVG | − | − | − | − | . | BIT_AND | + | − | − | + | . | BIT_OR | + | − | − | + | . | CASE | + | + | + | + | . | CAST | + | + | + | + | . | CBRT | + | − | − | + | . | CEIL | +для аргумента типа FLOAT | + | − | +для аргумента типа FLOAT | . | CEILING | +для аргумента типа FLOAT | + | − | +для аргумента типа FLOAT | . | CHAR | − | − | − | − | . | COALESCE | + | + | + | + | . | COS | + | + | − | + | . | COUNT | + | + | + | + | . | CROSS JOIN | + | − | + | + | . | DEGREES | + | − | − | + | . | EXCEPT | − | − | − | − | . | EXP | + | + | − | + | . | FLOOR | +для аргумента типа FLOAT | + | − | +для аргумента типа FLOAT | . | FULL JOIN | + | +при соединении по ключам шардирования | − | + | . | GREATEST | − | − | − | − | . | HEX | − | − | − | − | . | IFNULL | − | − | − | − | . | INTERSECT | − | − | − | − | . | JOIN для трех таблиц | + | − | + | + | . | JOIN с подзапросом | + | − | + | + | . | LEAST | − | − | − | − | . | LENGTH | − | − | − | − | . | LIKE | + | + | + | + | . | LN | + | + | − | + | . | LOG | − | − | − | − | . | LOWER | + | + | + | + | . | MAX | + | + | + | + | . | MIN | + | + | + | + | . | MOD | + | − | − | + | . | NULLIF | + | + | + | + | . | OCTET_LENGTH | − | − | − | − | . | PI | − | − | − | − | . | POSITION | + | − | − | + | . | POWER | + | + | − | + | . | PRINTF | − | − | − | − | . | QUOTE | − | − | − | − | . | RADIANS | + | − | − | + | . | RANDOM | − | − | − | − | . | REPLACE | + | + | + | + | . | RIGHT JOIN | + | + | − | + | . | ROUND | +для аргумента типа FLOAT | + | + | +для аргумента типа FLOAT | . | SIGN | +для аргумента типа FLOAT | − | − | +для аргумента типа FLOAT | . | SIN | + | + | − | + | . | SQRT | + | + | − | + | . | SUBSTRING | + | + | − | + | . | SUM | + | + | + | + | . | TAN | + | + | − | + | . | TRIM | + | + | + | + | . | TRUNC | − | − | − | − | . | TYPEOF | − | − | − | − | . | UNION | − | − | − | − | . | UPPER | + | + | + | + | . Примеры неподдерживаемых запросов . AVG . SELECT AVG(product_units) FROM sales.sales . CROSS JOIN . SELECT * FROM sales.sales AS s CROSS JOIN sales.stores AS st ORDER BY s.store_id, st.category LIMIT 5 DATASOURCE_TYPE = 'ADQM' . FULL JOIN . SELECT * FROM sales.sales AS s FULL JOIN sales.stores AS st ON s.store_id = st.id ORDER BY s.store_id LIMIT 5 DATASOURCE_TYPE = 'ADG' . JOIN для трех таблиц . SELECT * FROM demo.territories AS t LEFT JOIN demo.employee_territories AS et ON t.territory_id = et.territory_id LEFT JOIN demo.employees AS e ON t.territory_id = e.territory_id WHERE e.last_name is NOT NULL ORDER BY t.territory_id DATASOURCE_TYPE = 'ADQM' . JOIN с подзапросом . SELECT * FROM sales.sales AS s INNER JOIN (SELECT * FROM sales.stores) AS st ON s.store_id = st.id ORDER BY s.store_id DATASOURCE_TYPE = 'ADQM' . RIGHT JOIN . SELECT * FROM sales.sales AS s RIGHT JOIN sales.stores AS st ON s.store_id = st.id ORDER BY st.id LIMIT 5 DATASOURCE_TYPE = 'ADG' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/sql_support/sql_support.html",
    "relUrl": "/reference/sql_support/sql_support.html"
  },"81": {
    "doc": "Выгружаемые типы данных",
    "title": "Выгружаемые типы данных",
    "content": "Выгружаемые типы данных . Типы данных Avro, выгружаемые из системы, зависят от СУБД хранилища, из которой выгружаются данные. В таблице ниже для каждого логического типа данных указаны выгружаемые типы данных Avro. Подробнее о типах данных Avro см. в официальной документации Apache Avro. | Логический тип данных | Тип данных Avro, выгружаемый из ADB | Тип данных Avro, выгружаемый из ADG | Тип данных Avro, выгружаемый из ADQM | Тип данных Avro, выгружаемый из ADP | . | BOOLEAN | boolean | boolean | int | boolean | . | VARCHAR (n) | string | string | string | string | . | UUID | string | string | string | string | . | INT32 | int | int | int | int | . | INT | long | long | long | long | . | BIGINT | long | long | long | long | . | DOUBLE | double | double | double | double | . | FLOAT | float | float | float | float | . | DATE | int | int | int | int | . | TIME (precision) | long | long | long | long | . | TIMESTAMP (precision) | long | long | long | long | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/supported_data_types/download_data_types/download_data_types.html",
    "relUrl": "/reference/supported_data_types/download_data_types/download_data_types.html"
  },"82": {
    "doc": "Логические типы данных",
    "title": "Логические типы данных",
    "content": "Логические типы данных . Система поддерживает логические типы данных, описанные в таблице ниже. Для каждого из них в таблице указаны соответствующие физические типы данных СУБД хранилища. Примечание: при работе с логическими базами данных и их объектами нужно указывать логические типы данных. Физические типы данных описаны в справочных целях. | Логический тип | Описание | Тип данных ADB | Тип данных ADG | Тип данных ADQM | Тип данных ADP | . | BOOLEAN | Логический (булевый) тип | boolean | boolean | UInt8 | boolean | . | VARCHAR (n) | Строка ограниченной длины (n символов) | varchar (n) | string | String | varchar (n) | . | LINK | Строка неограниченной длины. Предназначена для ссылочных полей | varchar | string | String | varchar | . | CHAR (n) | Строка ограниченной длины (n символов) | varchar (n) | string | String | varchar (n) | . | UUID | Строка ограниченной длины (36 символов) | varchar (36) | string | String | varchar (36) | . | BIGINT | Целое число фиксированной длины со знаком, находящееся в диапазоне от -9223372036854775808 до 9223372036854775807 | bigint (int8) | integer | Int64 | bigint (int8) | . | INT | Целое число фиксированной длины со знаком, находящееся в диапазоне от -9223372036854775808 до 9223372036854775807 | bigint (int8) | integer | Int64 | bigint (int8) | . | INT32 | Целое число фиксированной длины со знаком, находящееся в диапазоне от -2147483648 до 2147483647 | integer (int4) | integer | Int32 | integer (int4) | . | DOUBLE | Число с плавающей запятой с двойной точностью | double precision (float8) | number | Float64 | double precision (float8) | . | FLOAT | Число с плавающей запятой | real (float4) | number | Float32 | real (float4) | . | DATE | Дата (без времени суток) | date | integer (знаковое число дней относительно даты 1970-01-01) | Int64 (знаковое число дней относительно даты 1970-01-01) | date | . | TIME, TIME (precision) | Время (без даты). Заданная точность (precision) влияет только на отображение времени. Возможные значения: от 0 до 6. Значение 0 соответствует секундам, значение 6 — микросекундам. Значение по умолчанию — 6. Количество микросекунд находится в диапазоне от 0 до 86399999999 | time (6) | integer (знаковое число микросекунд, начиная с 00:00:00.000000) | Int64 (знаковое число микросекунд, начиная с 00:00:00.000000) | time (6) | . | TIMESTAMP, TIMESTAMP (precision) | Дата и время. Заданная точность (precision) влияет только на отображение даты и времени. Возможные значения: от 0 до 6. Значение 0 соответствует секундам, значение 6 — микросекундам. Значение по умолчанию — 6 | timestamp (6) | integer (знаковое число микросекунд относительно 1970-01-01 00:00:00) | Int64 (знаковое число микросекунд относительно 1970-01-01 00:00:00) | timestamp (6) | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/supported_data_types/logical_data_types/logical_data_types.html",
    "relUrl": "/reference/supported_data_types/logical_data_types/logical_data_types.html"
  },"83": {
    "doc": "Поддерживаемые типы данных",
    "title": "Поддерживаемые типы данных",
    "content": "Поддерживаемые типы данных . В разделе описаны следующие типы данных: . | логические типы данных системы и соответствующие им физические типы данных СУБД хранилища (см. Логические типы данных); | загружаемые типы данных Avro и соответствующие им логические типы данных (см. Загружаемые типы данных); | логические типы данных и соответствующие им выгружаемые типы данных Avro (см. Выгружаемые типы данных). | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/supported_data_types/supported_data_types.html",
    "relUrl": "/reference/supported_data_types/supported_data_types.html"
  },"84": {
    "doc": "Загружаемые типы данных",
    "title": "Загружаемые типы данных",
    "content": "Загружаемые типы данных . Система поддерживает загрузку типов данных Avro, перечисленных в таблице ниже. Для каждого типа данных Avro указан соответствующий логический тип данных. Подробнее о типах данных Avro см. в официальной документации Apache Avro. | Загружаемый тип данных Avro | Логический тип данных | . | boolean | BOOLEAN | . | string | VARCHAR (n) | . | int | INT32 | . | long | BIGINT | . | float | FLOAT | . | double | DOUBLE | . | (int) date | DATE | . | (long) time-micros | TIME (precision) | . | (long) timestamp-micros | TIMESTAMP (precision) | . Примечание: . | Значение типа данных (long) time-micros считается корректным, если лежит в интервале [0; 86399999999] микросекунд. Для значений этого типа данных, лежащих вне указанного интервала, успешная загрузка и дальнейшая корректная обработка не гарантируются. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/supported_data_types/upload_data_types/upload_data_types.html",
    "relUrl": "/reference/supported_data_types/upload_data_types/upload_data_types.html"
  },"85": {
    "doc": "Системные представления (INFORMATION_SCHEMA)",
    "title": "Системные представления (INFORMATION_SCHEMA)",
    "content": "Системные представления (INFORMATION_SCHEMA) . Содержание раздела . | Представление schemata | Представление tables | Представление columns | Представление table_constraints | Представление key_column_usage | Взаимосвязь системных представлений | . Набор системных представлений (INFORMATION_SCHEMA) предоставляет доступ к метаданным логической схемы данных и содержит следующие элементы: . | schemata, | tables, | columns, | table_constraints, | key_column_usage. | . Набор системных представлений и их свойств фиксирован и недоступен для изменения. Представление schemata . Системное представление schemata содержит список логических баз данных окружения. По каждой логической базе доступна следующая информация: . | catalog_name — наименование каталога, в который помещена логическая база данных. Значение по умолчанию — public; | schema_name — наименование логической базы данных. | . Представление tables . Системное представление tables содержит список логических таблиц, логических представлений и материализованных представлений окружения. По каждой таблице или представлению доступна следующая информация: . | table_catalog — наименование каталога, в который помещена таблица или представление. Значение по умолчанию — public; | table_schema — наименование логической базы данных, к которой относится таблица или представление; | table_name — наименование таблицы или представления; | table_type — тип объекта. Возможные значения: BASE TABLE — логическая таблица или материализованное представление, VIEW — логическое представление; | table_datasource_type — список СУБД хранилища, в которых размещены данные таблицы или материализованного представления. Для логических представлений поле остается пустым. | . Представление columns . Системное представление columns содержит список столбцов логических таблиц и представлений окружения. По каждому столбцу доступна следующая информация: . | table_catalog — наименование каталога, в который помещена таблица или представление. Значение по умолчанию — public; | table_schema — наименование логической базы данных, к которой относится таблица или представление; | table_name — наименование таблицы или представления, к которому относится столбец; | column_name — наименование столбца, по которому предоставлена информация; | is_nullable — признак того, может ли значение столбца иметь пустое значение (null). Возможные значения: YES — столбец может содержать пустое значение; NO — столбец должен содержать непустое значение; | ordinal_position — порядковый номер столбца в таблице или представлении (нумерация начинается с 1); | character_maximum_length — максимально допустимое количество символов (для строковых значений); | datetime_precision — степень отображаемой точности значений типа TIMESTAMP. Возможное значение: от 0 (точность до секунд) до 6 (точность до микросекунд). | data_type — тип данных столбца. Возможные значения см. в разделе Логические типы данных. | . Представление table_constraints . Системное представление table_constraints содержит список ограничений логических таблиц и представлений окружения. По каждому ограничению доступна следующая информация: . | constraint_catalog — наименование каталога, в который помещена таблица или представление с ограничением. Значение по умолчанию — public; | constraint_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | constraint_name — наименование ограничения; | table_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | table_name — наименование таблицы или представления, к которому относится ограничение; | constraint_type — тип ограничения. Возможные значения: primary key — первичный ключ, sharding key — ключ шардирования. | . Представление key_column_usage . Системное представление key_column_usage содержит список столбцов окружения, с которыми связаны какие-либо ограничения. По каждому столбцу доступна следующая информация: . | constraint_catalog — наименование каталога, в который помещена таблица или представление с ограничением. Значение по умолчанию — public; | constraint_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | constraint_name — наименование ограничения; | table_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | table_name — наименование таблицы или представления, к которому относится ограничение; | column_name — наименование столбца, на который накладывается ограничение; | ordinal_position — порядковый номер поля в ключе (нумерация начинается с 1). | . Взаимосвязь системных представлений . На рисунке ниже показана взаимосвязь системных представлений. Взаимосвязь системных представлений . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/system_views/system_views.html",
    "relUrl": "/reference/system_views/system_views.html"
  },"86": {
    "doc": "Форматы даты и времени в запросах",
    "title": "Форматы даты и времени в запросах",
    "content": "Форматы даты и времени в запросах . Дату и время в запросах можно указывать в следующих форматах: . | с точностью до секунд: YYYY-MM-DD hh:mm:ss (например, 2021-05-25 18:00:17); | с любой точностью от десятых секунд (S) до микросекунд (SSSSSS): . | YYYY-MM-DD hh:mm:ss.S, | YYYY-MM-DD hh:mm:ss.SS, | YYYY-MM-DD hh:mm:ss.SSS (например, 2021-05-25 18:00:17.876), | YYYY-MM-DD hh:mm:ss.SSSS, | YYYY-MM-DD hh:mm:ss.SSSSS, | YYYY-MM-DD hh:mm:ss.SSSSSS (например, 2021-05-25 18:00:17.876784). | . | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/timestamp_formats/timestamp_formats.html",
    "relUrl": "/reference/timestamp_formats/timestamp_formats.html"
  },"87": {
    "doc": "Формат загрузки данных",
    "title": "Формат загрузки данных",
    "content": "Формат загрузки данных . Содержание раздела . | Структура сообщений | Формат данных | Примеры . | Пример загружаемой схемы данных Avro | Пример загружаемых записей Avro | . | . Структура сообщений . Данные загружаются в систему в виде сообщений топиков Kafka. Каждое сообщение имеет структуру, показанную на рисунке ниже. Структура загружаемых сообщений . Формат данных . Для успешной загрузки данные должны соответствовать следующим условиям: . | Данные представлены в виде сообщений топика Kafka. | Каждое сообщение состоит из ключа и тела. Требования к ключу сообщения не предъявляются. | Тело сообщения представляет собой файл Avro (Object Container File), который состоит из заголовка и блоков данных. | Заголовок файла содержит схему данных Avro. | Схема данных содержит следующие элементы: имя, тип “record” и перечень полей. Для каждого поля указано имя, а также тип данных Avro из перечисленных в разделе Загружаемые типы данных (см. пример ниже). Последним полем схемы указано служебное поле sys_op с типом данных int. | Каждый блок данных содержит запись, представленную в бинарной кодировке. Запись соответствует схеме данных из заголовка файла Avro. | Каждая запись содержит перечень полей и их значений. Имена и порядок перечисления полей, а также типы данных их значений соответствуют схеме данных (см. пример ниже). Последним полем каждой записи указано служебное поле sys_op со значением 0 (если запись добавляется или обновляется) или 1 (если запись удаляется). | Состав и порядок полей совпадают во всех следующих объектах: . | в схеме данных заголовка файла Avro, | в наборе загружаемых записей, | во внешней таблице загрузки (поле sys_op может отсутствовать, так как при создании внешней таблицы его можно не указывать), | в логической таблице, в которую загружаются данные (поле sys_op должно отсутствовать, так как оно относится к числу зарезервированных служебных полей). | . | . В схеме данных можно использовать логические типы Avro, а также элементы unions (см. пример ниже). Типы данных Avro, доступные к загрузке в систему, описаны в разделе Загружаемые типы данных. Подробнее о формате Avro см. в официальной документации на сайте https://avro.apache.org. Примеры . Пример загружаемой схемы данных Avro . Пример ниже содержит схему данных Avro, используемую для загрузки данных о продажах в логическую таблицу sales. Для поля transaction_date указан логический тип Avro, для поля description — элемент union. Для наглядности примера бинарные данные представлены в JSON-формате. { \"name\": \"sales\", \"type\": \"record\", \"fields\": [ { \"name\": \"id\", \"type\": \"long\" }, { \"name\": \"transaction_date\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\" }, { \"name\": \"product_code\", \"type\": \"string\" }, { \"name\": \"product_units\", \"type\": \"long\" }, { \"name\": \"store_id\", \"type\": \"long\" }, { \"name\": \"description\", \"type\": [ \"null\", \"string\" ] }, { \"name\": \"sys_op\", \"type\": \"int\" } ] } . Пример загружаемых записей Avro . Пример ниже содержит набор записей о продажах, загружаемых в логическую таблицу sales. Для наглядности примера бинарные данные представлены в JSON-формате. [ { \"id\": 1000111, \"transaction_date\": 1614269474000000, \"product_code\": \"ABC102101\", \"product_units\": 2, \"store_id\": 1000012345, \"description\": \"Покупка по акции 1+1\", \"sys_op\": 0 }, { \"id\": 1000112, \"transaction_date\": 1614334214000000, \"product_code\": \"ABC102001\", \"product_units\": 1, \"store_id\": 1000000123, \"description\": \"Покупка без акций\", \"sys_op\": 0 }, { \"id\": 1000020, \"transaction_date\": 1614636614000000, \"product_code\": \"ABC102010\", \"product_units\": 4, \"store_id\": 1000000123, \"description\": \"Покупка по акции 1+1\", \"sys_op\": 1 } ] . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/reference/upload_format/upload_format.html",
    "relUrl": "/reference/upload_format/upload_format.html"
  },"88": {
    "doc": "Ресурсы",
    "title": "Ресурсы",
    "content": "Ресурсы . github-репозиторий Prostore . Коннекторы . | github-репозиторий Kafka PXF connector | github-репозиторий Kafka Clickhouse connector | github-репозиторий Kafka Tarantool loader | github-репозиторий Kafka ADB connector . | github-репозиторий Apache Avro fork | . | github-репозиторий Kafka Postgres connector | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/resources/resources.html",
    "relUrl": "/resources/resources.html"
  },"89": {
    "doc": "История изменений",
    "title": "История изменений",
    "content": "История изменений . Содержание раздела . | Текущая версия документации (5.1) | Архивные версии документации . | Версия 5.0 | Версия 4.1 | Версия 4.0 | Версия 3.7.3 | . | . Текущая версия документации (5.1) . Изменения: . | добавлено ключевое слово ESTIMATE_ONLY, доступное в SELECT-запросах; | добавлено ключевое слово LOGICAL_ONLY, доступное в запросах на создание и удаление логической БД, логической таблицы и материализованного представления; | обновлено описание запросов CHECK_DATA и CHECK_SUM: . | добавлен коэффициент нормализации, повышающий максимально допустимое количество записей в проверяемых дельтах; | изменен расчет контрольных сумм: теперь они считаются по дельтам, а не отдельным операциям записи; | . | обновлено описание запроса CHECK_SUM: . | изменен расчет контрольной суммы по таблице/представлению: теперь расчет аналогичен тому, который выполняется для CHECK_DATA; | изменен расчет контрольной суммы по логической БД: теперь контрольные суммы таблиц складываются, а не проходят дополнительный этап хеширования; | . | в конфигурацию добавлен параметр DTM_VERTX_BLOCKING_STACKTRACE_TIME; | в главу «Работа с системой» добавлены разделы Получение информации о SELECT-запросе и Проверка месторасположения логической сущности; | в главу «Эксплуатация» добавлен раздел Часовые пояса системы и компонентов. | . Архивные версии документации . Версия 5.0 . Изменения: . | добавлена СУБД хранилища нового типа — ADP — на основе PostgreSQL; | добавлена выгрузка данных из СУБД хранилища, указанной в запросе (см. INSERT INTO download_external_table); | в системное представление tables добавлен столбец table_datasource_type; | обновлено описание запроса CHECK_SUM: теперь запрос поддерживает расчет контрольной суммы по материализованному представлению; | обновлена конфигурация: . | добавлены параметры для управления СУБД ADP; | добавлены параметры запроса prepared statement для ADB: ADB_PREPARED_CACHE_MAX_SIZE, ADB_PREPARED_CACHE_SQL_LIMIT и ADB_PREPARED_CACHE; | значения следующих параметров расширены новой СУБД ADP: CORE_PLUGINS_ACTIVE, DTM_CORE_PLUGINS_RELATIONAL, DTM_CORE_PLUGINS_ANALYTICAL, DTM_CORE_PLUGINS_DICTIONARY, DTM_CORE_PLUGINS_UNDEFINED; | добавлен параметр DTM_LOGGING_LEVEL для управления уровнем логирования; | конкретные IP-адреса заменены на localhost; | . | добавлен раздел Схемы развертывания. | . Версия 4.1 . Версия 4.1 доступна в архиве. Изменения: . | добавлено ключевое слово OFFSET, доступное в SELECT-запросах; | добавлено ключевое слово FETCH NEXT &lt;N&gt; ROWS ONLY как полная альтернатива ключевому слову LIMIT &lt;N&gt; в SELECT-запросах; | обновлено описание запроса ROLLBACK DELTA: теперь запрос отменяет как завершенные, так и выполняемые операции записи; | обновлена конфигурация: . | значение параметра ADB_EXECUTORS_COUNT изменено с 20 на 3; | значение параметра ADB_MAX_POOL_SIZE изменено с 5 на 3; | добавлен новый параметр DELTA_ROLLBACK_STATUS_CALLS_MS. | . | . Версия 4.0 . Изменения: . | описаны материализованные представления; | описаны возможные форматы даты и времени в запросах; | добавлен раздел «Проверка наличия логической сущности»; | добавлен раздел «Настройка JSON-логов»; | в конфигурацию добавлены параметры по управлению материализованными представлениями: . | MATERIALIZED_VIEWS_SYNC_PERIOD_MS, | MATERIALIZED_VIEWS_RETRY_COUNT, | MATERIALIZED_VIEWS_RETRY_COUNT. | . | . Версия 3.7.3 . Версия 3.7.3 доступна в архиве. Изменения: . | обновлена конфигурация: . | в секцию vertx.pool добавлены параметры DTM_CORE_WORKER_POOL_SIZE и DTM_CORE_EVENT_LOOP_POOL_SIZE; | путь к параметру ADB_MAX_POOL_SIZE изменился с adb.maxSize на adb.poolSize; | в секцию adb добавлен параметр ADB_EXECUTORS_COUNT; | . | описан запрос ROLLBACK CRASHED_WRITE_OPERATIONS; | доработаны разделы CHECK_DATA и CHECK_SUM: описаны алгоритм и пример расчета контрольной суммы; | уточнено описание формата загрузки и формата выгрузки данных; | в разделе «Минимальные системные требования» версия ADG обновлена до 2.7.2. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/revision_history/revision_history.html",
    "relUrl": "/revision_history/revision_history.html"
  },"90": {
    "doc": "Подключение",
    "title": "Подключение",
    "content": "Подключение . Чтобы начать работать с системой, нужно подключиться к системе. Доступны следующие способы подключения: . | с помощью SQL-клиента, например DBeaver или DataGrip; | с помощью программного подключения. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/connection/connection.html",
    "relUrl": "/working_with_system/connection/connection.html"
  },"91": {
    "doc": "Программное подключение",
    "title": "Программное подключение",
    "content": "Программное подключение . JDBC-драйвер системы позволяет подключаться программно (без использования SQL-клиента). Вы можете реализовать свое приложение, работающее с системой через JDBC-подключение. Чтобы подключиться к системе с помощью программного подключения: . | Загрузите скомпилированный файл драйвера с именем dtm-jdbc-&lt;version&gt;.jar. | Определите путь к jar-файлу драйвера любым из способов: . | задайте путь с помощью переменной окружения CLASSPATH; | задайте путь в командной строке при запуске своего приложения (формат зависит от операционной системы): java -classpath /&lt;path-to-driver&gt;/dtm-jdbc-&lt;version&gt;.jar myapplication.class . | . | В реализации класса вашего приложения, который отвечает за подключение к системе (см. пример ниже): . | импортируйте пакеты Java SQL: import java.sql.*; . | если используется Java версии менее 1.6, загрузите драйвер в память: Class.forName(\"io.arenadata.dtm.jdbc.DtmDriver\"); . | установите соединение с системой с помощью метода DriverManager.getConnection() в следующем формате: String url = \"jdbc:adtm://DtmHost:portNumber/logicalDatabaseName\"; Connection conn = DriverManager.getConnection(url, null, null); . | . | . Строка url содержит параметры: . | DtmHost — IP-адрес или имя хоста, на котором установлена система; | portNumber — номер порта для подключения; | (опционально) logicalDatabaseName — имя логической базы данных, используемой по умолчанию. | . Пример url: . String url = \"jdbc:adtm://10.92.3.3:9092/demo\"; Connection conn = DriverManager.getConnection(url, null, null); . После установки соединения можно выполнять запросы SQL+. По окончании работы с системой нужно закрыть подключение. В примере ниже показана базовая реализация класса SimpleDtmJDBCExample, который устанавливает соединение с системой по заданному адресу и затем закрывает соединение. import java.sql.*; public class SimpleDtmJDBCExample { public static void main(String[] args) { Connection conn; String url = \"jdbc:adtm://10.92.3.3:9092/demo\"; try { conn = DriverManager.getConnection(url); System.out.println(\"Connected\"); } catch (SQLException e) { // Catch all for the SQL exceptions e.printStackTrace(); } finally { conn.close(); } } . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/connection/connection_via_code/connection_via_code.html",
    "relUrl": "/working_with_system/connection/connection_via_code/connection_via_code.html"
  },"92": {
    "doc": "Подключение с помощью SQL-клиента",
    "title": "Подключение с помощью SQL-клиента",
    "content": "Подключение с помощью SQL-клиента . Перед настройкой подключения загрузите скомпилированный файл драйвера с именем dtm-jdbc-&lt;version&gt;.jar в вашу файловую систему. Чтобы настроить подключение к системе с помощью SQL-клиента: . | Откройте меню, отвечающее за добавление новых JDBC-драйверов. В SQL-клиенте DBeaver это меню Driver Management, доступное в панели Database Navigator, в DataGrip — меню Data Sources. | Добавьте новый драйвер со следующими настройками (см. рисунок ниже): . | (Driver) Name — произвольное имя драйвера, например DTM, | (Class) Name — io.arenadata.dtm.jdbc.DtmDriver, | URL Template — jdbc:adtm://{host}:{port}/{database}, | Default Port (если параметр присутствует) — 9090 или 9092. | . | Нажмите кнопку Add (File) для добавления файла драйвера и выберите файл dtm-jdbc-&lt;version&gt;.jar в вашей файловой системе. | Сохраните настройки драйвера. | Настройте новое подключение к системе с использованием добавленного JDBC-драйвера и укажите URL для подключения (например, jdbc:adtm://10.92.3.3:9092). | . После завершения настройки подключитесь к системе с помощью SQL-клиента. На рисунке ниже показаны параметры JDBC-драйвера DTM в SQL-клиенте DBeaver. Параметры JDBC-драйвера . На рисунке ниже показаны параметры подключения к системе с использованием драйвера DTM. Параметры подключения к системе . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/connection/connection_via_sql_client/connection_via_sql_client.html",
    "relUrl": "/working_with_system/connection/connection_via_sql_client/connection_via_sql_client.html"
  },"93": {
    "doc": "Выгрузка данных",
    "title": "Выгрузка данных",
    "content": "Выгрузка данных . Система позволяет выгружать актуальные и архивные данные, а также совокупность изменений, выполненных в рамках указанных дельт. Данные можно выгружать из логических таблиц и логических представлений. Выгрузка данных из материализованных представлений недоступна. Возможные способы выбора выгружаемых данных см. в секции FOR SYSTEM_TIME раздела SELECT. Данные можно выгрузить из СУБД хранилища, выбранной для выгрузки данных в конфигурации системы (см. параметр EDML_DATASOURCE), или любой указанной СУБД хранилища. Если в запросе не указана СУБД для выгрузки, данные выгружаются из СУБД, заданной в конфигурации. Чтобы выгрузить данные из другой СУБД, нужно добавить в запрос ключевое слово DATASOURCE_TYPE с псевдонимом СУБД. Для выгрузки данных нужен топик Kafka. Если в брокере сообщений Kafka настроено автоматическое создание топиков, то дополнительные действия не требуются. Иначе необходимо создать топик, если он еще не создан. Подробнее о создании топиков см. в документации Kafka: . | раздел Quick Start, | раздел Adding and removing topics. | . Чтобы выгрузить данные из логической таблицы или логического представления во внешнюю информационную систему: . | Создайте внешнюю таблицу выгрузки, если она еще не создана. | Выполните запрос INSERT INTO download_external_table на выгрузку данных в топик. В запросе нужно указать внешнюю таблицу выгрузки, определяющую параметры выгрузки. | Выгрузите данные из топика во внешнюю информационную систему. | . Созданные внешние таблицы выгрузки можно использовать повторно или удалить. Пример . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales -- создание внешней таблицы выгрузки sales_ext_download CREATE DOWNLOAD EXTERNAL TABLE sales_ext_download ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000 -- запуск выгрузки данных из логической таблицы sales INSERT INTO sales_ext_download SELECT * FROM sales WHERE product_units &gt; 2 FOR SYSTEM_TIME AS OF DELTA_NUM 10 -- создание внешней таблицы выгрузки stores_ext_download CREATE DOWNLOAD EXTERNAL TABLE sales.stores_ext_download ( id INT NOT NULL, category VARCHAR(256) NOT NULL, region VARCHAR(256) NOT NULL, address VARCHAR(256) NOT NULL, description VARCHAR(256) ) LOCATION 'kafka://$kafka/stores_out' FORMAT 'AVRO' CHUNK_SIZE 1000 -- запуск выгрузки данных из логической таблицы stores INSERT INTO stores_ext_download SELECT * FROM stores WHERE region = 'Москва' DATASOURCE_TYPE = 'adqm' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/data_download/data_download.html",
    "relUrl": "/working_with_system/data_download/data_download.html"
  },"94": {
    "doc": "Запрос данных",
    "title": "Запрос данных",
    "content": "Запрос данных . Система позволяет запрашивать небольшие объемы актуальных и архивных данных, а также изменений, выполненных в рамках указанных дельт. Возможные способы выборки данных описаны в секции FOR SYSTEM_TIME раздела SELECT. Примечание: под небольшим объемом данных подразумевается результат, содержащий десятки строк. Для запроса большого объема данных следует использовать функцию выгрузки данных. Чтобы запросить небольшой объем данных из логических таблиц, логических представлений или материализованного представления, выполните запрос SELECT. Запросы на чтение данных обрабатываются в порядке, описанном в разделе Порядок обработки запросов на чтение данных. При успешном выполнении запроса запрошенные данные возвращаются в ответе. На рисунке ниже показан пример запроса из логической таблицы sales, возвращающего одну строку. Так как ключевое слово DATASOURCE_TYPE не указано, система автоматически направляет запрос в СУБД, оптимальную для его исполнения (см. Маршрутизация запросов к данным). Запрос небольшого объема данных . Пример . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales -- запрос данных из логической таблицы sales SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC LIMIT 20 -- запрос данных из логического представления stores_by_sold_products SELECT sold.store_id, sold.product_amount FROM stores_by_sold_products AS sold . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/data_reading/data_reading.html",
    "relUrl": "/working_with_system/data_reading/data_reading.html"
  },"95": {
    "doc": "Маршрутизация запросов к данным",
    "title": "Маршрутизация запросов к данным",
    "content": "Маршрутизация запросов к данным . Содержание раздела . | Примеры запросов по категориям . | Реляционные запросы | Запросы агрегации и группировки | Запрос чтения по ключу | Запрос неопределенной категории | . | Маршрутизация запросов к данным материализованных представлений | . Запросы к данным маршрутизируются следующим образом: . | Если в запросе указано ключевое слово DATASOURCE_TYPE с СУБД хранилища для исполнения запроса, запрос направляется в указанную СУБД. | Иначе: . | Определяются те СУБД хранилища, в которых можно выполнить запрос, — выбираются СУБД, содержащие данные всех запрашиваемых логических сущностей. | Определяется категория запроса. | Запрос направляется в ту из выбранных СУБД, которая имеет в конфигурации самый высокий приоритет для запросов этой категории (см. ниже). | . | . Запросы к данным материализованных представлений после перечисленных этапов маршрутизации проходят дополнительные этапы (см. Маршрутизация запросов к данным материализованных представлений). Порядок выбора СУБД для исполнения каждой категории запросов настраивается в конфигурации системы. По умолчанию действует порядок, описанный в таблице ниже. Такой порядок выбора СУБД эффективно использует возможности каждой из СУБД хранилища, однако при необходимости его можно изменить. | Категория запроса | Порядок выбора СУБД для исполнения запроса | . | 1. Реляционный запрос (запрос с ключевым словом JOIN и (или) подзапросами) | 1. ADB2. ADP3. ADQM4. ADG | . | 2. Запрос агрегации и группировки | 1. ADQM2. ADB3. ADP4. ADG | . | 3. Запрос точечного чтения по ключу | 1. ADG2. ADB3. ADP4. ADQM | . | 4. Другой запрос (не соответствующий ни одной из предыдущих категорий) | 1. ADB2. ADP3. ADQM4. ADG | . Категория запроса определяется в указанном порядке: запрос проверяется на наличие признаков первой категории, и затем, если запрос не соответствует первой категории, он проверяется на наличие признаков второй категории и т.д. Например, запрос с ключевым словом JOIN соответствует первой категории независимо от наличия признаков других категорий — агрегации, группировки и чтения по ключу. Примеры запросов каждой из категорий см. ниже. Примечание: наиболее полный синтаксис запросов доступен в ADB и ADP. ADG и ADQM имеют ограничения на выполнение запросов, вызванные особенностями этих СУБД (см. Поддержка SQL). Примеры запросов по категориям . Реляционные запросы . Реляционный запрос: . SELECT * FROM sales.sales AS s JOIN sales.stores AS st ON s.store_id = st.id . Реляционный запрос, который включает агрегацию, группировку и чтение по ключу (st.id): . SELECT st.id, st.category, SUM(s.product_units) AS product_amount FROM sales.stores AS st JOIN sales.sales AS s ON st.id = s.store_id WHERE st.id &lt;&gt; 10004 GROUP BY st.id, st.category ORDER BY product_amount DESC . Запросы агрегации и группировки . Запрос агрегации и группировки: . SELECT s.product_code, SUM(s.product_units) AS product_amount FROM sales.sales AS s GROUP BY s.product_code ORDER BY product_amount ASC . Запрос агрегации и группировки, который включает чтение по ключу (s.id): . SELECT s.product_code, SUM(s.product_units) AS product_amount FROM sales.sales AS s WHERE s.id &gt; 20000 GROUP BY s.product_code . Запрос чтения по ключу . SELECT * FROM sales.sales as s WHERE s.id BETWEEN 1001 AND 2000 . Запрос неопределенной категории . SELECT * FROM sales.sales AS s WHERE s.product_units &gt; 2 . Маршрутизация запросов к данным материализованных представлений . Запросы к данным материализованных представлений проходят все этапы маршрутизации, описанные выше, и затем — дополнительные этапы: . | Если для материализованного представления не указано ключевое слово FOR SYSTEM_TIME, запрос направляется в СУБД, где размещены данные этого представления. Из представления выбираются данные, актуальные на момент его последней синхронизации. | Иначе, если ключевое слово FOR SYSTEM_TIME указано, система проверяет, присутствуют ли запрашиваемые данные в материализованном представлении. | Если данные присутствуют в представлении, запрос направляется в СУБД, где размещены данные этого представления. | Иначе запрос направляется к исходным таблицам СУБД-источника, на которых построено представление. | . | . Примечание: следующие ключевые слова не поддерживаются в запросах к материализованным представлениям: . | FOR SYSTEM_TIME AS OF LATEST_UNCOMMITTED_DELTA; | FOR SYSTEM_TIME AS OF STARTED IN (delta_num1, delta_num2), если хотя бы одна дельта из диапазона отсутствует в материализованном представлении; | FOR SYSTEM_TIME AS OF FINISHED IN (delta_num1, delta_num2), если хотя бы одна дельта из диапазона отсутствует в материализованном представлении. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/data_reading/routing/routing.html",
    "relUrl": "/working_with_system/data_reading/routing/routing.html"
  },"96": {
    "doc": "Загрузка данных",
    "title": "Загрузка данных",
    "content": "Загрузка данных . Для загрузки данных нужен топик Kafka. Если в брокере сообщений Kafka настроено автоматическое создание топиков, то дополнительные действия не требуются. Иначе необходимо создать топик, если он еще не создан. Подробнее о создании топиков см. в документации Kafka: . | раздел Quick Start, | раздел Adding and removing topics. | . Примечание: загрузка данных возможна только в логическую таблицу. Загрузка данных в логические и материализованные представления недоступна. Чтобы загрузить данные из внешней информационной системы в логическую таблицу: . | Загрузите данные из внешней информационной системы в топик Kafka. Данные должны иметь формат, описанный в разделе Формат загрузки данных. | Создайте логическую таблицу, если она еще не создана. | Создайте внешнюю таблицу загрузки, если она еще не создана. | Выполните запрос BEGIN DELTA на открытие дельты, если она еще не открыта. | Выполните запрос INSERT INTO logical_table на загрузку данных из топика в логическую таблицу. В запросе нужно указать внешнюю таблицу загрузки, определяющую параметры загрузки. После успешного окончания загрузки данных система вернет ответ с пустым объектом ResultSet. | Если необходимо, загрузите другие данные, например в другие логические таблицы. В рамках одной открытой дельты можно выполнять произвольное количество запросов INSERT INTO logical_table, при этом не допускается загрузка различных состояний одного и того же объекта. | Выполните запрос COMMIT DELTA для сохранения изменений и закрытия дельты. | . При успешном выполнении последовательности действий загруженные данные сохраняются в качестве актуальных, а предыдущая версия данных, если такая была, становится архивной. Подробнее о версионировании см. в разделе Версионирование данных. Пока дельта не закрыта, все изменения данных, выполненные в рамках нее, можно отменить (см. ROLLBACK DELTA). Созданные внешние таблицы загрузки можно использовать повторно или удалить. Пример . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales -- создание логической таблицы sales CREATE TABLE sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id); -- создание внешней таблицы загрузки CREATE UPLOAD EXTERNAL TABLE sales_ext_upload ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000 -- открытие новой (горячей) дельты BEGIN DELTA -- запуск загрузки данных в логическую таблицу sales INSERT INTO sales SELECT * FROM sales.sales_ext_upload -- закрытие дельты (фиксация изменений) COMMIT DELTA . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/data_upload/data_upload.html",
    "relUrl": "/working_with_system/data_upload/data_upload.html"
  },"97": {
    "doc": "Версионирование данных",
    "title": "Версионирование данных",
    "content": "Версионирование данных . Все записи логической таблицы с одинаковым первичным ключом рассматриваются системой как исторические состояния одного и того же объекта. Одновременно объект системы может иметь множество архивных состояний, а также не более одного актуального и не более одного нового (“горячего”) состояния. Записи, загружаемые в логическую таблицу в рамках одной дельты, должны иметь уникальный первичный ключ. Для того чтобы система могла корректно определить, что делать с загруженными записями, каждая из них должна содержать значение sys_op. Поле sys_op является служебным и может принимать следующие значения: . | 0 — нужно добавить новую запись или обновить существующую, если такая будет найдена; | 1 — нужно удалить существующую запись. | . Если поле sys_op отсутствует в схеме данных Avro и (или) в загружаемых записях, при попытке выполнить запрос INSERT INTO logical_table система вернет исключение. Все загружаемые данные сохраняются в виде горячих записей, и затем, при фиксации изменений, система обновляет состояние объектов логических таблиц в соответствии с новыми данными. Порядок применения каждой из новых записей зависит от наличия/отсутствия актуальной записи с таким же первичным ключом и значения sys_op новой записи: . | Если актуальная запись есть и значение sys_op новой записи равно 0, актуальная запись перемещается в архив, а новая запись сохраняется в качестве актуальной. | Если актуальная запись есть и значение sys_op новой записи равно 1, актуальная запись перемещается в архив. Добавление новой записи не происходит, и среди актуальных записей не остается записей с этим первичным ключом. | Если актуальной записи нет, новая запись сохраняется в качестве актуальной. | . Примечание: для удаления записи нужно, чтобы все данные новой записи (кроме значения sys_op) совпадали с данными одной из актуальных записей логической таблицы. Если первичные ключи актуальной и новой записи совпадают, но другие данные этих записей различаются, выдается исключение и запись не удаляется. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/data_upload/data_versioning/data_versioning.html",
    "relUrl": "/working_with_system/data_upload/data_versioning/data_versioning.html"
  },"98": {
    "doc": "Изменение логического представления",
    "title": "Изменение логического представления",
    "content": "Изменение логического представления . Чтобы изменить логическое представление в логической БД, выполните запрос ALTER VIEW или CREATE OR REPLACE VIEW (см. CREATE VIEW). При успешном выполнении запроса логическое представление изменит свой вид. Пример . -- выбор sales как логической базы данных по умолчанию USE sales -- создание логического представления CREATE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 10 -- изменение логического представления ALTER VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount ASC LIMIT 20 -- пересоздание логического представления CREATE OR REPLACE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 30 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/alter_view/alter_view.html",
    "relUrl": "/working_with_system/logical_schema_update/alter_view/alter_view.html"
  },"99": {
    "doc": "Создание логической базы данных",
    "title": "Создание логической базы данных",
    "content": "Создание логической базы данных . Чтобы создать логическую базу данных, выполните запрос CREATE DATABASE (см. примеры ниже). Если логическую базу данных нужно создать только на логическом уровне, без пересоздания связанной физической базы данных в хранилище данных, добавьте в запрос ключевое слово LOGICAL_ONLY. Наличие логической базы данных можно проверить, как описано в разделе Проверка наличия логической базы данных. Совет: для удобства написания последующих запросов к этой логической базе данных можно выбрать ее в качестве используемой по умолчанию. Примеры . Создание логической базы данных . CREATE DATABASE sales . Создание логической базы данных только на логическом уровне . CREATE DATABASE sales1 LOGICAL_ONLY . Выбор логической БД по умолчанию . USE SALES . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/create_db/create_db.html",
    "relUrl": "/working_with_system/logical_schema_update/create_db/create_db.html"
  },"100": {
    "doc": "Создание внешней таблицы выгрузки",
    "title": "Создание внешней таблицы выгрузки",
    "content": "Создание внешней таблицы выгрузки . Чтобы создать внешнюю таблицу выгрузки в логической БД, выполните запрос CREATE DOWNLOAD EXTERNAL TABLE. При успешном выполнении запроса внешняя таблица загрузки появляется в логической схеме данных. Совет: для удобства разделения таблиц выгрузки и загрузки рекомендуется задавать имя таблицы, указывающее на ее тип (например, transactions_ext_download или transactions_ext_upload). Примечание: внешняя таблица представляет собой декларацию приемника данных и формата выгрузки данных и не хранит сами данные. Наличие внешней таблицы можно проверить, как описано в разделе Проверка наличия внешней таблицы. Пример . -- выбор базы данных sales по умолчанию USE sales -- создание внешней таблицы выгрузки CREATE DOWNLOAD EXTERNAL TABLE sales.sales_ext_download ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/create_download_table/create_download_table.html",
    "relUrl": "/working_with_system/logical_schema_update/create_download_table/create_download_table.html"
  },"101": {
    "doc": "Создание материализованного представления",
    "title": "Создание материализованного представления",
    "content": "Создание материализованного представления . Чтобы создать материализованное представление в логической базе данных, выполните запрос CREATE MATERIALIZED VIEW. Если материализованное представление нужно создать только на логическом уровне, без пересоздания связанных физических таблиц в хранилище, добавьте в запрос ключевое слово LOGICAL_ONLY. Примечание: в текущей версии возможно создание материализованных представлений в ADG на основе данных ADB. Наличие материализованного представления можно проверить, как описано в разделе Проверка наличия материализованного представления. Наличие физических таблиц, связанных с материализованным представлением, можно проверить, как описано в разделе Проверка месторасположения логической сущности. Примеры . Создание материализованного представления . -- выбор базы данных sales по умолчанию USE sales -- создание материализованного представления sales_and_stores CREATE MATERIALIZED VIEW sales.sales_and_stores ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, description VARCHAR(256), store_id INT NOT NULL, store_category VARCHAR(256) NOT NULL, region VARCHAR(256) NOT NULL, PRIMARY KEY (id, region) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adg) AS SELECT s.id, s.transaction_date, s.product_code, s.product_units, s.description, st.id AS store_id, st.category as store_category, st.region FROM sales.sales AS s JOIN sales.stores AS st ON s.store_id = st.id DATASOURCE_TYPE = 'adb'; . Создание материализованного представления только на логическом уровне . CREATE MATERIALIZED VIEW sales.stores_by_sold_products_matview ( store_id INT NOT NULL, product_amount INT NOT NULL, PRIMARY KEY (store_id) ) DISTRIBUTED BY (store_id) DATASOURCE_TYPE (adg) AS SELECT store_id, SUM(product_units) AS product_amount FROM sales.sales GROUP BY store_id DATASOURCE_TYPE = 'adb' LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/create_materialized_view/create_materialized_view.html",
    "relUrl": "/working_with_system/logical_schema_update/create_materialized_view/create_materialized_view.html"
  },"102": {
    "doc": "Создание логической таблицы",
    "title": "Создание логической таблицы",
    "content": "Создание логической таблицы . Чтобы создать логическую таблицу в логической базе данных, выполните запрос CREATE TABLE. | Если данные логической таблицы нужно размещать только в некоторых СУБД хранилища, добавьте в запрос ключевое слово DATASOURCE_TYPE с псевдонимами требуемых СУБД. | Если логическую таблицу нужно создать только на логическом уровне, без пересоздания связанных физических таблиц в хранилище, добавьте в запрос ключевое слово LOGICAL_ONLY. | . Наличие логической таблицы можно проверить, как описано в разделе Проверка наличия логической таблицы. Наличие физических таблиц, связанных с логической, можно проверить, как описано в разделе Проверка месторасположения логической сущности. Примеры . Создание логической таблицы . -- выбор базы данных sales по умолчанию USE sales -- создание таблицы sales CREATE TABLE sales ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id); . Создание логической таблицы только на логическом уровне . CREATE TABLE sales.sales1 ( id INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (id) ) DISTRIBUTED BY (id) LOGICAL_ONLY . Создание логической таблицы с размещением данных в ADQM и ADG . CREATE TABLE sales.clients ( id INT NOT NULL, first_name VARCHAR(256) NOT NULL, last_name VARCHAR(256) NOT NULL, patronymic_name VARCHAR(256), birth_date DATE, PRIMARY KEY (id) ) DISTRIBUTED BY (id) DATASOURCE_TYPE (adqm,adg) . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/create_table/create_table.html",
    "relUrl": "/working_with_system/logical_schema_update/create_table/create_table.html"
  },"103": {
    "doc": "Создание внешней таблицы загрузки",
    "title": "Создание внешней таблицы загрузки",
    "content": "Создание внешней таблицы загрузки . Чтобы создать внешнюю таблицу загрузки в логической БД, выполните запрос CREATE UPLOAD EXTERNAL TABLE. При успешном выполнении запроса внешняя таблица загрузки появляется в логической схеме данных. Совет: для удобства разделения таблиц загрузки и выгрузки рекомендуется задавать имя таблицы, указывающее на ее тип (например, transactions_ext_upload или transactions_ext_download). Примечание: внешняя таблица представляет собой декларацию источника данных и формата загрузки данных и не хранит сами данные. Наличие внешней таблицы можно проверить, как описано в разделе Проверка наличия внешней таблицы. Пример . -- выбор базы данных sales по умолчанию USE sales -- создание внешней таблицы загрузки CREATE UPLOAD EXTERNAL TABLE sales.sales_ext_upload ( id INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/create_upload_table/create_upload_table.html",
    "relUrl": "/working_with_system/logical_schema_update/create_upload_table/create_upload_table.html"
  },"104": {
    "doc": "Создание логического представления",
    "title": "Создание логического представления",
    "content": "Создание логического представления . Чтобы создать логическое представление в логической БД, выполните запрос CREATE VIEW. При успешном выполнении запроса логическое представление появляется в логической схеме данных. Наличие логического представления можно проверить, как описано в разделе Проверка наличия логического представления. Пример . -- выбор базы данных sales по умолчанию USE sales -- создание представления stores_by_sold_products CREATE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales.sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 30 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/create_view/create_view.html",
    "relUrl": "/working_with_system/logical_schema_update/create_view/create_view.html"
  },"105": {
    "doc": "Удаление логической базы данных",
    "title": "Удаление логической базы данных",
    "content": "Удаление логической базы данных . Чтобы удалить логическую базу данных и ее данные, выполните запрос DROP DATABASE (см. примеры ниже). Если нужно удалить логическую базу данных только на логическом уровне, без удаления связанной физической базы данных и размещенных в ней данных из хранилища, добавьте в запрос ключевое слово LOGICAL_ONLY. Наличие логической базы данных можно проверить, как описано в разделе Проверка наличия логической базы данных. Примеры . Удаление логической базы данных . DROP DATABASE sales . Удаление логической базы данных только на логическом уровне . DROP DATABASE sales1 LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/drop_db/drop_db.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_db/drop_db.html"
  },"106": {
    "doc": "Удаление внешней таблицы выгрузки",
    "title": "Удаление внешней таблицы выгрузки",
    "content": "Удаление внешней таблицы выгрузки . Чтобы удалить внешнюю таблицу выгрузки, выполните запрос DROP DOWNLOAD EXTERNAL TABLE. При успешном выполнении запроса внешняя таблица выгрузки удаляется из логической схемы данных. Наличие внешней таблицы можно проверить, как описано в разделе Проверка наличия внешней таблицы. Пример . -- выбор базы данных sales по умолчанию USE sales -- удаление внешней таблицы выгрузки DROP DOWNLOAD EXTERNAL TABLE sales_ext_download . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/drop_download_table/drop_download_table.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_download_table/drop_download_table.html"
  },"107": {
    "doc": "Удаление материализованного представления",
    "title": "Удаление материализованного представления",
    "content": "Удаление материализованного представления . Чтобы удалить материализованное представление и его данные, выполните запрос DROP MATERIALIZED VIEW. Если материализованное представление нужно удалить только на логическом уровне, без удаления связанных физических таблиц и данных из хранилища, добавьте в запрос ключевое слово LOGICAL_ONLY. Наличие материализованного представления можно проверить, как описано в разделе Проверка наличия материализованного представления. Наличие физических таблиц, связанных с материализованным представлением, можно проверить, как описано в разделе Проверка месторасположения логической сущности. Примеры . Удаление материализованного представления из одной СУБД . -- выбор базы данных sales по умолчанию USE sales -- удаление представления sales_and_stores DROP MATERIALIZED VIEW sales_and_stores DATASOURCE_TYPE = 'adg' . Удаление материализованного представления из всех СУБД . DROP MATERIALIZED VIEW sales.sales_and_stores . Удаление материализованного представления только на логическом уровне . DROP MATERIALIZED VIEW sales.stores_by_sold_products_matview LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/drop_materialized_view/drop_materialized_view.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_materialized_view/drop_materialized_view.html"
  },"108": {
    "doc": "Удаление логической таблицы",
    "title": "Удаление логической таблицы",
    "content": "Удаление логической таблицы . Чтобы удалить логическую таблицу и ее данные, выполните запрос DROP TABLE. | Если данные логической таблицы нужно удалить только из некоторых СУБД хранилища, добавьте в запрос ключевое слово DATASOURCE_TYPE с псевдонимами требуемых СУБД. | Если логическую таблицу нужно удалить только на логическом уровне, без удаления связанных физических таблиц и данных из хранилища, добавьте в запрос ключевое слово LOGICAL_ONLY. | . Наличие логической таблицы можно проверить, как описано в разделе Проверка наличия логической таблицы. Наличие физических таблиц, связанных с логической, можно проверить, как описано в разделе Проверка месторасположения логической сущности. Примеры . Удаление логической таблицы из одной СУБД . -- выбор базы данных sales по умолчанию USE sales -- удаление таблицы sales из СУБД ADQM DROP TABLE sales DATASOURCE_TYPE = 'adqm' . Удаление логической таблицы из всех СУБД . DROP TABLE sales.sales . Удаление логической таблицы только на логическом уровне . DROP TABLE sales.sales1 LOGICAL_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/drop_table/drop_table.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_table/drop_table.html"
  },"109": {
    "doc": "Удаление внешней таблицы загрузки",
    "title": "Удаление внешней таблицы загрузки",
    "content": "Удаление внешней таблицы загрузки . Чтобы удалить внешнюю таблицу загрузки, выполните запрос DROP UPLOAD EXTERNAL TABLE. При успешном выполнении запроса внешняя таблица удаляется из логической схемы данных. Наличие внешней таблицы можно проверить, как описано в разделе Проверка наличия внешней таблицы. Пример . -- выбор базы данных sales по умолчанию USE sales -- удаление внешней таблицы загрузки DROP UPLOAD EXTERNAL TABLE sales_ext_upload . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/drop_upload_table/drop_upload_table.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_upload_table/drop_upload_table.html"
  },"110": {
    "doc": "Удаление логического представления",
    "title": "Удаление логического представления",
    "content": "Удаление логического представления . Чтобы удалить логическое представление из логической БД, выполните запрос DROP VIEW. При успешном выполнении запроса логическое представление удаляется из логической схемы данных. Удаление логического представления никак не отражается в хранилище. Наличие логического представления можно проверить, как описано в разделе Проверка наличия логического представления. Пример . -- выбор базы данных sales по умолчанию USE sales -- удаление представления stores_by_sold_products DROP VIEW stores_by_sold_products . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/drop_view/drop_view.html",
    "relUrl": "/working_with_system/logical_schema_update/drop_view/drop_view.html"
  },"111": {
    "doc": "Проверка наличия логической сущности",
    "title": "Проверка наличия логической сущности",
    "content": "Проверка наличия логической сущности . Содержание раздела . | Проверка наличия логической базы данных | Проверка наличия логической таблицы | Проверка наличия логического представления | Проверка наличия материализованного представления | Проверка наличия внешней таблицы | . При успешном создании любой логической сущности — логической базы данных, логической таблицы, логического представления, внешней таблицы загрузки, внешней таблицы выгрузки или материализованного представления — система возвращает в ответе пустой объект ResultSet. Если сущность не удалось создать, система возвращает исключение. Таким образом, по ответу на запрос можно определить, создалась ли логическая сущность, но при необходимости можно проверить наличие сущности, как описано в этом разделе. Наличие логической сущности можно проверить любым из способов: . | запросить метаданные из соответствующего системного представления (способ недоступен для внешних таблиц); | выполнить SELECT-запрос к проверяемой логической сущности (способ недоступен для логической БД и внешних таблиц); | проверить дерево объектов в SQL-клиенте. | . Примеры запросов для каждого типа сущности доступны в секциях ниже: . | Проверка наличия логической базы данных; | Проверка наличия логической таблицы; | Проверка наличия логического представления; | Проверка наличия материализованного представления; | Проверка наличия внешней таблицы. | . Примечание: наличие внешних таблиц загрузки и выгрузки можно проверить только в дереве объектов SQL-клиента. Внешние таблицы не отображаются в системных представлениях, и для них недоступны SELECT-запросы. Проверка наличия логической базы данных . Чтобы проверить наличие логической базы данных, используйте любой из способов: . | Выполните запрос к системному представлению schemata (вместо DB_NAME подставьте имя логической БД в верхнем регистре): SELECT CASE WHEN count(*) &gt; 0 THEN 'БД существует' ELSE 'БД не существует' END FROM INFORMATION_SCHEMA.schemata WHERE schema_name = '&lt;DB_NAME&gt;' . Если логическая база данных существует, в ответе возвращается строка “БД существует”, иначе — строка “БД не существует”. | Проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). Если логическая база данных существует, она присутствует среди объектов в SQL-клиенте, иначе — отсутствует среди объектов. | . На рисунке ниже показана логическая БД в дереве объектов SQL-клиента. Логическая БД в дереве объектов . Проверка наличия логической таблицы . Чтобы проверить наличие логической таблицы, используйте любой из способов: . | Выполните запрос к системному представлению tables (вместо DB_NAME и TABLE_NAME подставьте имя логической БД и имя таблицы в верхнем регистре): SELECT CASE WHEN count(*) &gt; 0 THEN 'таблица существует' ELSE 'таблица не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND (table_name = '&lt;TABLE_NAME&gt;' AND table_type = 'BASE TABLE') . Если логическая таблица существует, в ответе возвращается строка “таблица существует”, иначе — строка “таблица не существует”. | Выполните SELECT-запрос к логической таблице, например: SELECT * FROM &lt;db_name&gt;.&lt;table_name&gt; LIMIT 5 . Если логическая таблица существует, запрос возвращает от ноля до пяти записей (в зависимости от содержимого таблицы), иначе — исключение Entity &lt;table_name&gt; does not exist. | Проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). Если логическая таблица существует, она присутствует среди объектов логической БД в SQL-клиенте, иначе — отсутствует среди таких объектов. Логические таблицы в дереве объектов . | . Проверка наличия логического представления . Чтобы проверить наличие логического представления, используйте любой из способов: . | Выполните запрос к системному представлению tables (вместо DB_NAME и VIEW_NAME подставьте имя логической БД и имя логического представления в верхнем регистре): SELECT CASE WHEN count(*) &gt; 0 THEN 'представление существует' ELSE 'представление не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND (table_name = '&lt;VIEW_NAME&gt;' AND table_type = 'VIEW') . Если логическое представление существует, в ответе возвращается строка “представление существует”, иначе — строка “представление не существует”. | Выполните SELECT-запрос к логическому представлению, например: SELECT * FROM &lt;db_name&gt;.&lt;view_name&gt; LIMIT 5 . Если логическое представление существует, запрос возвращает от ноля до пяти записей, иначе — исключение Entity &lt;view_name&gt; does not exist. | Проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). Если логическое представление, оно присутствует среди объектов логической БД в SQL-клиенте, иначе — отсутствует среди объектов логической БД. Логическое представление в дереве объектов . | . Проверка наличия материализованного представления . Чтобы проверить наличие материализованного представления, используйте любой из способов: . | Выполните запрос к системному представлению tables (вместо DB_NAME и MATERIALIZED_VIEW_NAME подставьте имя логической БД и имя представления в верхнем регистре): SELECT CASE WHEN count(*) &gt; 1 THEN 'представление существует' ELSE 'представление не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND ((table_name = '&lt;MATERIALIZED_VIEW_NAME&gt;' AND table_type = 'BASE TABLE') OR (table_name = 'SYS_&lt;MATERIALIZED_VIEW_NAME&gt;' AND table_type = 'VIEW')) . Если материализованное представление существует, в ответе возвращается строка “представление существует”, иначе — строка “представление не существует”. | Выполните SELECT-запрос к материализованному представлению, например: SELECT * FROM &lt;db_name&gt;.&lt;materialized_view_name&gt; LIMIT 5 . Если материализованное представление существует, запрос возвращает от ноля до пяти записей, иначе — исключение Entity &lt;materialized_view_name&gt; does not exist. | Проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). Если материализованное представление существует, оно присутствует среди объектов логической БД в SQL-клиенте, иначе — отсутствует среди объектов логической БД. Материализованное представление в дереве объектов . | . Проверка наличия внешней таблицы . Чтобы проверить наличие внешней таблицы загрузки или выгрузки, проверьте дерево объектов в вашем SQL-клиенте (см. рисунки ниже). Если внешняя таблица существует, она присутствует среди объектов логической БД в SQL-клиенте, иначе — отсутствует среди объектов логической БД. На рисунках ниже показаны фрагменты дерева объектов SQL-клиента: с внешней таблицей загрузки sales_ext_upload и внешней таблицей выгрузки sales_ext_download соответственно. Внешняя таблица загрузки в дереве объектов . Внешняя таблица выгрузки в дереве объектов . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/entity_presence_check/entity_presence_check.html",
    "relUrl": "/working_with_system/logical_schema_update/entity_presence_check/entity_presence_check.html"
  },"112": {
    "doc": "Управление схемой данных",
    "title": "Управление схемой данных",
    "content": "Управление схемой данных . Система позволяет организовать структуру данных с помощью логической схемы данных. Доступны следующие действия по управлению логической схемой данных: . | Создание логической базы данных | Удаление логической базы данных | Создание логической таблицы | Удаление логической таблицы | Создание логического представления | Изменение логического представления | Удаление логического представления | Создание материализованного представления | Удаление материализованного представления | Создание внешней таблицы загрузки | Удаление внешней таблицы загрузки | Создание внешней таблицы выгрузки | Удаление внешней таблицы выгрузки | Проверка наличия логической сущности | Запрос метаданных логической схемы | . Запросы на обновление логической схемы данных обрабатываются в порядке, описанном в разделе Порядок обработки запросов на обновление логической схемы. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/logical_schema_update.html",
    "relUrl": "/working_with_system/logical_schema_update/logical_schema_update.html"
  },"113": {
    "doc": "Запрос метаданных логической схемы",
    "title": "Запрос метаданных логической схемы",
    "content": "Запрос метаданных логической схемы . Чтобы запросить метаданные объектов логической схемы данных, выполните запрос SELECT FROM INFORMATION_SCHEMA. Доступно получение информации о сущностях и их свойствах, перечисленных в разделе Системные представления (INFORMATION_SCHEMA). Примеры . Запрос списка логических БД окружения . SELECT schema_name FROM INFORMATION_SCHEMA.schemata ORDER BY schema_name . Запрос списка сущностей в логической БД . SELECT * FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' . Запрос списка столбцов сущностей в логической БД . SELECT TC.table_schema, TC.table_name, TT.table_type, TC.column_name FROM information_schema.columns AS TC JOIN information_schema.tables AS TT ON TC.table_schema = TT.table_schema and TC.table_name = TT.table_name WHERE TT.table_schema = 'SALES' ORDER BY TC.table_schema, TC.table_name . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/logical_schema_update/request_from_schema/request_from_schema.html",
    "relUrl": "/working_with_system/logical_schema_update/request_from_schema/request_from_schema.html"
  },"114": {
    "doc": "Проверка месторасположения логической сущности",
    "title": "Проверка месторасположения логической сущности",
    "content": "Проверка месторасположения логической сущности . Чтобы проверить, в каких СУБД хранилища размещены данные логической таблицы или материализованного представления, выполните запрос к системному представлению tables (вместо DB_NAME и ENTITY_NAME подставьте имя логической базы данных и имя таблицы или представления в верхнем регистре): . SELECT * FROM INFORMATION_SCHEMA.tables WHERE table_schema = '&lt;DB_NAME&gt;' AND (table_name = '&lt;ENTITY_NAME&gt;' AND table_type = 'BASE TABLE') . В ответе система возвращает информацию о запрошенной логической сущности, где в столбце table_datasource_type перечислены СУБД, которые содержат данные этой сущности. На рисунке ниже показан пример запроса по всем логическим сущностям логической БД sales: . Системное представление tables . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/other_features/datasource_check/datasource_check.html",
    "relUrl": "/working_with_system/other_features/datasource_check/datasource_check.html"
  },"115": {
    "doc": "Определение логической БД по умолчанию",
    "title": "Определение логической БД по умолчанию",
    "content": "Определение логической БД по умолчанию . Логическую базу данных можно определить как используемую по умолчанию. Если логическая база данных по умолчанию определена, система использует ее имя всякий раз, когда в запросах явно не указана логическая БД. Логическую базу данных по умолчанию необходимо определить перед выполнением запросов, предназначенных для управления дельтой и получения информации о ней. Это действие также можно выполнить перед другими запросами, что позволит не указывать имя логической БД перед именами логических сущностей в запросах к одной и той же логической базе данных. Чтобы определить логическую базу данных по умолчанию, используйте любой из способов: . | Укажите логическую базу данных в настройках JDBC-подключения к системе (см. рисунок ниже). Логическая база данных указывается последним параметром адресной строки (например, jdbc:adtm://10.92.3.3:9092/sales, где sales — имя логической базы данных). Логическая база, указанная таким образом, используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или изменение настроек JDBC-подключения. | Выполните запрос USE. Логическая база, указанная таким образом, используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или закрытие соединения с системой. | . На рисунке ниже показан пример настройки параметров JDBC-подключения в SQL-клиенте, где логическая БД sales указана как используемая по умолчанию. Параметры JDBC-драйвера с указанной логической БД по умолчанию . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/other_features/default_db_set-up/default_db_set-up.html",
    "relUrl": "/working_with_system/other_features/default_db_set-up/default_db_set-up.html"
  },"116": {
    "doc": "Другие действия",
    "title": "Другие действия",
    "content": "Другие действия . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/other_features/other_features.html",
    "relUrl": "/working_with_system/other_features/other_features.html"
  },"117": {
    "doc": "Получение информации о SELECT-запросе",
    "title": "Получение информации о SELECT-запросе",
    "content": "Получение информации о SELECT-запросе . По SELECT-запросу можно получить информацию о его выполнении без фактического выполнения в СУБД хранилища. Доступна следующая информация: . | имя СУБД хранилища, в которой предполагается выполнение запроса; | план выполнения запроса (только для ADB и ADP); | обогащенный запрос, подготовленный системой на основе исходного запроса с учетом специфики СУБД хранилища. | . Чтобы получить информацию о SELECT-запросе, выполните его с ключевым словом ESTIMATE_ONLY (см. пример ниже). Подробнее о формате и содержимом ответа см. в секции Ключевое слово ESTIMATE_ONLY раздела SELECT, о возможных ключевых словах SELECT-запроса — в секции Поддерживаемые ключевые слова того же раздела. Пример . SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales.sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC ESTIMATE_ONLY . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/other_features/query_estimation/query_estimation.html",
    "relUrl": "/working_with_system/other_features/query_estimation/query_estimation.html"
  },"118": {
    "doc": "Работа с системой",
    "title": "Работа с системой",
    "content": "Работа с системой . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/working_with_system/working_with_system.html",
    "relUrl": "/working_with_system/working_with_system.html"
  },"119": {
    "doc": "Temporary folder for processing SVG-files",
    "title": "Temporary folder for processing SVG-files",
    "content": "Temporary folder for processing SVG-files . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/TMP/DRAWIO/",
    "relUrl": "/TMP/DRAWIO/"
  },"120": {
    "doc": "Temporary folder for processing XML-files",
    "title": "Temporary folder for processing XML-files",
    "content": "Temporary folder for processing XML-files . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v5-1-0/TMP/SVG/",
    "relUrl": "/TMP/SVG/"
  }
}
